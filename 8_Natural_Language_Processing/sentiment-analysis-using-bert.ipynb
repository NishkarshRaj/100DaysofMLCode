{"cells":[{"metadata":{},"cell_type":"markdown","source":"![BERT](https://miro.medium.com/max/2960/0*63_xsVQp0Wezk9ua.jpg)"},{"metadata":{},"cell_type":"markdown","source":"#  What is BERT?\n* BERT stands for Bidirectional Encoders Representations from Transformers.\n* Bidirectional - to understand the text you’re looking you’ll have to look back (at the previous words) and forward (at the next words)\n* Transformers - The Attention Is All You Need paper presented the Transformer model. The Transformer reads entire sequences of tokens at once. In a sense, the model is non-directional, while LSTMs read sequentially (left-to-right or right-to-left). The attention mechanism allows for learning contextual relations between words (e.g. his in a sentence refers to Jim).\n* (Pre-trained) contextualized word embeddings - The ELMO paper introduced a way to encode words based on their meaning/context. Nails has multiple meanings - fingernails and metal nails.\n\nIn this notebook we will be using transformers library by hugging face."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/smile-twitter-emotion-dataset/smile-annotations-final.json\n/kaggle/input/smile-twitter-emotion-dataset/smile-annotations-final.csv\n/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv\n/kaggle/input/twitter-airline-sentiment/database.sqlite\n/kaggle/input/twitter-airline-sentiment/Tweets.csv\n/kaggle/input/twitter-sentiment-analysis-hatred-speech/test.csv\n/kaggle/input/twitter-sentiment-analysis-hatred-speech/train.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nfrom tqdm.notebook import tqdm","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading SMILE twitter emotion dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/smile-twitter-emotion-dataset/smile-annotations-final.csv\",\n                names = ['Id','Text','Category'])\ndf.set_index('Id',inplace = True)\ndf[:4]","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"                                                                 Text Category\nId                                                                            \n611857364396965889  @aandraous @britishmuseum @AndrewsAntonio Merc...   nocode\n614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...    happy\n614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...    happy\n614877582664835073  @Sofabsports thank you for following me back. ...    happy","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Category</th>\n    </tr>\n    <tr>\n      <th>Id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>611857364396965889</th>\n      <td>@aandraous @britishmuseum @AndrewsAntonio Merc...</td>\n      <td>nocode</td>\n    </tr>\n    <tr>\n      <th>614484565059596288</th>\n      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>614746522043973632</th>\n      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>614877582664835073</th>\n      <td>@Sofabsports thank you for following me back. ...</td>\n      <td>happy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Text.iloc[0]","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"'@aandraous @britishmuseum @AndrewsAntonio Merci pour le partage! @openwinemap'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"* Counts of Emotions in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Category.value_counts()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"nocode               1572\nhappy                1137\nnot-relevant          214\nangry                  57\nsurprise               35\nsad                    32\nhappy|surprise         11\nhappy|sad               9\ndisgust|angry           7\ndisgust                 6\nsad|disgust             2\nsad|angry               2\nsad|disgust|angry       1\nName: Category, dtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"We will be filtering the emotions with single emotions and ignoring the rest."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[(df.Category!=\"nocode\")]\ndf = df[~(df.Category.str.contains(\"\\|\"))]\ndf.Category.value_counts()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"happy           1137\nnot-relevant     214\nangry             57\nsurprise          35\nsad               32\ndisgust            6\nName: Category, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"possible_label = df.Category.unique()\ndict_label = {}\nfor index,possible_label in enumerate(possible_label):\n    dict_label[possible_label] = index\ndict_label","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"{'happy': 0,\n 'not-relevant': 1,\n 'angry': 2,\n 'disgust': 3,\n 'sad': 4,\n 'surprise': 5}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Label\"] = df[\"Category\"].replace(dict_label)\ndf.head()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"                                                                 Text  \\\nId                                                                      \n614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...   \n614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...   \n614877582664835073  @Sofabsports thank you for following me back. ...   \n611932373039644672  @britishmuseum @TudorHistory What a beautiful ...   \n611570404268883969  @NationalGallery @ThePoldarkian I have always ...   \n\n                   Category  Label  \nId                                  \n614484565059596288    happy      0  \n614746522043973632    happy      0  \n614877582664835073    happy      0  \n611932373039644672    happy      0  \n611570404268883969    happy      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Category</th>\n      <th>Label</th>\n    </tr>\n    <tr>\n      <th>Id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>614484565059596288</th>\n      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n      <td>happy</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>614746522043973632</th>\n      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n      <td>happy</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>614877582664835073</th>\n      <td>@Sofabsports thank you for following me back. ...</td>\n      <td>happy</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>611932373039644672</th>\n      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n      <td>happy</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>611570404268883969</th>\n      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n      <td>happy</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.rcParams['figure.figsize'] = (5,5)\nsns.countplot(df[\"Label\"],hue = df[\"Label\"],palette = 'dark')\nplt.legend(loc = 'upper right')\nplt.show()","execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 360x360 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = [0,1,2,3,4,5]\nsizes = df[\"Label\"].value_counts()\ncolors = plt.cm.copper(np.linspace(0, 1, 5))\nexplode = [0.1, 0.1,0.1, 0.2, 0.5, 0.9]\ncmap = plt.get_cmap('Spectral')\nplt.pie(sizes,labels = labels,colors = colors,shadow = True,explode = explode)\nplt.legend()\nplt.show()","execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 360x360 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(df.index.values,\n                                                df.Label.values,\n                                                test_size = 0.15,\n                                                random_state=17,\n                                                stratify = df.Label.values)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df[\"data_type \"] = ['not_set']*df.shape[0]\n# df.head()","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in df.index:\n#     if i in X_train:\n#         df[\"data_type\"].replace(\"not_set\",\"train\")\n#     elif i in X_test:\n#         df[\"data_type\"].replace(\"not_set\",\"test\")\n# df.head() \ndf.loc[X_train,'data_type'] = 'train'\ndf.loc[X_test,'data_type'] = 'test'","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"                                                                 Text  \\\nId                                                                      \n614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...   \n614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...   \n614877582664835073  @Sofabsports thank you for following me back. ...   \n611932373039644672  @britishmuseum @TudorHistory What a beautiful ...   \n611570404268883969  @NationalGallery @ThePoldarkian I have always ...   \n\n                   Category  Label data_type  \nId                                            \n614484565059596288    happy      0     train  \n614746522043973632    happy      0     train  \n614877582664835073    happy      0     train  \n611932373039644672    happy      0     train  \n611570404268883969    happy      0     train  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Category</th>\n      <th>Label</th>\n      <th>data_type</th>\n    </tr>\n    <tr>\n      <th>Id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>614484565059596288</th>\n      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n      <td>happy</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>614746522043973632</th>\n      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n      <td>happy</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>614877582664835073</th>\n      <td>@Sofabsports thank you for following me back. ...</td>\n      <td>happy</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>611932373039644672</th>\n      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n      <td>happy</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>611570404268883969</th>\n      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n      <td>happy</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['Category','Label','data_type']).count()","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"                              Text\nCategory     Label data_type      \nangry        2     test          9\n                   train        48\ndisgust      3     test          1\n                   train         5\nhappy        0     test        171\n                   train       966\nnot-relevant 1     test         32\n                   train       182\nsad          4     test          5\n                   train        27\nsurprise     5     test          5\n                   train        30","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>Text</th>\n    </tr>\n    <tr>\n      <th>Category</th>\n      <th>Label</th>\n      <th>data_type</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">angry</th>\n      <th rowspan=\"2\" valign=\"top\">2</th>\n      <th>test</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>train</th>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">disgust</th>\n      <th rowspan=\"2\" valign=\"top\">3</th>\n      <th>test</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>train</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">happy</th>\n      <th rowspan=\"2\" valign=\"top\">0</th>\n      <th>test</th>\n      <td>171</td>\n    </tr>\n    <tr>\n      <th>train</th>\n      <td>966</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">not-relevant</th>\n      <th rowspan=\"2\" valign=\"top\">1</th>\n      <th>test</th>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>train</th>\n      <td>182</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">sad</th>\n      <th rowspan=\"2\" valign=\"top\">4</th>\n      <th>test</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>train</th>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">surprise</th>\n      <th rowspan=\"2\" valign=\"top\">5</th>\n      <th>test</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>train</th>\n      <td>30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import BertTokenizer\nfrom torch.utils.data import TensorDataset","execution_count":16,"outputs":[{"output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',\n                                         do_lower_case = True)","execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28260be6fca344f0bea927b78e6eab34"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Encoding text by tokenizing using BERT Tokenizer\n* In order to use BERT text embeddings as input to train text classification model, we need to tokenize our text reviews. Tokenization refers to dividing a sentence into individual words. To tokenize our text, we will be using the BERT tokenizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_train = tokenizer.batch_encode_plus(df[df[\"data_type\"]=='train'].Text.values,\n                                           add_special_tokens = True,\n                                            return_attention_masks = True,\n                                           pad_to_max_length = True,\n                                           max_length = 256,\n                                           return_tensors = 'pt')\n\n\n\nencoder_test = tokenizer.batch_encode_plus(df[df[\"data_type\"]=='test'].Text.values,\n                                           add_special_tokens = True,\n                                            return_attention_masks = True,\n                                           pad_to_max_length = True,\n                                           max_length = 256,\n                                           return_tensors = 'pt')\n\ninput_ids_train = encoder_train['input_ids']\nattention_masks_train = encoder_train[\"attention_mask\"]\nlabels_train = torch.tensor(df[df['data_type']=='train'].Label.values)\n\n\ninput_ids_test = encoder_test['input_ids']\nattention_masks_test = encoder_test[\"attention_mask\"]\nlabels_test = torch.tensor(df[df['data_type']=='test'].Label.values)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = TensorDataset(input_ids_train,attention_masks_train,labels_train)\ndata_test = TensorDataset(input_ids_test,attention_masks_test,labels_test)\n","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data_train),len(data_test)","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"(1258, 223)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"* We will use sequence classification model as we have to classify multi label text from the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import BertForSequenceClassification\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n                                     num_labels = len(dict_label),\n                                     output_attentions = False,\n                                     output_hidden_states =  False)","execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae710fbeedaa457eab8d360ef8e296bd"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38274a9420db4c0796cb20aa8f37dfd6"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"From torch we will use data loader,randomsampler to load data in an iterable format but extracting different subsamples from dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import RandomSampler,SequentialSampler,DataLoader\n\ndataloader_train = DataLoader(\n    data_train,\n    sampler= RandomSampler(data_train),\n    batch_size = 16\n    \n)\n\n\ndataloader_test = DataLoader(\n    data_test,\n    sampler= RandomSampler(data_test),\n    batch_size = 32\n    \n)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import AdamW,get_linear_schedule_with_warmup\noptimizer = AdamW(model.parameters(),lr = 1e-5,eps = 1e-8)\n\nepochs  = 10\nscheduler = get_linear_schedule_with_warmup(\n            optimizer,\n    num_warmup_steps = 0,\n   num_training_steps = len(dataloader_train)*epochs \n)","execution_count":23,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining Model metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score \n\ndef f1_score_func(preds,labels):\n    preds_flat = np.argmax(preds,axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat,preds_flat,average = 'weighted')\n","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy_per_class(preds,labels):\n    label_dict_reverse = {v:k for k,v in dict_label.items()}\n    \n    preds_flat = np.argmax(preds,axis=1).flatten()\n    labels_flat = labels.flatten()\n    \n    for label in np.unique(labels_flat):\n        y_preds = preds_flat[labels_flat==label]\n        y_true = labels_flat[labels_flat==label]\n        print(f\"Class:{label_dict_reverse}\")\n        print(f\"Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n\")","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n\nseed_val = 17\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\nprint(f\"Loading:{device}\")","execution_count":27,"outputs":[{"output_type":"stream","text":"cuda\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Defining Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(dataloader_val):\n    model.eval()\n    \n    loss_val_total = 0\n    predictions,true_vals = [],[]\n    \n    for batch in tqdm(dataloader_val):\n        batch = tuple(b.to(device) for b in batch)\n        \n        inputs = {'input_ids':  batch[0],\n                  'attention_mask':batch[1],\n                  'labels': batch[2]\n                 }\n        with torch.no_grad():\n            outputs = model(**inputs)\n            \n        loss = outputs[0]\n        logits = outputs[1]\n        loss_val_total +=loss.item()\n        \n        logits = logits.detach().cpu().numpy()\n        label_ids = inputs['labels'].cpu().numpy()\n        predictions.append(logits)\n        true_vals.append(label_ids)\n        \n        \n    loss_val_avg = loss_val_total/len(dataloader_val)  \n    \n    predictions = np.concatenate(predictions,axis=0)\n    true_vals = np.concatenate(true_vals,axis=0) \n    return loss_val_avg,predictions,true_vals\n            ","execution_count":28,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Training Data"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"for epoch in tqdm(range(1,epochs+1)):\n    model.train()\n    \n    loss_train_total=0\n    \n    progress_bar = tqdm(dataloader_train,desc = \"Epoch: {:1d}\".format(epoch),leave = False,disable = False)\n    \n    \n    for batch in progress_bar:\n        model.zero_grad()\n        \n        batch = tuple(b.to(device) for b in batch)\n        \n        inputs = {\n            \"input_ids\":batch[0],\n            \"attention_mask\":batch[1],\n            \"labels\":batch[2]\n            \n        }\n        outputs = model(**inputs)\n        \n        loss = outputs[0]\n#         logits = outputs[1]\n        loss_train_total +=loss.item()\n        loss.backward()\n        \n        torch.nn.utils.clip_grad_norm(model.parameters(),1.0)\n        \n        optimizer.step()\n        scheduler.step()\n        \n        \n        progress_bar.set_postfix({'training_loss':'{:.3f}'.format(loss.item()/len(batch))})\n#     torch.save(model.state_dict(),f'/kaggle/output/BERT_ft_epoch{epoch}.model')To save the model after each epoch\n    \n    tqdm.write('\\nEpoch {epoch}')\n    \n    loss_train_avg = loss_train_total/len(dataloader_train)\n    tqdm.write(f'Training Loss: {loss_train_avg}')\n    val_loss,predictions,true_vals = evaluate(dataloader_test)\n    test_score = f1_score_func(predictions,true_vals)\n    tqdm.write(f'Val Loss:{val_loss}\\n Test Score:{test_score}')\n    ","execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36754fc8662f4f4486a2201c5a5e2003"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Epoch: 1', max=79.0, style=ProgressStyle(description_widt…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n","name":"stderr"},{"output_type":"stream","text":"\r\nEpoch {epoch}\n\rTraining Loss: 0.9699796487258959\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2567400badb4404fbba0739d35dde747"}},"metadata":{}},{"output_type":"stream","text":"\n\rVal Loss:0.7014265102999551\n Test Score:0.6953185953656175\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Epoch: 2', max=79.0, style=ProgressStyle(description_widt…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"\r\nEpoch {epoch}\n\rTraining Loss: 0.6117297460006762\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b34763ba4df4005970cd8948111a4f7"}},"metadata":{}},{"output_type":"stream","text":"\n\rVal Loss:0.5799521633556911\n Test Score:0.7571476303525896\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Epoch: 3', max=79.0, style=ProgressStyle(description_widt…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"\r\nEpoch {epoch}\n\rTraining Loss: 0.4657496551546869\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e6a9119ce534da5980a17e7924db35e"}},"metadata":{}},{"output_type":"stream","text":"\n\rVal Loss:0.5237005438123431\n Test Score:0.7902172903312981\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Epoch: 4', max=79.0, style=ProgressStyle(description_widt…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"\r\nEpoch {epoch}\n\rTraining Loss: 0.38381981491288053\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff32235c1e1b479b80c914027e215a97"}},"metadata":{}},{"output_type":"stream","text":"\n\rVal Loss:0.5376968894686017\n Test Score:0.7938675400685126\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Epoch: 5', max=79.0, style=ProgressStyle(description_widt…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"\r\nEpoch {epoch}\n\rTraining Loss: 0.3033778618408155\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18b8006a2f4c4d08959c9e3a6faf55c1"}},"metadata":{}},{"output_type":"stream","text":"\n\rVal Loss:0.5278307454926627\n Test Score:0.8050975582150716\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Epoch: 6', max=79.0, style=ProgressStyle(description_widt…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"\r\nEpoch {epoch}\n\rTraining Loss: 0.24704220919292183\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"564036fd26e3483b907e966496a7470a"}},"metadata":{}},{"output_type":"stream","text":"\n\rVal Loss:0.5274006170885903\n Test Score:0.8433260525207777\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Epoch: 7', max=79.0, style=ProgressStyle(description_widt…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"\r\nEpoch {epoch}\n\rTraining Loss: 0.21461329679889016\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"802b9eff99e94651a51840284dbd87cf"}},"metadata":{}},{"output_type":"stream","text":"\n\rVal Loss:0.5721525656325477\n Test Score:0.8528528996575542\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Epoch: 8', max=79.0, style=ProgressStyle(description_widt…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"\r\nEpoch {epoch}\n\rTraining Loss: 0.1806286097138743\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e00bd97ba5646299d7dc642e4268b3f"}},"metadata":{}},{"output_type":"stream","text":"\n\rVal Loss:0.5534958051783698\n Test Score:0.8494232891614654\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Epoch: 9', max=79.0, style=ProgressStyle(description_widt…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"\r\nEpoch {epoch}\n\rTraining Loss: 0.15728285135347633\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b2a3e6e13bb44e5935c9d690559ed8f"}},"metadata":{}},{"output_type":"stream","text":"\n\rVal Loss:0.5554194450378418\n Test Score:0.8469984025469383\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Epoch: 10', max=79.0, style=ProgressStyle(description_wid…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"\r\nEpoch {epoch}\n\rTraining Loss: 0.1455424027163771\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82faf3e2cc054247a9aaed89249bd765"}},"metadata":{}},{"output_type":"stream","text":"\n\rVal Loss:0.5662243110792977\n Test Score:0.8505631660263822\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Using the saved model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from transformers import BertForSequenceClassification\n# model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n#                                      num_labels = len(dict_label),\n#                                      output_attentions = False,\n#                                      output_hidden_states =  False)","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.to(device)\n","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=6, bias=True)\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #using saved model\n# model.load_state_dict(torch.load(\"Path of saved model\"))# in case want to use the saved model\n# _,predictions,true_vals = evaluate(dataloader_test)\n# accuracy_per_class(predictions,true_vals)","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_,predictions,true_vals = evaluate(dataloader_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_per_class(predictions,true_vals)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}