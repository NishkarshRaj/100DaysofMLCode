{"cells":[{"metadata":{"_uuid":"2a85b978e287eaa4218d41d2884c53e1c77ae576"},"cell_type":"markdown","source":"# Intro to Movie Review Sentiment Analysis\n\n\n![](https://i.imgur.com/WNgxr2I.png)\n\n\nFor the movie review sentiment analysis, we will be working on The Rotten Tomatoes movie review dataset from Kaggle. \nHere, we'll have to label phrases on a scale of five values: negative, somewhat negative, neutral, somewhat positive, positive based on the sentiment of the movie reviews.\n\nThe dataset is comprised of tab-separated files with phrases from the Rotten Tomatoes dataset. Each phrase has a PhraseId. Each sentence has a SentenceId. Phrases that are repeated (such as short/common words) are only included once in the data.\n\nThe sentiment labels are:\n\n* 0 - *negative*\n* 1 - *somewhat negative*\n* 2 - *neutral*\n* 3 - *somewhat positive*\n* 4 - *positive*\n\n\n\n\n\n\n\n**Any suggestions for improvement or comments are highly appreciated!**\n\nPlease upvote(like button) and share this kernel if you like it so that more people can learn from it. \n\n"},{"metadata":{"_uuid":"5014a9648e6127b5dd14275d120472adb00cfb7b"},"cell_type":"markdown","source":"Below is the step by step methodology that we will be following :\n\n- <a href='#1'>1. Initial Look at the Data</a>\n    - <a href='#1.1'>1.1 Distribution of reviews in each sentiment category</a>\n    - <a href='#1.2'>1.2 Dropping insignificant columns</a>\n    - <a href='#1.3'>1.3 Overall Distribution of the length of the reviews under each sentiment class</a>\n    - <a href='#1.4'>1.4 Creating Word Cloud of negative and positive movie reviews</a>\n        - <a href='#1.4.1'>1.4.1 Filtering out positive and negative movie reviews</a>\n        - <a href='#1.4.2'>1.4.2 Word Cloud for negatively classified movie reviews</a>\n        - <a href='#1.4.3'>1.4.3 Word Cloud for positively classified movie reviews</a>\n    - <a href='#1.5'>1.5 Term Frequencies of each Sentiment class</a>\n        - <a href='#1.5.1'>1.5.1 Term Frequency for 'negative' sentiments</a>\n        - <a href='#1.5.2'>1.5.2 Term Frequency for 'some negative' sentiments</a>\n        - <a href='#1.5.3'>1.5.3 Term Frequency for 'neutral' sentiments</a>\n        - <a href='#1.5.4'>1.5.4 Term Frequency for 'some positive' sentiments</a>\n        - <a href='#1.5.5'>1.5.5 Term Frequency for 'positive' sentiments</a>\n    - <a href='#1.6'>1.6 Total Term Frequency of all the 5 sentiment classes</a>\n    - <a href='#1.7'>1.7 Frequency plot of top frequent 500 phrases in movie reviews</a>\n    - <a href='#1.8'>1.8 Plot of Absolute frequency of phrases against their rank</a>\n    - <a href='#1.9'>1.9 Movie Reviews Tokens Visualisation</a>\n        - <a href='#1.9.1'>1.9.1 Plot of top frequently used 50 phrases in negative movie reviews</a>\n        - <a href='#1.9.2'>1.9.2 Plot of top frequently used 50 phrases in positive movie reviews</a>\n- <a href='#2'>2. Traditional Supervised Machine Learning Models</a>\n    - <a href='#2.1'>2.1 Feature Engineering</a>\n    - <a href='#2.2'>2.2 Implementation of CountVectorizer & TF-IDF\n        - <a href='#2.2.1'>2.2.1 CountVectorizer</a>\n        - <a href='#2.2.2'>2.2.2 How is TF-IDF different from CountVectorizer?</a>\n        - <a href='#2.2.3'>2.2.3 How exactly does TF-IDF work?</a>\n        - <a href='#2.2.4'>2.2.4 Understanding the parameters of TfidfVectorizer</a>\n        - <a href='#2.2.5'>2.2.5 Setting the parametrs of CountVectorizer</a>\n    - <a href='#2.3'>2.3 Model Training, Prediction and Performance Evaluation</a>\n        - <a href='#2.3.1'>2.3.1 Logistic Regression model on CountVectorizer</a>\n        - <a href='#2.3.2'>2.3.2 Logistic Regression model on TF-IDF features</a>\n        - <a href='#2.3.3'>2.3.3 SGD model on Countvectorizer</a>\n        - <a href='#2.3.4'>2.3.4 SGD model on TF-IDF</a>\n        - <a href='#2.3.5'>2.3.5 RandomForest model on TF-IDF</a>"},{"metadata":{"_uuid":"7ea63ad921444c7265324c85064bab3aa01207a6","collapsed":true,"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c406efbd9ca6864ab84f1fc25a9e512cc8ba0a3d"},"cell_type":"markdown","source":"## <a id='1'>1. Initial Look at the Data</a>"},{"metadata":{"_uuid":"8ee2739c4e266c53f7e8e2e4aab0bd60bb265906","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/train.tsv\", sep='\\t')\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f701590db15d56a5ca47371cfb21aac9baa90d6","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"df_test = pd.read_csv(\"../input/test.tsv\", sep='\\t')\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"96f31551ff20a1b44bf848486ba6ef9f9521a694"},"cell_type":"markdown","source":"## <a id='1.1'>1.1 Distribution of reviews in each sentiment category</a>"},{"metadata":{"_uuid":"983dc50e848ef91f81c69857a8ef890da59b1b7c"},"cell_type":"markdown","source":"Here, the training dataset has dominating neutral phrases from the movie reviews followed by somewhat positive and then somewhat negative."},{"metadata":{"_uuid":"a89e161dcd817cfb03342bc7ae4a04b8ad8e57a8","scrolled":false,"trusted":false,"collapsed":true},"cell_type":"code","source":"df_train.Sentiment.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e96bcf266d41b7aa186d787b47dc138ce70f02f1","scrolled":false,"trusted":false,"collapsed":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4fb9e3b54b520eeafccabf4a607ba6a34d699104"},"cell_type":"markdown","source":"## <a id='1.2'>1.2 Dropping insignificant columns</a>"},{"metadata":{"_uuid":"5a92ef85a8e441f5289637157fb584d581f2de40","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train_1 = df_train.drop(['PhraseId','SentenceId'],axis=1)\ndf_train_1.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"496ae4ed51c567010b771e8c16e51f3e4de2f172"},"cell_type":"markdown","source":"Let's check the phrase length of each of the movie reviews."},{"metadata":{"_uuid":"478a9ccfab1a9351c0e99564311d52838ab13021","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"df_train_1['phrase_len'] = [len(t) for t in df_train_1.Phrase]\ndf_train_1.head(4)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c743f73ae5c73317a40e04f8ae77f25009cb3b7"},"cell_type":"markdown","source":"## <a id='1.3'>1.3 Overall Distribution of the length of the reviews under each sentiment class</a>"},{"metadata":{"_uuid":"41e4b53027bb5a3a66db83de41888ae74d9a8e73","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(5,5))\nplt.boxplot(df_train_1.phrase_len)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ec19e9e1be7ebaad60d569c5a649a429b105ff92"},"cell_type":"markdown","source":"From the above box plot, some of the reviews are way more than 100 chracters long."},{"metadata":{"_uuid":"92c0268b05909c2516eb405cfd020af11f59a007","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train_1[df_train_1.phrase_len > 100].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b8786fb91ca96671fa0be586df9ee8578637d662","scrolled":false,"trusted":false,"collapsed":true},"cell_type":"code","source":"df_train_1[df_train_1.phrase_len > 100].loc[0].Phrase","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80e6456059886e07ab9c7f75d235d846613dfc8b"},"cell_type":"markdown","source":"## <a id='1.4'>1.4 Creating Word Cloud of negative and positive movie reviews</a>"},{"metadata":{"_uuid":"766f9c7e804f822c69a32013aeceb658ef85e133"},"cell_type":"markdown","source":"### Word Cloud"},{"metadata":{"_uuid":"05539f594fd62e0c3f8fa2b3e05ccb281e9d504d"},"cell_type":"markdown","source":"\nA word cloud is a graphical representation of frequently used words in a collection of text files. The height of each word in this picture is an indication of frequency of occurrence of the word in the entire text. Such diagrams are very useful when doing text analytics.\n\nIt provides a general idea of what kind of words are frequent in the corpus, in a sort of quick and dirty way.\n\nLet's start doing some EDA on text data by Word Cloud."},{"metadata":{"_uuid":"7c1be67de37fb1f1fc45a95dee52e0eb6900d13d"},"cell_type":"markdown","source":"## <a id='1.4.1'>1.4.1 Filtering out positive and negative movie reviews</a>"},{"metadata":{"_uuid":"5e6c63dff26b13c2be2d26c814b36152a71eeda4","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"neg_phrases = df_train_1[df_train_1.Sentiment == 0]\nneg_words = []\nfor t in neg_phrases.Phrase:\n    neg_words.append(t)\nneg_words[:4]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8405d63cdadb0c65d6da87e4ab9d3c8989864a0d"},"cell_type":"markdown","source":"**pandas.Series.str.cat ** : Concatenate strings in the Series/Index with given separator. Here we give a space as separator, so, it will concatenate all the strings in each of the index separated by a space."},{"metadata":{"_uuid":"fd90a795d8dbd965797e450e9b793ee20ba8dc71","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"neg_text = pd.Series(neg_words).str.cat(sep=' ')\nneg_text[:100]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c9e456533e79755decde9cb8eec4622e7bd8d39","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"for t in neg_phrases.Phrase[:300]:\n    if 'good' in t:\n        print(t)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a4e228ec91f5ad248025d01117cb72eca45c6ac1"},"cell_type":"markdown","source":"So, we can very well see, even if the texts contain words like \"good\", it is a negative sentiment because it indicates that the movie is **NOT** a good movie. "},{"metadata":{"_uuid":"b49cbe635d373c4ed116188a381b9cb8a57f1e69","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"pos_phrases = df_train_1[df_train_1.Sentiment == 4] ## 4 is positive sentiment\npos_string = []\nfor t in pos_phrases.Phrase:\n    pos_string.append(t)\npos_text = pd.Series(pos_string).str.cat(sep=' ')\npos_text[:100]\n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de8ddb77d6d286fe97bce8217955e2a2b279e586"},"cell_type":"markdown","source":"## <a id='1.4.2'>1.4.2 Word Cloud for negatively classified movie reviews</a>"},{"metadata":{"_uuid":"3dbf9496951d7537670f099aa18abdb8a7000e08","scrolled":false,"trusted":false,"collapsed":true},"cell_type":"code","source":"from wordcloud import WordCloud\nwordcloud = WordCloud(width=1600, height=800, max_font_size=200).generate(neg_text)\nplt.figure(figsize=(12,10))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de5143f2ee6daeb038d52b8e6280b0d08855dd52"},"cell_type":"markdown","source":"Some of the big words can be interpreted quite neutral, such as \"movie\",\"film\", etc. We can see some of the words in smaller size make sense to be in negative movie reviews like \"bad cinema\", \"annoying\", \"dull\", etc.\n\nHowever, there are some words like \"good\" is also present in the negatively classified sentiment about the movie.\nLet's go deeper into such words/texts:"},{"metadata":{"_uuid":"b64315c2ccf42d51061ed47b69405bec5b73d9cb"},"cell_type":"markdown","source":"## <a id='1.4.3'>1.4.3 Word Cloud for positively classified movie reviews</a>"},{"metadata":{"_uuid":"f5ed638dd52e7552c05dd84ef6b232b6a1017224","trusted":false,"collapsed":true},"cell_type":"code","source":"wordcloud = WordCloud(width=1600, height=800, max_font_size=200).generate(pos_text)\nplt.figure(figsize=(12,10))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a817c098422c0adc528c425b18ab153751efad29"},"cell_type":"markdown","source":"Again I see some neutral words in big size, \"movie\",\"film\", but positive words like \"good\", \"best\", \"fascinating\" also stand out."},{"metadata":{"_uuid":"adbd87ed4d6bb2bd1915dff4e7654a419e6ec264"},"cell_type":"markdown","source":"## <a id='1.5'>1.5 Term Frequencies of each Sentiment class</a>"},{"metadata":{"_uuid":"0cb9326536f9abec470ca18aafd38f0b62a315e0"},"cell_type":"markdown","source":"We also want to understand how terms are distributed across documents. This helps us to characterize the properties of the algorithms for compressing phrases.\n\nA commonly used model of the distribution of terms in a collection is Zipf's law . It states that, if $t_1$ is the most common term in the collection, $t_2$ is the next most common, and so on, then the collection frequency $cf_i$ of the $i$th most common term is proportional to $1/i$: \n\n$\\displaystyle cf_i \\propto \\frac{1}{i}.$\t\n\n\nSo if the most frequent term occurs $cf_1$ times, then the second most frequent term has half as many occurrences, the third most frequent term a third as many occurrences, and so on. The intuition is that frequency decreases very rapidly with rank.\nThe above equation is one of the simplest ways of formalizing such a rapid decrease and it has been found to be a reasonably good model.\n"},{"metadata":{"_uuid":"ae206bbbe7c0e5e5c8813e8cddd66b5d51466702"},"cell_type":"markdown","source":"We need the Term Frequency data to see what kind of words are used in the movie reviews and how many times have been used.\nLet's proceed with CountVectorizer to calculate term frequencies:\n"},{"metadata":{"_uuid":"db4e3dec7cacf84f4f28406542c2ed0c20bbca94","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncvector = CountVectorizer(min_df = 0.0, max_df = 1.0, ngram_range=(1,2))\ncvector.fit(df_train_1.Phrase)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6278fe75fafb2711526a8ed500445a8adb7343b6","trusted":false,"collapsed":true},"cell_type":"code","source":"len(cvector.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"214bfea4cb040b56f2b1ebee25dfc8dbfe0df830"},"cell_type":"markdown","source":"It looks like count vectorizer has extracted 94644 words out of the corpus.\nGetting term frequency for each class can be obtained with the below code block."},{"metadata":{"_uuid":"ea8bdc96b277e060391266117e021e82bca580ba"},"cell_type":"markdown","source":"## <a id='1.5.1'>1.5.1 Term Frequency for 'negative' sentiments</a>"},{"metadata":{"_uuid":"f7ef9568f910ada27044c800529c193316d4aa4a","collapsed":true,"trusted":false},"cell_type":"code","source":"neg_matrix = cvector.transform(df_train_1[df_train_1.Sentiment == 0].Phrase)\nsom_neg_matrix = cvector.transform(df_train_1[df_train_1.Sentiment == 1].Phrase)\nneu_matrix = cvector.transform(df_train_1[df_train_1.Sentiment == 2].Phrase)\nsom_pos_matrix = cvector.transform(df_train_1[df_train_1.Sentiment == 3].Phrase)\npos_matrix = cvector.transform(df_train_1[df_train_1.Sentiment == 4].Phrase)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a140d887852da48a67446129dddc5bda25ffd4b8","collapsed":true,"trusted":false},"cell_type":"code","source":"neg_words = neg_matrix.sum(axis=0)\nneg_words_freq = [(word, neg_words[0, idx]) for word, idx in cvector.vocabulary_.items()]\nneg_tf = pd.DataFrame(list(sorted(neg_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','negative'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"afd149eebcd629d74c002896fb95cf3c7facf702","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"neg_tf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa8e17414b0a4cda78d78345b228ef4663b85466","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"neg_tf_df = neg_tf.set_index('Terms')\nneg_tf_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ccb34e301ffc55f7480b2356286e4c4e13757e6"},"cell_type":"markdown","source":"## <a id='1.5.2'>1.5.2 Term Frequency for 'some negative' sentiments</a>"},{"metadata":{"_uuid":"5e984d6718bbeed3da65524314d64d617bb4f7b0","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"\nsom_neg_words = som_neg_matrix.sum(axis=0)\nsom_neg_words_freq = [(word, som_neg_words[0, idx]) for word, idx in cvector.vocabulary_.items()]\nsom_neg_tf = pd.DataFrame(list(sorted(som_neg_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','some-negative'])\nsom_neg_tf_df = som_neg_tf.set_index('Terms')\nsom_neg_tf_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1954b289edc3c8eaa95508cbd6088f28bc333acb"},"cell_type":"markdown","source":"## <a id='1.5.3'>1.5.3 Term Frequency for 'neutral' sentiments</a>"},{"metadata":{"_uuid":"fbe3951224d3fb650a0cf97bd676467287ab5a5d","trusted":false,"collapsed":true},"cell_type":"code","source":"\nneu_words = neu_matrix.sum(axis=0)\nneu_words_freq = [(word, neu_words[0, idx]) for word, idx in cvector.vocabulary_.items()]\nneu_words_tf = pd.DataFrame(list(sorted(neu_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','neutral'])\nneu_words_tf_df = neu_words_tf.set_index('Terms')\nneu_words_tf_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e396c0f7e6cf4379e64fe9e2aa10208d8fe7339"},"cell_type":"markdown","source":"## <a id='1.5.4'>1.5.4 Term Frequency for 'some positive' sentiments</a>"},{"metadata":{"_uuid":"7a348acec9f82413338ff1ace08bba60a10d0c5a","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"\nsom_pos_words = som_pos_matrix.sum(axis=0)\nsom_pos_words_freq = [(word, som_pos_words[0, idx]) for word, idx in cvector.vocabulary_.items()]\nsom_pos_words_tf = pd.DataFrame(list(sorted(som_pos_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','some-positive'])\nsom_pos_words_tf_df = som_pos_words_tf.set_index('Terms')\nsom_pos_words_tf_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d09e7f6615f4f2a9cea2884ae6177104a09ad6c0"},"cell_type":"markdown","source":"## <a id='1.5.5'>1.5.5 Term Frequency for 'positive' sentiments</a>\n"},{"metadata":{"_uuid":"15142bbb0fa395b5e79408625062769e540ec1e3","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"\npos_words = pos_matrix.sum(axis=0)\npos_words_freq = [(word, pos_words[0, idx]) for word, idx in cvector.vocabulary_.items()]\npos_words_tf = pd.DataFrame(list(sorted(pos_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','positive'])\npos_words_tf_df = pos_words_tf.set_index('Terms')\npos_words_tf_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb98ba8b4a6451a71de55fd58e43ccd8da6b2b53","trusted":false,"collapsed":true},"cell_type":"code","source":"term_freq_df = pd.concat([neg_tf_df,som_neg_tf_df,neu_words_tf_df,som_pos_words_tf_df,pos_words_tf_df],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26f53fc7234d3ebf38e17ef2dbf818666c127403"},"cell_type":"markdown","source":"## <a id='1.6'>1.6 Total Term Frequency of all the 5 sentiment classes</a>"},{"metadata":{"_uuid":"1d6213384eb9577706f169dd589cbe60601cc540","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"term_freq_df['total'] = term_freq_df['negative'] + term_freq_df['some-negative'] \\\n                                 + term_freq_df['neutral'] + term_freq_df['some-positive'] \\\n                                 +  term_freq_df['positive'] \nterm_freq_df.sort_values(by='total', ascending=False).head(20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0f3deb29b7a720b576ff5ccba12be2a9e31f0e94"},"cell_type":"markdown","source":"## <a id='1.7'>1.7 Frequency plot of top frequent 500 phrases in movie reviews</a>"},{"metadata":{"_uuid":"87edadbb8b312c669fb1015d5626a3ca3e095687"},"cell_type":"markdown","source":"**\"Given some corpus of natural language utterances, the frequency of any word is inversely proportional to its rank in the frequency table. Thus the most frequent word will occur approximately twice as often as the second most frequent word, three times as often as the third most frequent word, etc.\"**\n\nIn other words, the rth most frequent word has a frequency f(r) that scales according to $${f(r)} \\propto \\frac{1}{r^\\alpha}$$ for $$\\alpha \\approx {1}$$\n\n\nLet's see how the movie review tokens and their frequencies look like on a plot."},{"metadata":{"_uuid":"1a5a3f0a08926e9c15f2052f08c6f86d6bef0b8f","scrolled":false,"trusted":false,"collapsed":true},"cell_type":"code","source":"y_pos = np.arange(500)\nplt.figure(figsize=(10,8))\ns = 1\nexpected_zipf = [term_freq_df.sort_values(by='total', ascending=False)['total'][0]/(i+1)**s for i in y_pos]\nplt.bar(y_pos, term_freq_df.sort_values(by='total', ascending=False)['total'][:500], align='center', alpha=0.5)\nplt.plot(y_pos, expected_zipf, color='r', linestyle='--',linewidth=2,alpha=0.5)\nplt.ylabel('Frequency')\nplt.title('Top 500 phrases in movie reviews')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26070c09600b4dcc39bd25857b1a96d651274f71"},"cell_type":"markdown","source":"On the X-axis is the rank of the frequency from highest rank from left up to 500th rank to the right. Y-axis is the frequency observed in the corpus.\n\nAnother way to plot this is on a log-log graph, with X-axis being log(rank), Y-axis being log(frequency). By plotting on the log-log scale the result will yield roughly linear line on the graph."},{"metadata":{"_uuid":"3b89ca3666ffbc43da538aa61eff9d564ffa9840"},"cell_type":"markdown","source":"## <a id='1.8'>1.8 Plot of Absolute frequency of phrases against their rank</a>"},{"metadata":{"_uuid":"821b8c7856c0756dbbcb23ca5827694bd86d3862","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"from pylab import *\ncounts = term_freq_df.total\ntokens = term_freq_df.index\nranks = arange(1, len(counts)+1)\nindices = argsort(-counts)\nfrequencies = counts[indices]\nplt.figure(figsize=(8,6))\nplt.ylim(1,10**6)\nplt.xlim(1,10**6)\nloglog(ranks, frequencies, marker=\".\")\nplt.plot([1,frequencies[0]],[frequencies[0],1],color='r')\ntitle(\"Zipf plot for phrases tokens\")\nxlabel(\"Frequency rank of token\")\nylabel(\"Absolute frequency of token\")\ngrid(True)\nfor n in list(logspace(-0.5, log10(len(counts)-2), 25).astype(int)):\n    dummy = text(ranks[n], frequencies[n], \" \" + tokens[indices[n]], \n                 verticalalignment=\"bottom\",\n                 horizontalalignment=\"left\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca26e9e91cff8917516b73c94611c8a80412a129"},"cell_type":"markdown","source":"We can clearly see that words like \"the\", \"in\",\"it\", etc are much higher in frequency but has been ranked less as they don't have any significance regarding the sentiment of the movie review. On the other hand, some words like \"downbeat laughably\" have been given higher rank as they are very less frequent in the document and seems to be significant related to the sentiment of a movie."},{"metadata":{"_uuid":"1e0758285815c4a9d5e05c0ff2092f9d64bfe763"},"cell_type":"markdown","source":"## <a id='1.9'>1.9 Movie Reviews Tokens Visualisation</a>"},{"metadata":{"_uuid":"99fd3447729d4bce7e24d521b3adb145877c7d53"},"cell_type":"markdown","source":"Next, let's explore about how different the tokens in two different classes(positive, negative)."},{"metadata":{"_uuid":"71fa756343d3c09a91af56201d77fc06ebec1711","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncvec = CountVectorizer(stop_words='english',max_features=10000)\ncvec.fit(df_train_1.Phrase)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4610152e091103cc45749c28e7acd8f8d5efc594","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"neg_matrix = cvec.transform(df_train_1[df_train_1.Sentiment == 0].Phrase)\nsom_neg_matrix = cvec.transform(df_train_1[df_train_1.Sentiment == 1].Phrase)\nneu_matrix = cvec.transform(df_train_1[df_train_1.Sentiment == 2].Phrase)\nsom_pos_matrix = cvec.transform(df_train_1[df_train_1.Sentiment == 3].Phrase)\npos_matrix = cvec.transform(df_train_1[df_train_1.Sentiment == 4].Phrase)\n\nneg_words = neg_matrix.sum(axis=0)\nneg_words_freq = [(word, neg_words[0, idx]) for word, idx in cvec.vocabulary_.items()]\nneg_tf = pd.DataFrame(list(sorted(neg_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','negative'])\n\nneg_tf_df = neg_tf.set_index('Terms')\n\n\nsom_neg_words = som_neg_matrix.sum(axis=0)\nsom_neg_words_freq = [(word, som_neg_words[0, idx]) for word, idx in cvec.vocabulary_.items()]\nsom_neg_tf = pd.DataFrame(list(sorted(som_neg_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','some-negative'])\nsom_neg_tf_df = som_neg_tf.set_index('Terms')\n\nneu_words = neu_matrix.sum(axis=0)\nneu_words_freq = [(word, neu_words[0, idx]) for word, idx in cvec.vocabulary_.items()]\nneu_words_tf = pd.DataFrame(list(sorted(neu_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','neutral'])\nneu_words_tf_df = neu_words_tf.set_index('Terms')\n\nsom_pos_words = som_pos_matrix.sum(axis=0)\nsom_pos_words_freq = [(word, som_pos_words[0, idx]) for word, idx in cvec.vocabulary_.items()]\nsom_pos_words_tf = pd.DataFrame(list(sorted(som_pos_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','some-positive'])\nsom_pos_words_tf_df = som_pos_words_tf.set_index('Terms')\n\npos_words = pos_matrix.sum(axis=0)\npos_words_freq = [(word, pos_words[0, idx]) for word, idx in cvec.vocabulary_.items()]\npos_words_tf = pd.DataFrame(list(sorted(pos_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','positive'])\npos_words_tf_df = pos_words_tf.set_index('Terms')\n\nterm_freq_df = pd.concat([neg_tf_df,som_neg_tf_df,neu_words_tf_df,som_pos_words_tf_df,pos_words_tf_df],axis=1)\n\nterm_freq_df['total'] = term_freq_df['negative'] + term_freq_df['some-negative'] \\\n                                 + term_freq_df['neutral'] + term_freq_df['some-positive'] \\\n                                 +  term_freq_df['positive'] \n        \nterm_freq_df.sort_values(by='total', ascending=False).head(15)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3380f8661a35422709ab69630394d3fdb902d703"},"cell_type":"markdown","source":"## <a id='1.9.1'>1.9.1 Plot of top frequently used 50 phrases in negative movie reviews</a>"},{"metadata":{"_uuid":"0763d42b62ce97cd3735608c7b5f61066e8ae5c5","scrolled":false,"trusted":false,"collapsed":true},"cell_type":"code","source":"y_pos = np.arange(50)\nplt.figure(figsize=(12,10))\nplt.bar(y_pos, term_freq_df.sort_values(by='negative', ascending=False)['negative'][:50], align='center', alpha=0.5)\nplt.xticks(y_pos, term_freq_df.sort_values(by='negative', ascending=False)['negative'][:50].index,rotation='vertical')\nplt.ylabel('Frequency')\nplt.xlabel('Top 50 negative tokens')\nplt.title('Top 50 tokens in negative movie reviews')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1110131a46661caecbeef07827d490d6bdde0739"},"cell_type":"markdown","source":"We can see some negative words like \"bad\", \"worst\", \"dull\" are some of the high frequency words. But, there exists few neutral words like \"movie\", \"film\", \"minutes\" dominating the frequency plots.\n\nLet's also take a look at top 50 positive tokens on a bar chart."},{"metadata":{"_uuid":"2401dcdb9c0e51e061344c021b2c72222888c712"},"cell_type":"markdown","source":"## <a id='1.9.2'>1.9.2 Plot of top frequently used 50 phrases in positive movie reviews</a>"},{"metadata":{"_uuid":"a151c4a3ca51a5713d554b1de6baa8401015227c","scrolled":false,"trusted":false,"collapsed":true},"cell_type":"code","source":"y_pos = np.arange(50)\nplt.figure(figsize=(12,10))\nplt.bar(y_pos, term_freq_df.sort_values(by='positive', ascending=False)['positive'][:50], align='center', alpha=0.5)\nplt.xticks(y_pos, term_freq_df.sort_values(by='positive', ascending=False)['positive'][:50].index,rotation='vertical')\nplt.ylabel('Frequency')\nplt.xlabel('Top 50 positive tokens')\nplt.title('Top 50 tokens in positive movie reviews')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f8caf13c8425d6b6c2c4e8e40962496c971c2b5d"},"cell_type":"markdown","source":"Once again, there are some neutral words like \"film\", \"movie\", are quite high up in the rank."},{"metadata":{"_uuid":"1cb184980287b00528cb4b752bb25da316542b2f"},"cell_type":"markdown","source":"## <a id='2'>2. Traditional Supervised Machine Learning Models</a>\n"},{"metadata":{"_uuid":"2d22dcb3c19a4df7c9a6f141dc276a97e7d0d874"},"cell_type":"markdown","source":"## <a id='2.1'>2.1 Feature Engineering</a>"},{"metadata":{"_uuid":"e485a8aff3bb55cfa10afbadf5d43d4815dc0e7d","collapsed":true,"trusted":false},"cell_type":"code","source":"phrase = np.array(df_train_1['Phrase'])\nsentiments = np.array(df_train_1['Sentiment'])\n# build train and test datasets\n\nfrom sklearn.model_selection import train_test_split    \nphrase_train, phrase_test, sentiments_train, sentiments_test = train_test_split(phrase, sentiments, test_size=0.2, random_state=4)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a97602604e4d2ff2527bc91912cb94e5cd9288b6"},"cell_type":"markdown","source":"Next, we will try to see how different are the tokens in 4 different classes(positive,some positive,neutral, some negative, negative). "},{"metadata":{"_uuid":"dbe1d3e99ac64c4ee3a957e798071d9b0a4b3a47"},"cell_type":"markdown","source":"## <a id='2.2'>2.2 Implementation of CountVectorizer & TF-IDF"},{"metadata":{"_uuid":"2256ab84dc009a5379e855d2cad214b8c3995ffd"},"cell_type":"markdown","source":"## <a id='2.2.1'>2.2.1 CountVectorizer</a>\n\n"},{"metadata":{"_uuid":"ac4dcc73540473e6264fabba8f139416f3a6fba9"},"cell_type":"markdown","source":"As we all know, all machine learning algorithms are good with numbers; we have to extract or convert the text data into numbers without losing much of the information.\nOne way to do such transformation is Bag-Of-Words (BOW) which gives a number to each word but that is very inefficient.\nSo, a way to do it is by **CountVectorizer**: it counts the number of words in the document i.e it converts a collection of text documents to a matrix of the counts of occurences of each word in the document. "},{"metadata":{"_uuid":"38bb6c963fe20eedc50b021fe5e338647fd62636"},"cell_type":"markdown","source":"For Example: If we have a collection of 3 text documents as below, then CountVectorizer converts that into individual counts of occurences of each of the words in the document as below:\n\n\n"},{"metadata":{"_uuid":"094838fc12f70ddb59fc2b5df82a15a4a6d84173","collapsed":true,"trusted":false},"cell_type":"code","source":"cv1 = CountVectorizer()\nx_traincv = cv1.fit_transform([\"Hi How are you How are you doing\",\"Hi what's up\",\"Wow that's awesome\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cf754862c89712ce863ba07aca0079987b9dc258","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"x_traincv_df = pd.DataFrame(x_traincv.toarray(),columns=list(cv1.get_feature_names()))\nx_traincv_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4fa2c8f03d46a595fab8ba0d8794d67c90fe850e"},"cell_type":"markdown","source":"Now, in case of CountVectorizer, we are just counting the number of words in the document and many times it happens that some words like \"are\",\"you\",\"hi\",etc are very large in numbers and that would dominate our results in machinelearning algorithm."},{"metadata":{"_uuid":"ebf6fd81879ae73c9077894573c12b5b3628e295"},"cell_type":"markdown","source":"## <a id='2.2.2'>2.2.2 How is TF-IDF different from CountVectorizer?</a>"},{"metadata":{"_uuid":"9a19696985bc26df680a8714f7387ba7c9607ece"},"cell_type":"markdown","source":"So, TF-IDF (stands for **Term-Frequency-Inverse-Document Frequency**) weights down the common words occuring in almost all the documents and give more importance to the words that appear in a subset of documents.\nTF-IDF works by penalising these common words by assigning them lower weights while giving importance to some rare words in a particular document. "},{"metadata":{"_uuid":"5c7e01eb145e7f8d8a7437f3f7d10b0a2d5c90a6"},"cell_type":"markdown","source":"## <a id='2.2.3'>2.2.3 How exactly does TF-IDF work?</a>"},{"metadata":{"_uuid":"051f3db156d301f55e7992d7ff1aca3760a82a2a"},"cell_type":"markdown","source":"\nConsider the below sample table which gives the count of terms(tokens/words) in two documents.\n\n![](https://i.imgur.com/iVOI1TQ.png)\n\nNow, let us define a few terms related to TF-IDF.\n\n**TF (Term Frequency)** :\nDenotes the contribution of the word to the document i.e. words relevant to the document should be frequent. \n\n            TF = (Number of times term t appears in a document)/(Number of terms in the document)\n\nSo, TF(This,Document1) = 1/8\n\nTF(This, Document2)=1/5\n\n**IDF (Inverse Document Frequency)** :\nIf a word has appeared in all the document, then probably that word is not relevant to a particular document. \nBut, if it has appeared in a subset of documents then probably the word is of some relevance to the documents it is present in.\n\n\n           IDF = log(N/n), where, N is the number of documents and n is the number of documents a term t has appeared in.\n\nSo, IDF(This) = log(2/2) = 0.\nIDF(Messi) = log(2/1) = 0.301.\n\n\nNow, let us compare the TF-IDF for a common word ‘This’ and a word ‘Messi’ which seems to be of relevance to Document 1.\n\nTF-IDF(This,Document1) = (1/8) * (0) = 0\n\nTF-IDF(This, Document2) = (1/5) * (0) = 0\n\nTF-IDF(Messi, Document1) = (4/8) * 0.301 = 0.15\n\nSo,  for Document1 , TF-IDF method heavily penalises the word ‘This’ but assigns greater weight to ‘Messi’. So, this may be understood as ‘Messi’ is an important word for Document1 from the context of the entire corpus.\n\n\n## \"Rare terms are more informative than frequent terms\"\n\nThe graphic below attempts to express this intuition. Note that the TF-IDF weight is a relative measurement, so the values in red on the axis are not intended to be taken as absolute weights.\n\n![](https://i.imgur.com/pmjduLZ.png)\n\n\n\n"},{"metadata":{"_uuid":"d3c42da13e1f7f70e2756b1f72ad9980674f60b6"},"cell_type":"markdown","source":"When your corpus (or Structured set of texts) is large, TfIdf is the best option.\n\nNow, let's get back to our problem:"},{"metadata":{"_uuid":"24b6be928a85aa2fd70ae69750ecfbb430410052"},"cell_type":"markdown","source":"## <a id='2.2.4'>2.2.4 Understanding the parameters of TfidfVectorizer</a>"},{"metadata":{"_uuid":"76db18f3d2f0879ebaa7906ce2cce3e9ad2610cd"},"cell_type":"markdown","source":"\n* min_df : While building the vocabulary, it will ignore terms that have a document frequency strictly lower than the given threshold. In our case, threshold for min_df = 0.0\n\n* max_df : While building the vocabulary, it ignore terms that have a document frequency strictly higher than the given threshold. For us, threshold for max_df = 1.0\n\n* ngram_range : A tuple of lower and upper boundary of the range of n-values for different n-grams to be extracted. \n\n\n![](https://i.imgur.com/Gld6LGz.png)\n\n\n\n"},{"metadata":{"_uuid":"bae47448ad5184a46ddf1be663a96a14c2037cbe"},"cell_type":"markdown","source":"* sublinear_tf : Sublinear tf scaling addresses the problem that 20 occurrences of a word is probably not 20 times more important than 1 occurrence.\n\n![](https://i.imgur.com/ZzspOIQ.png)\n","attachments":{}},{"metadata":{"_uuid":"fc3d673f15daec70e6e69e9885798862afaca621"},"cell_type":"markdown","source":"** Why is log used when calculating term frequency weight and IDF, inverse document frequency in sublinear_tf transformation?**"},{"metadata":{"_uuid":"2ee2347922ad3fab8e387fa490b48e5543a4df16"},"cell_type":"markdown","source":"Found the answer to this question in Stackoverflow forum which you may find useful."},{"metadata":{"_uuid":"a36be4e36465c3ea0ab6c2836bbd68c6d6ceb4ff"},"cell_type":"markdown","source":"![](https://i.imgur.com/85dZ0io.png)"},{"metadata":{"_uuid":"cac04a59e791529dde73160120f1872bd96e8e31"},"cell_type":"markdown","source":"## <a id='2.2.5'>2.2.5 Setting the parameters of CountVectorizer</a>"},{"metadata":{"_uuid":"7d2c9cf5818b4bd1c6fd938c1529b9bbb49bf575"},"cell_type":"markdown","source":"**For CountVectorizer**\nThis time, the stop words will not help much, because of the same high-frequency words, such as \"the\", \"to\", will equally frequent in both classes. If these stop words dominate both of the classes, I won't be able to have a meaningful result. So, I decided to remove stop words, and also will limit the max_features to 10,000 with countvectorizer."},{"metadata":{"_uuid":"943db60fb55e7f713aaa7009ed1d0956e7a96e33","collapsed":true,"trusted":false},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\n## Build Bag-Of-Words on train phrases\ncv = CountVectorizer(stop_words='english',max_features=10000)\ncv_train_features = cv.fit_transform(phrase_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b60fc6e40d006052752423fbc052c804b1241b70","collapsed":true,"trusted":false},"cell_type":"code","source":"\n# build TFIDF features on train reviews\ntv = TfidfVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1,2),\n                     sublinear_tf=True)\ntv_train_features = tv.fit_transform(phrase_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05d593d36171762a107bef9093a6e89a7572b8d8","collapsed":true,"trusted":false},"cell_type":"code","source":"# transform test reviews into features\ncv_test_features = cv.transform(phrase_test)\ntv_test_features = tv.transform(phrase_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e43b15f4f229c4641353cc1d276d35dc7b0805eb","trusted":false,"collapsed":true},"cell_type":"code","source":"print('BOW model:> Train features shape:', cv_train_features.shape, ' Test features shape:', cv_test_features.shape)\nprint('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97f74a489528db56beb7294a7bc0d3be344f8a58"},"cell_type":"markdown","source":"## <a id='2.3'>2.3 Model Training, Prediction and Performance Evaluation</a>"},{"metadata":{"_uuid":"fa45f6dc201478664f308baf8a0e5b6ee211bd42","collapsed":true,"trusted":false},"cell_type":"code","source":"####Evaluation metrics\n\n\nfrom sklearn import metrics\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.base import clone\nfrom sklearn.preprocessing import label_binarize\nfrom scipy import interp\nfrom sklearn.metrics import roc_curve, auc \n\n\ndef get_metrics(true_labels, predicted_labels):\n    \n    print('Accuracy:', np.round(\n                        metrics.accuracy_score(true_labels, \n                                               predicted_labels),\n                        4))\n    print('Precision:', np.round(\n                        metrics.precision_score(true_labels, \n                                               predicted_labels,\n                                               average='weighted'),\n                        4))\n    print('Recall:', np.round(\n                        metrics.recall_score(true_labels, \n                                               predicted_labels,\n                                               average='weighted'),\n                        4))\n    print('F1 Score:', np.round(\n                        metrics.f1_score(true_labels, \n                                               predicted_labels,\n                                               average='weighted'),\n                        4))\n                        \n\ndef train_predict_model(classifier, \n                        train_features, train_labels, \n                        test_features, test_labels):\n    # build model    \n    classifier.fit(train_features, train_labels)\n    # predict using model\n    predictions = classifier.predict(test_features) \n    return predictions    \n\n\ndef display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\n    \n    total_classes = len(classes)\n    level_labels = [total_classes*[0], list(range(total_classes))]\n\n    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels, \n                                  labels=classes)\n    cm_frame = pd.DataFrame(data=cm, \n                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n                                                  labels=level_labels), \n                            index=pd.MultiIndex(levels=[['Actual:'], classes], \n                                                labels=level_labels)) \n    print(cm_frame) \n    \ndef display_classification_report(true_labels, predicted_labels, classes=[1,0]):\n\n    report = metrics.classification_report(y_true=true_labels, \n                                           y_pred=predicted_labels, \n                                           labels=classes) \n    print(report)\n    \n    \n    \ndef display_model_performance_metrics(true_labels, predicted_labels, classes=[1,0]):\n    print('Model Performance metrics:')\n    print('-'*30)\n    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\n    print('\\nModel Classification report:')\n    print('-'*30)\n    display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels, \n                                  classes=classes)\n    print('\\nPrediction Confusion Matrix:')\n    print('-'*30)\n    display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, \n                             classes=classes)\n\n\ndef plot_model_decision_surface(clf, train_features, train_labels,\n                                plot_step=0.02, cmap=plt.cm.RdYlBu,\n                                markers=None, alphas=None, colors=None):\n    \n    if train_features.shape[1] != 2:\n        raise ValueError(\"X_train should have exactly 2 columnns!\")\n    \n    x_min, x_max = train_features[:, 0].min() - plot_step, train_features[:, 0].max() + plot_step\n    y_min, y_max = train_features[:, 1].min() - plot_step, train_features[:, 1].max() + plot_step\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n                         np.arange(y_min, y_max, plot_step))\n\n    clf_est = clone(clf)\n    clf_est.fit(train_features,train_labels)\n    if hasattr(clf_est, 'predict_proba'):\n        Z = clf_est.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,1]\n    else:\n        Z = clf_est.predict(np.c_[xx.ravel(), yy.ravel()])    \n    Z = Z.reshape(xx.shape)\n    cs = plt.contourf(xx, yy, Z, cmap=cmap)\n    \n    le = LabelEncoder()\n    y_enc = le.fit_transform(train_labels)\n    n_classes = len(le.classes_)\n    plot_colors = ''.join(colors) if colors else [None] * n_classes\n    label_names = le.classes_\n    markers = markers if markers else [None] * n_classes\n    alphas = alphas if alphas else [None] * n_classes\n    for i, color in zip(range(n_classes), plot_colors):\n        idx = np.where(y_enc == i)\n        plt.scatter(train_features[idx, 0], train_features[idx, 1], c=color,\n                    label=label_names[i], cmap=cmap, edgecolors='black', \n                    marker=markers[i], alpha=alphas[i])\n    plt.legend()\n    plt.show()\n\n\ndef plot_model_roc_curve(clf, features, true_labels, label_encoder=None, class_names=None):\n    \n    ## Compute ROC curve and ROC area for each class\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    if hasattr(clf, 'classes_'):\n        class_labels = clf.classes_\n    elif label_encoder:\n        class_labels = label_encoder.classes_\n    elif class_names:\n        class_labels = class_names\n    else:\n        raise ValueError('Unable to derive prediction classes, please specify class_names!')\n    n_classes = len(class_labels)\n    y_test = label_binarize(true_labels, classes=class_labels)\n    if n_classes == 2:\n        if hasattr(clf, 'predict_proba'):\n            prob = clf.predict_proba(features)\n            y_score = prob[:, prob.shape[1]-1] \n        elif hasattr(clf, 'decision_function'):\n            prob = clf.decision_function(features)\n            y_score = prob[:, prob.shape[1]-1]\n        else:\n            raise AttributeError(\"Estimator doesn't have a probability or confidence scoring system!\")\n        \n        fpr, tpr, _ = roc_curve(y_test, y_score)      \n        roc_auc = auc(fpr, tpr)\n        plt.plot(fpr, tpr, label='ROC curve (area = {0:0.2f})'\n                                 ''.format(roc_auc),\n                 linewidth=2.5)\n        \n    elif n_classes > 2:\n        if hasattr(clf, 'predict_proba'):\n            y_score = clf.predict_proba(features)\n        elif hasattr(clf, 'decision_function'):\n            y_score = clf.decision_function(features)\n        else:\n            raise AttributeError(\"Estimator doesn't have a probability or confidence scoring system!\")\n\n        for i in range(n_classes):\n            fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n            roc_auc[i] = auc(fpr[i], tpr[i])\n\n        ## Compute micro-average ROC curve and ROC area\n        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n        ## Compute macro-average ROC curve and ROC area\n        # First aggregate all false positive rates\n        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n        # Then interpolate all ROC curves at this points\n        mean_tpr = np.zeros_like(all_fpr)\n        for i in range(n_classes):\n            mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n        # Finally average it and compute AUC\n        mean_tpr /= n_classes\n        fpr[\"macro\"] = all_fpr\n        tpr[\"macro\"] = mean_tpr\n        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n        ## Plot ROC curves\n        plt.figure(figsize=(6, 4))\n        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n                 label='micro-average ROC curve (area = {0:0.2f})'\n                       ''.format(roc_auc[\"micro\"]), linewidth=3)\n\n        plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n                 label='macro-average ROC curve (area = {0:0.2f})'\n                       ''.format(roc_auc[\"macro\"]), linewidth=3)\n\n        for i, label in enumerate(class_labels):\n            plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n                                           ''.format(label, roc_auc[i]), \n                     linewidth=2, linestyle=':')\n    else:\n        raise ValueError('Number of classes should be atleast 2 or more')\n        \n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend(loc=\"lower right\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d49692a01a2f90d1eed7f068922223457331e37c","collapsed":true,"trusted":false},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier, LogisticRegression\n\nlr = LogisticRegression(penalty='l2', max_iter=100, C=1)\nsgd = SGDClassifier(loss='hinge', n_iter=100)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26a6a0833ca7a4b534c59c174a294e3fa8a1a769"},"cell_type":"markdown","source":"## <a id='2.3.1'>2.3.1 Logistic Regression model on CountVectorizer</a>"},{"metadata":{"_uuid":"4d4238110bcadf37dfcfd6f8da629ecee852934a","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"# Logistic Regression model on BOW features\nlr_bow_predictions = train_predict_model(classifier=lr, \n                                             train_features=cv_train_features, train_labels=sentiments_train,\n                                             test_features=cv_test_features, test_labels=sentiments_test)\ndisplay_model_performance_metrics(true_labels=sentiments_test, predicted_labels=lr_bow_predictions,\n                                      classes=[0,1,2,3,4])\n                                    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2fdd434362737e0c6b4a422c08f70c1933a35f09"},"cell_type":"markdown","source":"## <a id='2.3.2'>2.3.2 Logistic Regression model on TF-IDF features</a>\n"},{"metadata":{"_uuid":"d0eb869ed3d8fcc3cd46b46b4ca94494f651dfb1","trusted":false,"collapsed":true},"cell_type":"code","source":"# Logistic Regression model on TF-IDF features\nlr_tfidf_predictions = train_predict_model(classifier=lr, \n                                               train_features=tv_train_features, train_labels=sentiments_train,\n                                               test_features=tv_test_features, test_labels=sentiments_test)\ndisplay_model_performance_metrics(true_labels=sentiments_test, predicted_labels=lr_tfidf_predictions,\n                                      classes=[0,1,2,3,4])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a06c41270a16765371d55ea0867272e32c11c168"},"cell_type":"markdown","source":"\n## <a id='2.3.3'>2.3.3 SGD model on Countvectorizer</a>"},{"metadata":{"_uuid":"032a59ea317ffdf108ea44435c67a696776501ed","trusted":false,"collapsed":true},"cell_type":"code","source":"# SGD model on Countvectorizer\nsgd_bow_predictions = train_predict_model(classifier=sgd, \n                                             train_features=cv_train_features, train_labels=sentiments_train,\n                                             test_features=cv_test_features, test_labels=sentiments_test)\ndisplay_model_performance_metrics(true_labels=sentiments_test, predicted_labels=sgd_bow_predictions,\n                                      classes=[0,1,2,3,4])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea0ade40d9946875030cceaac360438cfdd4d578"},"cell_type":"markdown","source":"## <a id='2.3.4'>2.3.4 SGD model on TF-IDF</a>"},{"metadata":{"_uuid":"9a7f8c5ddad383a00bf9a6546b40887557490761","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"# SGD model on TF-IDF\nsgd_tfidf_predictions = train_predict_model(classifier=sgd, \n                                                train_features=tv_train_features, train_labels=sentiments_train,\n                                                test_features=tv_test_features, test_labels=sentiments_test)\ndisplay_model_performance_metrics(true_labels=sentiments_test, predicted_labels=sgd_tfidf_predictions,\n                                      classes=[0,1,2,3,4])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"72f5810f845994a8bdde673e0999a7f48291222a"},"cell_type":"markdown","source":"## <a id='2.3.5'>2.3.5 RandomForest model on TF-IDF</a>"},{"metadata":{"_uuid":"3f3217776a15885b48e28229b1b3cb73432dfc35","collapsed":true,"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b8473be4a644d5ab3d44cd033483dfae8b6f39a","collapsed":true,"trusted":false},"cell_type":"code","source":"# RandomForest model on TF-IDF\nrfc_tfidf_predictions = train_predict_model(classifier=rfc, \n                                                train_features=tv_train_features, train_labels=sentiments_train,\n                                                test_features=tv_test_features, test_labels=sentiments_test)\ndisplay_model_performance_metrics(true_labels=sentiments_test, predicted_labels=rfc_tfidf_predictions,\n                                      classes=[0,1,2,3,4])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0c5f92714acf7d2af782d4dd3ed2aa7ee8a8f689"},"cell_type":"markdown","source":"**Logistic Regression on TF-IDF is outperforming other machine learning algorithms**. \n\n"},{"metadata":{"_uuid":"e3fafb1a8a0c774eae7b8b28d78d356aaf2074b0","collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}