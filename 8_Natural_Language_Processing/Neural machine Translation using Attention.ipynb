{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralTranslation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mbl8A75__v8I",
        "outputId": "8048e549-6e2a-4e64-9c21-bcf0874da3ac"
      },
      "source": [
        "!wget http://www.manythings.org/anki/fra-eng.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-18 13:37:14--  http://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 172.67.186.54, 104.21.92.44, 2606:4700:3030::6815:5c2c, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|172.67.186.54|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6451478 (6.2M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip.1’\n",
            "\n",
            "fra-eng.zip.1       100%[===================>]   6.15M  8.56MB/s    in 0.7s    \n",
            "\n",
            "2021-08-18 13:37:14 (8.56 MB/s) - ‘fra-eng.zip.1’ saved [6451478/6451478]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzPknink_1AQ",
        "outputId": "8b6e6805-121f-4f60-f76e-1c7537150d72"
      },
      "source": [
        "!unzip fra-eng.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  fra-eng.zip\n",
            "replace _about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: _about.txt              \n",
            "replace fra.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: fra.txt                 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7ptvyA43oiM"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkAPN97F30_n"
      },
      "source": [
        "path_to_file=\"fra.txt\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4s201V54CMC"
      },
      "source": [
        "#to convert unicode to ascii\n",
        "def unicode_to_ascii(s):\n",
        "    text = s.encode('utf-8').decode('utf-8')\n",
        "    return text\n",
        "#preprcessing with turning specific characters\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "\n",
        "    w = w.strip()\n",
        "\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w    "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gb4NXbKd4EYG",
        "outputId": "7d4fde2f-a08b-4fd0-ec9c-c0ded8d27743"
      },
      "source": [
        "en_sentence = u\"Here's my account number.\"\n",
        "hn_sentence = u\"Voici mon numéro de compte.\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(hn_sentence))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> here's my account number . <end>\n",
            "<start> voici mon numéro de compte . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nhGXb-J4GXP"
      },
      "source": [
        "\"\"\"\n",
        "1.Remove the accents\n",
        "2.clean the sentences\n",
        "3.Return the sentense in this seq[English,French]\n",
        "\"\"\"\n",
        "def create_dataset(path,num_examples):\n",
        "    lines=io.open(path,encoding='UTF-8').read().strip().split('\\n')\n",
        "    \n",
        "    \n",
        "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "    \n",
        "    return zip(*word_pairs)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjGbquCG4ICa",
        "outputId": "00dbc17e-db52-4637-eaa0-e49619057933"
      },
      "source": [
        "en,fr,un = create_dataset(path_to_file,None)\n",
        "print(en[-1])\n",
        "print(fr[-1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> it may be impossible to get a completely error-free corpus due to the nature of this kind of collaborative effort . however , if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning , we might be able to minimize errors . <end>\n",
            "<start> il est peut-être impossible d'obtenir un corpus complètement dénué de fautes , étant donnée la nature de ce type d'entreprise collaborative . cependant , si nous encourageons les membres à produire des phrases dans leurs propres langues plutôt que d'expérimenter dans les langues qu'ils apprennent , nous pourrions être en mesure de réduire les erreurs . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owYZiyk24JgR"
      },
      "source": [
        "def tokenize(lang):\n",
        "    lang_tokenizer=tf.keras.preprocessing.text.Tokenizer(\n",
        "        filters=''\n",
        "    )\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    tensors = lang_tokenizer.texts_to_sequences(lang)\n",
        "    tensors = tf.keras.preprocessing.sequence.pad_sequences(tensors,padding='post')\n",
        "    \n",
        "    return tensors,lang_tokenizer"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EqU5NEC4Ln3"
      },
      "source": [
        "#defning the load datase function that will carry all the above three functions:)\n",
        "def load_dataset(path,num_examples=None):\n",
        "    inp_lang,targ_lang,unwanted = create_dataset(path,num_examples)\n",
        "    \n",
        "    input_tensor,input_language_tokenizer = tokenize(inp_lang)\n",
        "    target_tensor,targ_lang_tokenizer = tokenize(targ_lang)\n",
        "    \n",
        "    return input_tensor,target_tensor,input_language_tokenizer,targ_lang_tokenizer"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAEnunrL4NKr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de89542a-e8da-4fe7-aa98-6444efe7db4f"
      },
      "source": [
        "\"\"\"\n",
        "limiting the examples so that training can be faster\n",
        "there are >100000 sentences in data set to compile we are selecting\n",
        "50000 but compromising the the quality \n",
        "TODO change the num example to None in releasing patterns\n",
        "\"\"\"\n",
        "#taking 50000 samples for fast traning\n",
        "num_examples=50000\n",
        "input_tensor,target_tensor,inp_lang,targ_lang = load_dataset(path_to_file,num_examples)\n",
        "\n",
        "#max length of target tensors\n",
        "max_length_targ,max_length_inp = target_tensor.shape[1],input_tensor.shape[1]\n",
        "print(max_length_targ)\n",
        "print(max_length_inp)\n",
        "print(inp_lang.word_index)\n",
        "print(targ_lang)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18\n",
            "11\n",
            "{'<start>': 1, '<end>': 2, '.': 3, 'i': 4, '?': 5, 'you': 6, 'tom': 7, 'a': 8, 'is': 9, 'it': 10, 'the': 11, 'to': 12, \"i'm\": 13, 'he': 14, 'me': 15, 'this': 16, 'do': 17, 'was': 18, 'that': 19, 'are': 20, \"you're\": 21, 'we': 22, 'have': 23, \"don't\": 24, 'your': 25, 'my': 26, 'not': 27, \"it's\": 28, 'go': 29, '!': 30, 'did': 31, 'be': 32, 'can': 33, 'they': 34, 'like': 35, 'all': 36, 'no': 37, 'in': 38, \"we're\": 39, 'what': 40, 'she': 41, 'very': 42, 'of': 43, 'here': 44, 'want': 45, 'how': 46, 'get': 47, 'on': 48, \"i'll\": 49, \"that's\": 50, 'know': 51, 'need': 52, \"can't\": 53, 'up': 54, ',': 55, 'one': 56, 'for': 57, 'him': 58, 'out': 59, 'so': 60, 'at': 61, 'now': 62, 'good': 63, 'just': 64, 'were': 65, 'love': 66, 'come': 67, 'please': 68, 'help': 69, 'has': 70, 'too': 71, 'there': 72, 'why': 73, \"they're\": 74, 'look': 75, 'who': 76, 'got': 77, 'us': 78, \"he's\": 79, \"let's\": 80, 'will': 81, 'see': 82, 'take': 83, 'his': 84, 'am': 85, 'had': 86, 'let': 87, 'think': 88, 'stop': 89, 'with': 90, 'an': 91, 'home': 92, 'her': 93, \"didn't\": 94, 'back': 95, 'really': 96, 'happy': 97, 'give': 98, 'must': 99, 'right': 100, 'keep': 101, 'feel': 102, \"i've\": 103, 'try': 104, 'work': 105, 'them': 106, 'still': 107, 'where': 108, 'car': 109, 'made': 110, \"tom's\": 111, 'going': 112, 'may': 113, 'never': 114, 'alone': 115, 'leave': 116, \"what's\": 117, 'eat': 118, 'stay': 119, 'busy': 120, 'about': 121, 'looks': 122, 'french': 123, 'saw': 124, 'time': 125, \"isn't\": 126, 'again': 127, 'lost': 128, 'mary': 129, 'went': 130, 'dog': 131, 'does': 132, 'make': 133, 'well': 134, 'down': 135, 'big': 136, 'everyone': 137, 'ready': 138, \"won't\": 139, 'job': 140, 'some': 141, 'off': 142, 'hate': 143, 'felt': 144, 'should': 145, 'bad': 146, 'say': 147, 'today': 148, 'tell': 149, 'drink': 150, 'away': 151, 'could': 152, 'wait': 153, 'old': 154, 'tired': 155, 'much': 156, 'nice': 157, 'lot': 158, 'money': 159, 'book': 160, 'room': 161, 'call': 162, 'left': 163, 'talk': 164, 'hear': 165, 'our': 166, 'new': 167, 'wrong': 168, 'enough': 169, 'hurt': 170, 'been': 171, 'fun': 172, 'seems': 173, 'done': 174, \"we'll\": 175, 'said': 176, 'find': 177, 'sure': 178, 'way': 179, 'over': 180, 'day': 181, 'hard': 182, 'house': 183, \"i'd\": 184, \"where's\": 185, 'door': 186, 'everybody': 187, 'open': 188, 'came': 189, 'everything': 190, \"wasn't\": 191, 'safe': 192, 'mine': 193, 'late': 194, 'hope': 195, 'live': 196, 'kept': 197, 'bed': 198, 'likes': 199, 'gave': 200, 'speak': 201, 'read': 202, 'anyone': 203, 'more': 204, 'better': 205, 'friends': 206, 'yet': 207, 'both': 208, 'sorry': 209, 'ask': 210, 'easy': 211, 'idea': 212, 'would': 213, 'watch': 214, \"she's\": 215, 'turn': 216, 'found': 217, 'cold': 218, \"who's\": 219, 'nothing': 220, 'play': 221, 'broke': 222, 'funny': 223, 'friend': 224, 'when': 225, 'man': 226, 'water': 227, 'these': 228, 'something': 229, 'trust': 230, 'and': 231, 'knew': 232, 'sleep': 233, 'heard': 234, 'buy': 235, 'true': 236, 'long': 237, 'yours': 238, 'by': 239, 'ok': 240, 'died': 241, 'careful': 242, \"you've\": 243, 'loves': 244, 'took': 245, 'as': 246, 'run': 247, 'hurry': 248, 'life': 249, 'remember': 250, 'hungry': 251, 'nobody': 252, 'put': 253, 'great': 254, 'teacher': 255, 'show': 256, 'miss': 257, 'only': 258, 'sick': 259, 'doing': 260, \"there's\": 261, 'win': 262, 'crazy': 263, 'gone': 264, 'sit': 265, 'use': 266, 'fast': 267, 'told': 268, 'already': 269, 'coming': 270, 'best': 271, 'pay': 272, 'anybody': 273, 'cat': 274, 'school': 275, 'from': 276, 'angry': 277, 'wanted': 278, 'being': 279, 'dead': 280, 'knows': 281, 'problem': 282, 'yourself': 283, 'started': 284, 'anything': 285, 'kind': 286, 'close': 287, 'boy': 288, 'die': 289, 'forget': 290, 'believe': 291, \"aren't\": 292, 'mean': 293, 'called': 294, 'eyes': 295, 'tomorrow': 296, 'early': 297, 'name': 298, 'always': 299, 'any': 300, 'sing': 301, 'bring': 302, 'liked': 303, 'little': 304, 'sat': 305, 'tried': 306, 'looked': 307, 'answer': 308, 'quiet': 309, 'upset': 310, 'mother': 311, 'quit': 312, 'swim': 313, 'stupid': 314, 'bit': 315, 'won': 316, 'move': 317, 'start': 318, 'two': 319, 'talking': 320, 'afraid': 321, 'pretty': 322, 'ran': 323, 'care': 324, 'almost': 325, \"doesn't\": 326, 'if': 327, 'fine': 328, 'drive': 329, 'glad': 330, 'soon': 331, 'hot': 332, 'walk': 333, 'outside': 334, 'beer': 335, 'wants': 336, 'free': 337, 'food': 338, 'scared': 339, 'those': 340, 'sad': 341, 'mad': 342, 'married': 343, 'working': 344, 'met': 345, 'hat': 346, 'thanks': 347, 'drunk': 348, 'kids': 349, \"how's\": 350, \"we've\": 351, 'lie': 352, 'lucky': 353, 'shot': 354, 'change': 355, 'many': 356, 'hand': 357, 'myself': 358, 'used': 359, 'fell': 360, 'tall': 361, 'works': 362, 'last': 363, 'night': 364, 'once': 365, 'coffee': 366, 'perfect': 367, 'stand': 368, 'serious': 369, 'check': 370, 'bought': 371, 'shut': 372, 'first': 373, 'changed': 374, 'seat': 375, 'needs': 376, 'lunch': 377, 'handle': 378, 'touch': 379, 'study': 380, 'stopped': 381, 'fired': 382, 'tea': 383, 'ate': 384, 'enjoy': 385, 'light': 386, 'word': 387, 'listen': 388, 'around': 389, 'often': 390, 'thought': 391, 'finished': 392, 'hair': 393, 'write': 394, 'tv': 395, 'wine': 396, 'wish': 397, 'meet': 398, 'doctor': 399, 'key': 400, 'plan': 401, 'choice': 402, 'phone': 403, 'mind': 404, 'fish': 405, 'next': 406, 'seen': 407, 'forgot': 408, 'rest': 409, 'music': 410, 'books': 411, \"they'll\": 412, 'needed': 413, 'cool': 414, 'fat': 415, 'red': 416, 'hands': 417, 'bus': 418, 'father': 419, 'dinner': 420, 'quite': 421, 'into': 422, 'getting': 423, 'proud': 424, 'three': 425, 'loved': 426, 'son': 427, 'leaving': 428, 'maybe': 429, 'wife': 430, 'which': 431, 'born': 432, 'paid': 433, 'guess': 434, 'eating': 435, 'caught': 436, 'naive': 437, 'lose': 438, 'running': 439, 'guy': 440, 'sounds': 441, 'story': 442, 'rich': 443, 'clean': 444, 'someone': 445, 'dream': 446, 'agree': 447, 'ahead': 448, 'dogs': 449, 'follow': 450, 'inside': 451, 'luck': 452, 'weird': 453, 'liar': 454, 'kidding': 455, 'nervous': 456, 'quickly': 457, 'understand': 458, 'place': 459, 'such': 460, 'hit': 461, 'kiss': 462, 'asked': 463, 'reading': 464, 'whose': 465, 'boston': 466, 'seem': 467, 'lying': 468, 'girl': 469, \"it'll\": 470, 'invited': 471, 'confused': 472, 'hates': 473, 'else': 474, 'together': 475, 'bicycle': 476, 'cute': 477, 'game': 478, 'young': 479, 'asleep': 480, 'nuts': 481, 'happened': 482, 'crying': 483, \"you'll\": 484, 'own': 485, 'surprised': 486, 'arrived': 487, 'wake': 488, 'fix': 489, 'missed': 490, 'break': 491, 'milk': 492, 'cake': 493, 'song': 494, 'gun': 495, 'bag': 496, 'warned': 497, 'began': 498, 'shoes': 499, 'owe': 500, \"couldn't\": 501, 'than': 502, 'yesterday': 503, 'thing': 504, 'awesome': 505, 'drop': 506, 'helped': 507, 'smart': 508, 'strong': 509, 'deal': 510, 'child': 511, 'laughed': 512, 'another': 513, \"you'd\": 514, 'lied': 515, 'hold': 516, 'kill': 517, 'cry': 518, \"here's\": 519, 'worked': 520, 'cut': 521, 'excited': 522, 'might': 523, 'or': 524, \"one's\": 525, 'trouble': 526, 'calm': 527, 'real': 528, 'spoke': 529, 'alive': 530, 'sleepy': 531, 'joke': 532, 'writing': 533, 'things': 534, 'killed': 535, 'became': 536, 'people': 537, 'minute': 538, 'turned': 539, 'ill': 540, 'head': 541, 'worried': 542, 'broken': 543, 'family': 544, 'lives': 545, 'far': 546, 'thank': 547, 'waited': 548, 'walked': 549, 'sweet': 550, 'girls': 551, 'happen': 552, 'beautiful': 553, 'behind': 554, 'fault': 555, 'sister': 556, 'fire': 557, 'beat': 558, 'lazy': 559, 'catch': 560, 'lonely': 561, 'normal': 562, 'even': 563, 'fight': 564, 'news': 565, 'rain': 566, 'week': 567, 'sound': 568, 'sign': 569, 'guys': 570, 'face': 571, 'count': 572, 'pen': 573, 'singing': 574, 'different': 575, 'every': 576, 'clever': 577, 'cats': 578, 'jealous': 579, 'empty': 580, 'horse': 581, 'chance': 582, 'children': 583, 'cried': 584, 'smoke': 585, 'brave': 586, 'after': 587, 'trying': 588, 'smell': 589, 'team': 590, 'upstairs': 591, 'coat': 592, 'satisfied': 593, 'same': 594, 'movie': 595, 'fair': 596, 'wonderful': 597, 'box': 598, 'age': 599, 'saved': 600, 'heart': 601, 'boss': 602, 'blame': 603, 'small': 604, 'student': 605, 'keys': 606, 'prepared': 607, 'curious': 608, 'dance': 609, 'makes': 610, 'betrayed': 611, 'watching': 612, 'dark': 613, 'worry': 614, 'shocked': 615, 'looking': 616, 'sent': 617, 'mom': 618, 'trusted': 619, 'important': 620, 'danger': 621, 'terrible': 622, 'tie': 623, 'somebody': 624, 'tonight': 625, 'slow': 626, 'fit': 627, 'hurts': 628, 'tough': 629, 'drank': 630, 'silent': 631, 'send': 632, 'later': 633, 'amazing': 634, 'camera': 635, 'bike': 636, 'baby': 637, 'apple': 638, 'drinking': 639, 'person': 640, 'shy': 641, 'smiled': 642, 'yes': 643, 'joking': 644, 'list': 645, 'finally': 646, 'ride': 647, 'window': 648, 'boat': 649, 'hug': 650, 'lock': 651, 'full': 652, 'warn': 653, 'awful': 654, 'short': 655, 'idiot': 656, 'duty': 657, 'correct': 658, 'thirsty': 659, 'slowly': 660, 'arm': 661, 'followed': 662, 'polite': 663, 'god': 664, 'studying': 665, 'japanese': 666, 'rules': 667, 'rude': 668, 'failed': 669, 'honest': 670, 'fly': 671, 'excuse': 672, 'step': 673, 'wrote': 674, 'laugh': 675, 'bet': 676, 'fool': 677, 'act': 678, 'kid': 679, 'involved': 680, 'feels': 681, 'english': 682, 'nose': 683, 'prefer': 684, 'table': 685, 'mistake': 686, 'grab': 687, 'dirty': 688, 'tight': 689, 'blue': 690, 'bored': 691, 'dancing': 692, 'secret': 693, 'explain': 694, 'lawyer': 695, 'sleeping': 696, 'meant': 697, 'closed': 698, 'comes': 699, 'town': 700, 'seemed': 701, 'playing': 702, 'expect': 703, 'opened': 704, 'daughter': 705, 'talked': 706, 'terrific': 707, 'retired': 708, 'woke': 709, 'moving': 710, 'ignore': 711, 'vote': 712, 'unlucky': 713, 'winning': 714, 'party': 715, 'teach': 716, 'few': 717, 'impatient': 718, 'boring': 719, 'possible': 720, 'having': 721, 'oldest': 722, 'picture': 723, 'their': 724, 'trip': 725, 'message': 726, 'relax': 727, 'hang': 728, 'wet': 729, 'wise': 730, 'weak': 731, 'save': 732, 'faster': 733, 'relaxed': 734, 'cook': 735, 'awake': 736, 'cooking': 737, 'snow': 738, 'huge': 739, 'meat': 740, 'pain': 741, 'deserve': 742, 'slept': 743, 'pizza': 744, 'smiling': 745, 'cops': 746, 'exhausted': 747, 'listening': 748, 'laughing': 749, 'tree': 750, 'end': 751, 'believed': 752, 'chair': 753, 'dangerous': 754, 'order': 755, 'death': 756, 'feeling': 757, 'taking': 758, 'shirt': 759, 'welcome': 760, 'stayed': 761, 'ugly': 762, 'dying': 763, 'timid': 764, 'ours': 765, 'hired': 766, 'patient': 767, 'famous': 768, 'apologize': 769, 'shall': 770, 'kissed': 771, 'says': 772, 'shopping': 773, 'forward': 774, 'woman': 775, 'talented': 776, 'smells': 777, 'sense': 778, 'shower': 779, 'before': 780, 'point': 781, 'travel': 782, 'expensive': 783, 'jump': 784, 'begin': 785, 'join': 786, 'push': 787, 'high': 788, 'cheated': 789, 'blind': 790, 'then': 791, 'men': 792, 'skinny': 793, 'closer': 794, 'refused': 795, 'hey': 796, 'strange': 797, 'feet': 798, 'guilty': 799, 'downstairs': 800, 'second': 801, 'cannot': 802, 'truth': 803, 'brother': 804, 'parents': 805, 'choose': 806, 'drives': 807, 'class': 808, 'set': 809, 'watched': 810, 'dress': 811, 'map': 812, 'prove': 813, 'near': 814, 'cup': 815, 'glasses': 816, 'smarter': 817, 'bill': 818, 'longer': 819, 'deep': 820, 'warm': 821, 'air': 822, 'finish': 823, 'eggs': 824, 'driving': 825, 'touched': 826, 'date': 827, 'bath': 828, 'war': 829, 'decided': 830, 'black': 831, 'white': 832, 'matter': 833, \"everyone's\": 834, 'baked': 835, 'respect': 836, 'depressed': 837, 'tastes': 838, 'waiting': 839, 'interested': 840, 'continue': 841, 'train': 842, 'pencil': 843, 'speaks': 844, 'clothes': 845, 'smile': 846, 'agreed': 847, 'clear': 848, 'hero': 849, 'losing': 850, 'sharp': 851, 'dressed': 852, 'monday': 853, 'fake': 854, 'risk': 855, 'control': 856, 'clock': 857, 'line': 858, 'impressed': 859, 'moment': 860, 'breath': 861, 'throw': 862, 'rid': 863, 'park': 864, 'disgusting': 865, 'knife': 866, 'rather': 867, 'making': 868, 'escape': 869, 'hardly': 870, 'charge': 871, 'allowed': 872, 'under': 873, \"what're\": 874, 'wash': 875, 'refuse': 876, 'obey': 877, 'naked': 878, 'along': 879, 'poor': 880, 'shoot': 881, 'direct': 882, 'share': 883, 'cash': 884, 'bite': 885, 'mess': 886, 'apples': 887, 'learn': 888, 'law': 889, 'yelling': 890, 'cruel': 891, 'advice': 892, 'convinced': 893, 'raining': 894, 'business': 895, 'worth': 896, 'six': 897, 'plays': 898, 'brought': 899, 'students': 900, 'ordered': 901, 'ago': 902, 'decision': 903, 'without': 904, 'breakfast': 905, 'protect': 906, 'helps': 907, 'beg': 908, 'forgive': 909, 'drinks': 910, \"tom'll\": 911, 'boys': 912, 'hated': 913, 'also': 914, 'stunned': 915, 'trapped': 916, 'simple': 917, 'grow': 918, 'fighting': 919, 'innocent': 920, 'smoking': 921, 'bird': 922, 'survive': 923, 'pleased': 924, 'helping': 925, 'gift': 926, 'bell': 927, 'ball': 928, 'year': 929, 'wear': 930, 'holiday': 931, 'christmas': 932, 'carefully': 933, 'side': 934, \"haven't\": 935, 'totally': 936, 'enemy': 937, 'office': 938, 'mouth': 939, 'cost': 940, 'himself': 941, 'hi': 942, 'fantastic': 943, 'promise': 944, 'stuck': 945, 'pardon': 946, 'lovely': 947, 'pick': 948, 'friendly': 949, 'generous': 950, 'locked': 951, 'paper': 952, 'silly': 953, 'piano': 954, 'speaking': 955, 'missing': 956, 'special': 957, 'favor': 958, 'rope': 959, 'lit': 960, 'doors': 961, 'relieved': 962, 'homework': 963, 'swimming': 964, 'match': 965, 'bank': 966, 'cautious': 967, 'ideas': 968, 'eye': 969, 'letter': 970, 'other': 971, 'anymore': 972, 'low': 973, 'pull': 974, 'seated': 975, 'built': 976, 'aside': 977, 'decide': 978, 'creative': 979, 'grew': 980, 'chose': 981, 'useless': 982, 'horrible': 983, 'legs': 984, 'while': 985, 'unbelievable': 986, 'deny': 987, 'dry': 988, 'foolish': 989, 'fed': 990, 'fever': 991, 'summer': 992, 'nearly': 993, 'raise': 994, 'ambitious': 995, 'concerned': 996, 'gets': 997, 'fishing': 998, 'truck': 999, 'cookies': 1000, 'goal': 1001, 'afford': 1002, 'weight': 1003, 'question': 1004, 'flight': 1005, 'days': 1006, 'hide': 1007, 'attack': 1008, 'bald': 1009, 'dizzy': 1010, 'ruined': 1011, 'green': 1012, 'golf': 1013, 'soup': 1014, 'staying': 1015, 'hugged': 1016, 'confident': 1017, 'dumped': 1018, 'admire': 1019, 'plans': 1020, 'ears': 1021, 'part': 1022, 'skiing': 1023, 'taxi': 1024, 'allow': 1025, 'motivated': 1026, 'remain': 1027, 'lay': 1028, 'wind': 1029, 'dad': 1030, 'tennis': 1031, 'rang': 1032, 'regret': 1033, 'address': 1034, 'hello': 1035, 'stood': 1036, 'noticed': 1037, 'armed': 1038, 'ice': 1039, 'merciful': 1040, 'fear': 1041, 'surprise': 1042, 'loud': 1043, 'escaped': 1044, 'half': 1045, 'handled': 1046, 'proof': 1047, 'bleeding': 1048, 'outraged': 1049, 'positive': 1050, 'nearby': 1051, 'stole': 1052, 'pale': 1053, 'ring': 1054, 'wore': 1055, 'artist': 1056, 'screaming': 1057, 'weapon': 1058, 'offer': 1059, 'complain': 1060, 'eaten': 1061, 'harm': 1062, 'radio': 1063, 'desk': 1064, 'towel': 1065, 'hour': 1066, 'store': 1067, 'learned': 1068, 'happening': 1069, 'straight': 1070, 'fate': 1071, 'wasting': 1072, 'each': 1073, \"everybody's\": 1074, 'threatened': 1075, 'ever': 1076, 'showed': 1077, 'but': 1078, 'example': 1079, 'candles': 1080, 'runs': 1081, 'seriously': 1082, 'cares': 1083, 'doubt': 1084, 'panicked': 1085, 'screamed': 1086, 'accept': 1087, 'single': 1088, 'happens': 1089, 'cheap': 1090, 'comment': 1091, 'discreet': 1092, 'sell': 1093, 'moved': 1094, 'chicken': 1095, 'ship': 1096, 'morning': 1097, 'denied': 1098, 'annoying': 1099, 'enjoyed': 1100, 'waste': 1101, 'focused': 1102, 'sang': 1103, 'jobs': 1104, 'badly': 1105, 'blood': 1106, 'resilient': 1107, 'saying': 1108, 'test': 1109, 'standing': 1110, 'number': 1111, 'suit': 1112, 'floor': 1113, 'sold': 1114, 'attacked': 1115, 'helpful': 1116, 'glass': 1117, 'interesting': 1118, 'embarrassed': 1119, 'ridiculous': 1120, 'held': 1121, 'wallet': 1122, 'disappointed': 1123, 'guitar': 1124, 'others': 1125, 'rely': 1126, 'power': 1127, 'loudly': 1128, \"should've\": 1129, 'weekend': 1130, 'spotted': 1131, 'deaf': 1132, 'taste': 1133, 'hers': 1134, 'content': 1135, 'promised': 1136, 'amused': 1137, 'buying': 1138, 'cover': 1139, 'punctual': 1140, 'manage': 1141, 'scream': 1142, 'starved': 1143, 'unhappy': 1144, 'fact': 1145, 'leg': 1146, 'fall': 1147, 'romantic': 1148, 'wonder': 1149, 'singer': 1150, 'fearless': 1151, 'powerful': 1152, 'checked': 1153, 'closely': 1154, 'tense': 1155, 'beware': 1156, 'crime': 1157, 'tricked': 1158, 'soccer': 1159, 'note': 1160, 'played': 1161, 'available': 1162, 'insane': 1163, 'trusts': 1164, 'succeed': 1165, 'nonsense': 1166, 'grass': 1167, 'borrow': 1168, 'flowers': 1169, 'large': 1170, 'prices': 1171, 'price': 1172, 'road': 1173, 'country': 1174, 'evidence': 1175, 'noise': 1176, 'rent': 1177, 'handsome': 1178, 'seeing': 1179, 'changes': 1180, 'believes': 1181, 'yourselves': 1182, 'remained': 1183, 'sore': 1184, 'overreacting': 1185, 'fingers': 1186, 'surrounded': 1187, 'pants': 1188, 'productive': 1189, 'recognized': 1190, 'oh': 1191, 'birds': 1192, 'loosen': 1193, 'breathe': 1194, 'rush': 1195, 'fill': 1196, 'matters': 1197, 'pray': 1198, 'bother': 1199, 'thorough': 1200, 'burned': 1201, 'bread': 1202, 'fruit': 1203, 'dumb': 1204, 'fined': 1205, 'messed': 1206, 'ashamed': 1207, 'baffled': 1208, 'certain': 1209, 'healthy': 1210, 'sincere': 1211, 'doll': 1212, 'talks': 1213, 'drowned': 1214, 'resist': 1215, 'safely': 1216, 'paint': 1217, 'canadian': 1218, 'stubborn': 1219, 'unfair': 1220, 'walking': 1221, 'ended': 1222, 'staring': 1223, 'gold': 1224, 'scary': 1225, 'dating': 1226, 'loser': 1227, 'words': 1228, 'dreaming': 1229, 'feed': 1230, 'maid': 1231, 'rescued': 1232, 'terrified': 1233, 'leak': 1234, 'stuff': 1235, 'shoe': 1236, 'injured': 1237, 'cousins': 1238, 'enemies': 1239, 'college': 1240, 'vegetarian': 1241, 'brothers': 1242, 'taught': 1243, \"wouldn't\": 1244, 'able': 1245, 'truly': 1246, 'city': 1247, 'answered': 1248, 'times': 1249, 'stolen': 1250, 'teeth': 1251, 'immediately': 1252, 'umbrella': 1253, 'suddenly': 1254, 'ticket': 1255, 'headache': 1256, 'papers': 1257, 'band': 1258, 'church': 1259, \"they've\": 1260, 'whatever': 1261, 'hobby': 1262, 'familiar': 1263, 'raised': 1264, \"he'll\": 1265, 'exactly': 1266, 'opinion': 1267, 'accident': 1268, 'forced': 1269, 'anywhere': 1270, 'chosen': 1271, 'continued': 1272, 'stylish': 1273, 'okay': 1274, 'thin': 1275, 'ski': 1276, 'pass': 1277, 'fussy': 1278, 'quick': 1279, 'calls': 1280, 'admit': 1281, 'canceled': 1282, 'fixed': 1283, 'loaded': 1284, 'shaken': 1285, 'jerk': 1286, 'rice': 1287, 'rock': 1288, 'cars': 1289, 'washed': 1290, 'puzzled': 1291, 'objective': 1292, 'exciting': 1293, 'draw': 1294, 'cab': 1295, 'understood': 1296, 'genius': 1297, 'divorced': 1298, 'mistaken': 1299, 'pregnant': 1300, 'reserved': 1301, 'cancer': 1302, 'shame': 1303, 'garbage': 1304, 'obvious': 1305, 'goes': 1306, 'arguing': 1307, \"that'll\": 1308, 'dropped': 1309, 'ignored': 1310, 'thief': 1311, 'adorable': 1312, 'american': 1313, 'movies': 1314, 'volunteered': 1315, 'forgetful': 1316, 'pathetic': 1317, 'foot': 1318, \"nobody's\": 1319, 'peace': 1320, 'japan': 1321, 'wounded': 1322, 'bright': 1323, 'panting': 1324, 'diary': 1325, 'details': 1326, 'astonished': 1327, 'overworked': 1328, 'counting': 1329, 'blew': 1330, 'earlier': 1331, 'baseball': 1332, 'seldom': 1333, 'fresh': 1334, 'sounded': 1335, 'fabulous': 1336, 'sale': 1337, 'insurance': 1338, 'drill': 1339, 'beach': 1340, 'rarely': 1341, 'living': 1342, 'fortunate': 1343, \"joke's\": 1344, 'difficult': 1345, 'mistakes': 1346, 'briefly': 1347, 'heavy': 1348, 'weather': 1349, 'rained': 1350, 'downtown': 1351, 'served': 1352, 'meeting': 1353, 'arrive': 1354, 'master': 1355, 'volume': 1356, 'station': 1357, 'toilet': 1358, 'kitchen': 1359, 'mentally': 1360, 'burn': 1361, 'goodbye': 1362, 'brief': 1363, 'jumped': 1364, 'obeyed': 1365, 'phoned': 1366, 'odd': 1367, 'cheered': 1368, 'snowed': 1369, 'stinks': 1370, 'course': 1371, 'walks': 1372, 'disagree': 1373, 'sneaky': 1374, 'math': 1375, 'spring': 1376, 'split': 1377, 'memorize': 1378, 'return': 1379, 'shake': 1380, 'older': 1381, 'evil': 1382, 'twins': 1383, 'owns': 1384, 'doubts': 1385, 'sugar': 1386, 'grateful': 1387, 'hopeless': 1388, 'saint': 1389, 'rumor': 1390, 'snowing': 1391, 'quietly': 1392, 'dreams': 1393, 'uneasy': 1394, 'circle': 1395, 'gear': 1396, 'type': 1397, 'deserved': 1398, 'dislike': 1399, 'horses': 1400, 'plane': 1401, 'expecting': 1402, 'fan': 1403, 'powerless': 1404, 'worse': 1405, 'climbing': 1406, 'gambling': 1407, 'anyway': 1408, 'creepy': 1409, 'till': 1410, 'crafty': 1411, 'annoy': 1412, 'disappeared': 1413, 'uncle': 1414, 'keeps': 1415, 'spot': 1416, 'careless': 1417, 'devastated': 1418, 'reply': 1419, 'charming': 1420, 'stalling': 1421, 'cleaned': 1422, 'envious': 1423, 'police': 1424, 'studied': 1425, 'appreciate': 1426, 'voice': 1427, 'misunderstood': 1428, 'mayor': 1429, 'volunteer': 1430, 'calling': 1431, 'extroverted': 1432, 'resourceful': 1433, 'incredible': 1434, 'orange': 1435, 'sky': 1436, 'player': 1437, 'prize': 1438, 'flexible': 1439, 'reason': 1440, 'bowed': 1441, \"could've\": 1442, 'cap': 1443, 'computer': 1444, 'frightened': 1445, 'humiliated': 1446, 'sunday': 1447, 'shape': 1448, 'company': 1449, 'size': 1450, 'unnecessary': 1451, 'rejected': 1452, 'abandoned': 1453, 'problems': 1454, 'robbed': 1455, 'barely': 1456, 'emergency': 1457, 'none': 1458, 'lights': 1459, 'knocked': 1460, 'somewhere': 1461, 'painting': 1462, 'astute': 1463, 'burst': 1464, 'bless': 1465, 'crashed': 1466, 'hurried': 1467, 'cop': 1468, 'voted': 1469, 'facts': 1470, 'envy': 1471, 'exercise': 1472, 'greedy': 1473, 'strict': 1474, 'cheerful': 1475, 'ruthless': 1476, 'gas': 1477, 'popular': 1478, 'psychic': 1479, 'card': 1480, 'coughed': 1481, 'evening': 1482, 'apologized': 1483, 'chess': 1484, 'freezing': 1485, 'reliable': 1486, 'thrilled': 1487, 'digging': 1488, 'command': 1489, 'stoned': 1490, 'translate': 1491, 'fooled': 1492, 'sells': 1493, 'demented': 1494, 'bananas': 1495, 'winter': 1496, 'copy': 1497, 'contented': 1498, 'flattered': 1499, 'intrigued': 1500, 'personal': 1501, 'attention': 1502, 'clearly': 1503, 'doctors': 1504, 'thinks': 1505, 'mail': 1506, 'cows': 1507, 'van': 1508, 'scolded': 1509, 'parties': 1510, 'secrets': 1511, 'spiders': 1512, 'dessert': 1513, 'punished': 1514, 'file': 1515, 'guide': 1516, 'against': 1517, 'contagious': 1518, 'successful': 1519, 'common': 1520, 'illegal': 1521, 'present': 1522, 'solution': 1523, 'ten': 1524, 'adventurous': 1525, 'expected': 1526, 'sons': 1527, 'alarmed': 1528, 'unambitious': 1529, 'unusual': 1530, 'sour': 1531, 'practice': 1532, 'smaller': 1533, 'bottle': 1534, 'repeat': 1535, 'alarm': 1536, 'lake': 1537, 'salt': 1538, 'forgiven': 1539, 'dishes': 1540, 'teachers': 1541, 'prisoners': 1542, 'teaches': 1543, 'traveling': 1544, 'chocolate': 1545, 'america': 1546, 'cards': 1547, 'windows': 1548, 'promoted': 1549, 'entered': 1550, 'murdered': 1551, 'five': 1552, 'add': 1553, 'weapons': 1554, 'knees': 1555, 'style': 1556, 'abroad': 1557, 'pushed': 1558, \"shouldn't\": 1559, 'wreck': 1560, 'extremely': 1561, 'wild': 1562, 'leader': 1563, 'hospital': 1564, 'lived': 1565, 'mood': 1566, 'lots': 1567, 'probably': 1568, 'wearing': 1569, 'either': 1570, 'alcohol': 1571, 'crossed': 1572, 'connected': 1573, 'drove': 1574, 'rested': 1575, 'marry': 1576, 'lies': 1577, 'pack': 1578, 'prudent': 1579, 'carry': 1580, 'destroy': 1581, 'hung': 1582, 'flinched': 1583, 'twin': 1584, 'hiding': 1585, 'thirty': 1586, 'nap': 1587, 'notes': 1588, 'cooked': 1589, 'taxes': 1590, 'struggled': 1591, 'attend': 1592, 'finicky': 1593, 'selfish': 1594, 'through': 1595, 'wealthy': 1596, 'legal': 1597, 'flat': 1598, 'trap': 1599, 'numb': 1600, 'dope': 1601, 'beef': 1602, 'rifle': 1603, 'kicked': 1604, 'arrogant': 1605, 'easily': 1606, 'women': 1607, 'sue': 1608, 'coward': 1609, 'paris': 1610, 'offended': 1611, 'starving': 1612, 'identify': 1613, 'ink': 1614, 'body': 1615, 'blow': 1616, 'gamble': 1617, 'tokyo': 1618, 'pie': 1619, 'ought': 1620, 'outrank': 1621, 'surrendered': 1622, 'pool': 1623, 'songs': 1624, 'delighted': 1625, 'desperate': 1626, 'miserable': 1627, 'diet': 1628, 'skeptical': 1629, 'coach': 1630, '2:30': 1631, 'unlocked': 1632, 'proceed': 1633, 'model': 1634, 'scares': 1635, 'trees': 1636, 'growing': 1637, 'related': 1638, \"what'll\": 1639, 'judge': 1640, 'guns': 1641, 'actor': 1642, 'slapped': 1643, 'wide': 1644, 'arrested': 1645, 'history': 1646, 'oysters': 1647, 'animals': 1648, 'answers': 1649, 'likely': 1650, 'beauty': 1651, 'similar': 1652, 'harmless': 1653, 'escaping': 1654, 'congratulations': 1655, 'stared': 1656, 'husband': 1657, 'salad': 1658, 'tongue': 1659, 'resign': 1660, 'returned': 1661, \"we'd\": 1662, 'hammer': 1663, 'zoo': 1664, 'addict': 1665, 'comfortable': 1666, 'vacation': 1667, 'river': 1668, 'impossible': 1669, 'its': 1670, 'gray': 1671, 'sea': 1672, 'acted': 1673, 'agitated': 1674, 'wears': 1675, 'street': 1676, 'mention': 1677, 'juice': 1678, 'stairs': 1679, 'noon': 1680, 'debt': 1681, 'receipt': 1682, 'candle': 1683, 'month': 1684, 'frustrated': 1685, 'cousin': 1686, 'washing': 1687, 'necessary': 1688, 'race': 1689, 'complicated': 1690, 'drug': 1691, 'sofa': 1692, 'tire': 1693, 'socks': 1694, 'wisely': 1695, \"someone's\": 1696, 'sports': 1697, 'conceited': 1698, 'courteous': 1699, \"weren't\": 1700, 'advance': 1701, \"everything's\": 1702, 'incompetent': 1703, 'skipped': 1704, 'hotel': 1705, 'discouraged': 1706, 'overwhelmed': 1707, 'sort': 1708, 'world': 1709, 'sight': 1710, 'bothering': 1711, 'attractive': 1712, 'fashionable': 1713, 'giggled': 1714, 'shop': 1715, 'courageous': 1716, 'responsible': 1717, 'banged': 1718, 'memory': 1719, 'confirm': 1720, 'report': 1721, 'nine': 1722, 'suggest': 1723, 'infected': 1724, 'fascinating': 1725, 'accepted': 1726, 'tears': 1727, 'gently': 1728, 'sweater': 1729, 'service': 1730, 'perfectly': 1731, 'sidetracked': 1732, 'skip': 1733, 'nodded': 1734, 'tidy': 1735, 'west': 1736, 'above': 1737, 'swam': 1738, 'north': 1739, 'chuckled': 1740, 'art': 1741, 'listened': 1742, 'biased': 1743, 'safer': 1744, 'cheat': 1745, 'yelled': 1746, 'harder': 1747, 'fail': 1748, 'cancel': 1749, 'argue': 1750, 'resigned': 1751, 'disagreed': 1752, 'engaged': 1753, 'smashed': 1754, 'teasing': 1755, 'rule': 1756, 'means': 1757, 'fainted': 1758, 'guessed': 1759, 'caution': 1760, 'pity': 1761, 'guest': 1762, 'liars': 1763, 'games': 1764, 'jokes': 1765, 'rose': 1766, 'smelled': 1767, 'risks': 1768, 'twice': 1769, 'bluffing': 1770, 'homesick': 1771, 'curse': 1772, 'spy': 1773, 'focus': 1774, 'overslept': 1775, 'shock': 1776, 'years': 1777, 'passed': 1778, 'scare': 1779, 'eats': 1780, 'belong': 1781, 'caused': 1782, 'despise': 1783, 'freaked': 1784, 'elected': 1785, 'clue': 1786, 'orders': 1787, 'cheese': 1788, 'insist': 1789, 'tempted': 1790, 'disgusted': 1791, 'takes': 1792, 'saturday': 1793, 'treat': 1794, 'worrying': 1795, 'differ': 1796, 'adores': 1797, 'misled': 1798, 'remembers': 1799, 'respond': 1800, 'group': 1801, 'hint': 1802, 'birthday': 1803, 'flew': 1804, 'beard': 1805, 'video': 1806, 'outgoing': 1807, 'prison': 1808, 'sisters': 1809, 'sun': 1810, 'painted': 1811, 'usually': 1812, 'revenge': 1813, 'speechless': 1814, 'tooth': 1815, 'roses': 1816, 'awkward': 1817, 'whistling': 1818, \"today's\": 1819, 'talent': 1820, 'remembered': 1821, 'troubled': 1822, 'blast': 1823, 'action': 1824, 'taken': 1825, 'excused': 1826, 'interrupt': 1827, 'partner': 1828, 'notice': 1829, 'football': 1830, 'misjudged': 1831, 'tissue': 1832, 'horrified': 1833, 'kidnapped': 1834, 'defenseless': 1835, 'introverted': 1836, 'trustworthy': 1837, 'soft': 1838, 'negotiate': 1839, \"mary's\": 1840, 'remove': 1841, 'reads': 1842, 'exit': 1843, 'sipped': 1844, 'front': 1845, 'toes': 1846, 'giving': 1847, 'separated': 1848, 'startled': 1849, 'barking': 1850, 'fuse': 1851, 'blown': 1852, 'top': 1853, 'drawer': 1854, 'costs': 1855, 'grown': 1856, 'unconscious': 1857, 'embarrassing': 1858, 'politely': 1859, 'novel': 1860, 'egg': 1861, 'recommend': 1862, 'criminal': 1863, 'complaining': 1864, 'studies': 1865, 'hilarious': 1866, 'selected': 1867, 'soldiers': 1868, 'lady': 1869, 'talkative': 1870, 'arms': 1871, 'pens': 1872, 'trusting': 1873, 'sandwich': 1874, 'hook': 1875, 'ground': 1876, 'color': 1877, 'schedule': 1878, 'everywhere': 1879, 'photo': 1880, 'pulled': 1881, 'neighbor': 1882, 'heavily': 1883, 'no-brainer': 1884, 'following': 1885, 'disturbing': 1886, 'handy': 1887, 'market': 1888, 'damage': 1889, 'deserves': 1890, 'suspicious': 1891, 'changing': 1892, 'jacket': 1893, 'prisoner': 1894, 'chinese': 1895, 'completely': 1896, 'roommate': 1897, 'blonde': 1898, 'challenge': 1899, 'kissing': 1900, 'boyfriend': 1901, 'fooling': 1902, 'learning': 1903, 'coincidence': 1904, 'potatoes': 1905, 'traveled': 1906, 'frequently': 1907, 'enjoying': 1908, 'stranger': 1909, 'exam': 1910, 'eyesight': 1911, 'apartment': 1912, 'choices': 1913, 'perhaps': 1914, 'poem': 1915, 'conscientious': 1916, 'removed': 1917, 'suspect': 1918, 'bury': 1919, 'stink': 1920, 'loyal': 1921, 'sober': 1922, 'sand': 1923, 'cooks': 1924, 'unlock': 1925, 'aboard': 1926, 'fret': 1927, 'survived': 1928, 'threw': 1929, 'begun': 1930, 'replace': 1931, 'alert': 1932, 'sec': 1933, 'panic': 1934, 'eight': 1935, 'confessed': 1936, 'lips': 1937, 'succeeded': 1938, 'dieting': 1939, 'falling': 1940, 'frantic': 1941, 'furious': 1942, 'psyched': 1943, 'pipe': 1944, 'cloudy': 1945, 'lift': 1946, 'timing': 1947, 'describe': 1948, 'snack': 1949, 'chased': 1950, 'lousy': 1951, 'opera': 1952, 'star': 1953, 'suppose': 1954, 'member': 1955, 'addicted': 1956, 'faithful': 1957, 'grounded': 1958, 'obedient': 1959, 'complex': 1960, 'genuine': 1961, 'hideous': 1962, 'lead': 1963, 'pigs': 1964, 'recess': 1965, 'approved': 1966, 'bores': 1967, 'pig': 1968, 'mature': 1969, 'included': 1970, 'reasonable': 1971, 'kite': 1972, 'ham': 1973, 'delicious': 1974, 'borrowed': 1975, 'steal': 1976, 'fought': 1977, 'visa': 1978, 'salmon': 1979, 'hiking': 1980, 'nature': 1981, 'tourist': 1982, 'impulsive': 1983, 'uninsured': 1984, 'relief': 1985, 'bragging': 1986, 'cow': 1987, 'vulgar': 1988, 'joined': 1989, 'adopted': 1990, 'grumpy': 1991, 'avoid': 1992, 'form': 1993, 'gossip': 1994, 'nauseous': 1995, 'realize': 1996, 'data': 1997, 'insulted': 1998, 'welcomed': 1999, 'undressing': 2000, 'forgotten': 2001, 'bargain': 2002, 'lend': 2003, 'larger': 2004, 'prepare': 2005, 'meter': 2006, 'intervened': 2007, 'precise': 2008, 'spoiled': 2009, 'shook': 2010, 'prude': 2011, 'brush': 2012, 'meal': 2013, 'mercy': 2014, 'dreamer': 2015, 'mentioned': 2016, 'cheating': 2017, 'writes': 2018, 'violence': 2019, 'teaching': 2020, 'army': 2021, 'experienced': 2022, 'training': 2023, 'captain': 2024, 'manager': 2025, 'breathing': 2026, 'irrelevant': 2027, 'windy': 2028, 'niece': 2029, 'neither': 2030, 'peel': 2031, 'calmed': 2032, 'roll': 2033, 'silk': 2034, 'moon': 2035, 'deranged': 2036, 'suffer': 2037, 'repulsive': 2038, 'freedom': 2039, 'pleasure': 2040, 'punched': 2041, 'disloyal': 2042, 'crack': 2043, 'cross': 2044, 'speech': 2045, 'distracted': 2046, 'pajamas': 2047, 'france': 2048, 'sweat': 2049, 'knee': 2050, 'request': 2051, 'coughing': 2052, 'australia': 2053, 'bar': 2054, 'victorious': 2055, 'fbi': 2056, 'stressed': 2057, 'volunteering': 2058, 'belongs': 2059, 'trick': 2060, 'effective': 2061, 'repair': 2062, 'mars': 2063, 'responded': 2064, 'italy': 2065, 'search': 2066, 'rough': 2067, 'guard': 2068, 'reluctant': 2069, 'texting': 2070, 'silently': 2071, 'belt': 2072, 'younger': 2073, 'traitor': 2074, 'thieves': 2075, 'screw': 2076, 'earth': 2077, 'brown': 2078, 'sailor': 2079, 'lightly': 2080, '2013': 2081, 'sometimes': 2082, 'aware': 2083, 'garden': 2084, 'uncomfortable': 2085, 'depends': 2086, 'gained': 2087, 'beginner': 2088, 'turning': 2089, 'wall': 2090, 'system': 2091, 'determined': 2092, 'crawling': 2093, 'visit': 2094, 'terms': 2095, 'hurting': 2096, 'lacks': 2097, 'filthy': 2098, 'jail': 2099, 'hid': 2100, 'imagination': 2101, 'hours': 2102, 'letting': 2103, 'seven': 2104, 'forever': 2105, 'frozen': 2106, 'telephone': 2107, 'treatment': 2108, 'bruised': 2109, 'firm': 2110, 'button': 2111, 'embarrass': 2112, 'vegetables': 2113, 'piece': 2114, 'medal': 2115, 'hearing': 2116, 'faith': 2117, 'highly': 2118, 'tattoo': 2119, 'risked': 2120, 'vacant': 2121, 'disturbed': 2122, 'negative': 2123, 'become': 2124, 'snickering': 2125, 'allergic': 2126, 'opportunistic': 2127, 'double-parked': 2128, 'inconsiderate': 2129, 'temperamental': 2130, 'unable': 2131, 'reminded': 2132, 'wow': 2133, 'duck': 2134, 'waved': 2135, 'aim': 2136, 'tries': 2137, 'east': 2138, 'chubby': 2139, 'fad': 2140, 'cds': 2141, 'sensible': 2142, 'watchful': 2143, 'comfort': 2144, 'coin': 2145, 'buried': 2146, 'beans': 2147, 'jazz': 2148, 'recovered': 2149, 'jittery': 2150, 'sloshed': 2151, 'stuffed': 2152, 'unarmed': 2153, 'ironic': 2154, 'poison': 2155, 'urgent': 2156, 'plants': 2157, 'fox': 2158, 'grim': 2159, 'realistic': 2160, 'donut': 2161, 'poet': 2162, 'faint': 2163, 'giddy': 2164, 'dancer': 2165, 'farmer': 2166, 'adult': 2167, 'drowning': 2168, 'gullible': 2169, 'thinking': 2170, 'wolf': 2171, 'noisy': 2172, 'sued': 2173, 'pushing': 2174, 'questions': 2175, 'respectful': 2176, 'skate': 2177, 'wins': 2178, 'cookie': 2179, 'hole': 2180, 'contributed': 2181, 'garlic': 2182, 'yellow': 2183, 'object': 2184, 'support': 2185, 'behave': 2186, 'committed': 2187, 'observant': 2188, 'painful': 2189, 'apart': 2190, 'active': 2191, 'suits': 2192, 'texted': 2193, 'annoyed': 2194, 'packing': 2195, 'violent': 2196, 'page': 2197, 'lawyers': 2198, 'sinking': 2199, 'racist': 2200, '30': 2201, 'mug': 2202, 'writer': 2203, 'vision': 2204, 'turtles': 2205, 'protest': 2206, 'cleaning': 2207, 'testify': 2208, 'cooperate': 2209, 'optimistic': 2210, 'winner': 2211, 'untalented': 2212, 'remarried': 2213, 'miracle': 2214, 'nurse': 2215, 'teased': 2216, 'appeared': 2217, 'logical': 2218, 'rubbish': 2219, 'bites': 2220, 'fork': 2221, 'moron': 2222, 'sitting': 2223, 'sobbing': 2224, 'calmly': 2225, 'homeless': 2226, 'couple': 2227, 'helpless': 2228, 'wipe': 2229, 'balls': 2230, 'boil': 2231, 'rub': 2232, 'signed': 2233, 'photogenic': 2234, 'id': 2235, 'unfortunate': 2236, 'alibi': 2237, 'sword': 2238, 'shave': 2239, 'bills': 2240, 'witness': 2241, 'attorney': 2242, 'celebrating': 2243, 'open-minded': 2244, 'natural': 2245, 'tasted': 2246, 'acceptable': 2247, 'inevitable': 2248, 'loan': 2249, 'narrow': 2250, 'jeans': 2251, 'leaves': 2252, 'tied': 2253, 'breather': 2254, 'childish': 2255, 'immature': 2256, 'understands': 2257, 'lack': 2258, 'rented': 2259, 'fixing': 2260, 'organized': 2261, 'survivors': 2262, \"what've\": 2263, 'blushing': 2264, 'less': 2265, 'accidents': 2266, 'catholic': 2267, 'snakes': 2268, 'concentrate': 2269, 'dial': 2270, 'purpose': 2271, 'useful': 2272, 'garage': 2273, 'oranges': 2274, 'gentleman': 2275, \"how're\": 2276, 'dumbfounded': 2277, 'trout': 2278, 'halloween': 2279, 'surprises': 2280, 'journal': 2281, 'led': 2282, 'require': 2283, 'retire': 2284, 'aggressive': 2285, 'farm': 2286, 'between': 2287, 'enthusiastic': 2288, 'fairly': 2289, 'ignoring': 2290, 'killing': 2291, 'threat': 2292, 'rainy': 2293, 'sunny': 2294, 'gain': 2295, 'shots': 2296, 'issue': 2297, 'monster': 2298, 'mystery': 2299, 'indignant': 2300, 'perplexed': 2301, 'sarcastic': 2302, 'stepped': 2303, 'released': 2304, 'demand': 2305, 'theory': 2306, 'unique': 2307, 'obnoxious': 2308, 'policeman': 2309, 'threaten': 2310, 'land': 2311, 'raking': 2312, 'graduate': 2313, 'regrets': 2314, 'skirt': 2315, 'earring': 2316, 'sunrise': 2317, 'victory': 2318, 'apology': 2319, 'outnumbered': 2320, 'gym': 2321, \"would've\": 2322, 'worker': 2323, 'total': 2324, 'awfully': 2325, 'unexpected': 2326, 'dictionary': 2327, 'starting': 2328, \"something's\": 2329, 'wood': 2330, 'driver': 2331, 'offensive': 2332, \"hasn't\": 2333, 'handcuffed': 2334, 'patiently': 2335, 'cowards': 2336, 'happiness': 2337, 'asking': 2338, 'target': 2339, 'registered': 2340, 'using': 2341, 'robots': 2342, 'traffic': 2343, 'overconfident': 2344, 'advise': 2345, 'comic': 2346, 'couch': 2347, 'spilled': 2348, 'stiff': 2349, 'unavoidable': 2350, 'corner': 2351, 'strive': 2352, 'packed': 2353, 'case': 2354, 'cleared': 2355, 'christians': 2356, 'unreliable': 2357, 'bigger': 2358, 'louder': 2359, 'experience': 2360, \"when's\": 2361, 'avoiding': 2362, 'seats': 2363, 'loose': 2364, 'girlfriend': 2365, 'assistant': 2366, 'received': 2367, 'german': 2368, 'building': 2369, 'debate': 2370, 'trousers': 2371, 'knives': 2372, 'intolerable': 2373, 'weeks': 2374, 'groggy': 2375, 'hill': 2376, 'stopping': 2377, 'difference': 2378, 'stove': 2379, 'holding': 2380, 'purse': 2381, 'cheers': 2382, 'knit': 2383, 'dozed': 2384, 'snore': 2385, 'beats': 2386, 'speed': 2387, 'chill': 2388, 'film': 2389, 'cringed': 2390, 'exhaled': 2391, 'seize': 2392, \"who'll\": 2393, 'south': 2394, 'tragic': 2395, 'squinted': 2396, 'baking': 2397, 'paying': 2398, 'magic': 2399, 'cd': 2400, 'jesus': 2401, 'wept': 2402, 'lighten': 2403, 'flies': 2404, 'agrees': 2405, 'winced': 2406, 'stare': 2407, 'guts': 2408, 'nerd': 2409, 'taller': 2410, 'mice': 2411, 'hesitated': 2412, 'snickered': 2413, 'third': 2414, 'medic': 2415, 'blessed': 2416, 'yen': 2417, 'scam': 2418, 'across': 2419, 'burns': 2420, 'settle': 2421, 'blushed': 2422, 'lame': 2423, 'neat': 2424, 'listens': 2425, 'drew': 2426, 'attentive': 2427, 'spoon': 2428, 'bigot': 2429, 'honey': 2430, 'sushi': 2431, 'trips': 2432, 'space': 2433, 'rugby': 2434, 'rational': 2435, 'shooting': 2436, 'truthful': 2437, 'deer': 2438, 'vague': 2439, 'bedtime': 2440, \"school's\": 2441, 'trash': 2442, \"this'll\": 2443, 'nerve': 2444, 'bossy': 2445, \"ain't\": 2446, 'futon': 2447, 'supportive': 2448, 'security': 2449, 'pitch': 2450, 'deeply': 2451, 'skating': 2452, 'toys': 2453, 'pinched': 2454, 'admired': 2455, 'muslim': 2456, 'runner': 2457, 'cough': 2458, 'tenure': 2459, 'lamp': 2460, 'violin': 2461, 'rescheduled': 2462, 'plumber': 2463, 'dedicated': 2464, 'expert': 2465, 'sensitive': 2466, 'shivering': 2467, 'flaw': 2468, 'gorgeous': 2469, 'midnight': 2470, 'outdated': 2471, 'unlikely': 2472, \"name's\": 2473, 'seal': 2474, 'beside': 2475, 'ease': 2476, 'shouting': 2477, 'sweep': 2478, 'sheep': 2479, 'online': 2480, 'rushed': 2481, 'snoring': 2482, 'qualified': 2483, 'hiring': 2484, 'gate': 2485, 'contact': 2486, 'recycle': 2487, 'counts': 2488, 'gambler': 2489, 'banana': 2490, 'corrected': 2491, 'flunk': 2492, 'honored': 2493, 'carrots': 2494, 'flu': 2495, 'plead': 2496, 'puppy': 2497, 'justice': 2498, 'detained': 2499, 'diplomatic': 2500, 'fascinated': 2501, 'overweight': 2502, 'unemployed': 2503, 'bear': 2504, 'planned': 2505, 'snowman': 2506, 'beyond': 2507, 'brand': 2508, 'redundant': 2509, 'risky': 2510, 'science': 2511, 'choked': 2512, 'swims': 2513, 'snap': 2514, 'barked': 2515, 'roof': 2516, 'leaks': 2517, 'annoys': 2518, 'complained': 2519, 'crook': 2520, 'unmoved': 2521, 'volunteers': 2522, 'brain': 2523, 'guests': 2524, 'quitting': 2525, 'retiring': 2526, 'stronger': 2527, 'tragedy': 2528, 'screwed': 2529, 'capsized': 2530, 'ghost': 2531, 'round': 2532, 'bees': 2533, 'dismissed': 2534, 'insult': 2535, 'overdo': 2536, 'prayed': 2537, 'fasten': 2538, 'bottom': 2539, 'acts': 2540, 'painter': 2541, 'surfing': 2542, 'lad': 2543, \"how'd\": 2544, 'abhor': 2545, 'tomatoes': 2546, 'showered': 2547, 'lent': 2548, 'supper': 2549, 'helmet': 2550, 'relied': 2551, 'parrot': 2552, '10': 2553, 'solve': 2554, 'detective': 2555, 'engineer': 2556, 'cracking': 2557, 'heartbroken': 2558, 'interfering': 2559, 'ammo': 2560, 'persevering': 2561, 'modest': 2562, 'shortcut': 2563, 'impressive': 2564, 'season': 2565, 'terrifying': 2566, 'celebrate': 2567, \"nothing's\": 2568, 'october': 2569, 'forgave': 2570, 'typist': 2571, 'assertive': 2572, 'silence': 2573, 'steady': 2574, 'chances': 2575, 'damp': 2576, 'cure': 2577, 'blocked': 2578, 'feared': 2579, 'greeted': 2580, 'visited': 2581, 'gifts': 2582, 'friday': 2583, 'rabbits': 2584, 'dejected': 2585, 'giggling': 2586, 'pleasant': 2587, 'panicking': 2588, 'suffered': 2589, 'canadians': 2590, 'neighbors': 2591, 'disaster': 2592, 'comb': 2593, 'naughty': 2594, '5': 2595, 'apply': 2596, 'golfer': 2597, 'cane': 2598, 'climb': 2599, 'bridge': 2600, 'wire': 2601, 'joy': 2602, 'hunting': 2603, 'hunt': 2604, 'arabic': 2605, 'struck': 2606, 'heaven': 2607, 'sneezed': 2608, 'pork': 2609, 'hybrid': 2610, 'empowered': 2611, 'website': 2612, 'toothache': 2613, 'ocean': 2614, 'view': 2615, 'planted': 2616, 'disorganized': 2617, 'heading': 2618, 'homeschooled': 2619, 'drawn': 2620, 'informed': 2621, 'compromise': 2622, 'planet': 2623, 'pulse': 2624, 'stung': 2625, 'pets': 2626, 'article': 2627, 'defeated': 2628, 'spit': 2629, 'showing': 2630, 'touching': 2631, 'ludicrous': 2632, 'limit': 2633, 'tank': 2634, \"water's\": 2635, 'deceived': 2636, 'relaxing': 2637, 'glanced': 2638, 'excellent': 2639, 'considered': 2640, 'depend': 2641, 'pictures': 2642, 'visitors': 2643, 'dozing': 2644, 'owners': 2645, 'steps': 2646, 'arrest': 2647, 'build': 2648, 'pet': 2649, 'fuss': 2650, 'goodnight': 2651, 'deals': 2652, 'vase': 2653, 'grabbed': 2654, 'scientist': 2655, 'forty': 2656, 'travels': 2657, 'rapidly': 2658, 'ballistic': 2659, 'journalist': 2660, 'bolted': 2661, 'brushed': 2662, 'chopin': 2663, 'intervene': 2664, 'scarf': 2665, 'grade': 2666, 'bee': 2667, 'soaking': 2668, 'privacy': 2669, 'colors': 2670, \"must've\": 2671, 'minutes': 2672, 'picked': 2673, 'recommended': 2674, 'dawn': 2675, 'notebook': 2676, 'pure': 2677, 'depressing': 2678, 'rats': 2679, 'bitterly': 2680, 'harassing': 2681, \"door's\": 2682, 'worst': 2683, 'sensed': 2684, 'suffocating': 2685, 'witnesses': 2686, 'pessimistic': 2687, 'achieved': 2688, 'future': 2689, 'european': 2690, 'survivor': 2691, 'telling': 2692, 'storm': 2693, 'menu': 2694, 'invite': 2695, 'tells': 2696, 'offend': 2697, 'applauded': 2698, 'desire': 2699, 'fifty': 2700, 'position': 2701, 'fond': 2702, 'spare': 2703, 'information': 2704, 'tickets': 2705, 'pot': 2706, 'offense': 2707, 'chef': 2708, 'gotten': 2709, 'compliment': 2710, 'breaks': 2711, 'extreme': 2712, 'effort': 2713, 'crowded': 2714, 'fridge': 2715, 'unforgettable': 2716, 'cucumbers': 2717, 'manners': 2718, 'sip': 2719, 'urgency': 2720, 'crept': 2721, 'scout': 2722, 'gunshot': 2723, 'until': 2724, 'settling': 2725, 'rooms': 2726, 'lessons': 2727, 'opposite': 2728, 'defeat': 2729, 'repay': 2730, 'folded': 2731, 'towels': 2732, 'email': 2733, 'slightly': 2734, 'colds': 2735, 'pretended': 2736, 'value': 2737, 'given': 2738, 'social': 2739, 'bathroom': 2740, 'appropriate': 2741, 'burning': 2742, 'whole': 2743, 'sealed': 2744, 'elders': 2745, 'tiger': 2746, 'zipper': 2747, 'questioned': 2748, 'infuriating': 2749, 'incorrigible': 2750, 'accompany': 2751, 'joystick': 2752, 'booze': 2753, 'poisoning': 2754, 'flirt': 2755, 'greatest': 2756, 'suspicion': 2757, 'diamonds': 2758, 'undress': 2759, 'blames': 2760, 'measured': 2761, 'speaker': 2762, 'actually': 2763, 'squeeze': 2764, 'password': 2765, 'argument': 2766, 'pharmacy': 2767, 'shorter': 2768, 'closet': 2769, 'headed': 2770, 'separately': 2771, 'guilt': 2772, 'extraordinary': 2773, 'irresponsible': 2774, 'hospitalized': 2775, 'outcome': 2776, 'permit': 2777, 'feelings': 2778, 'salts': 2779, 'success': 2780, 'entirely': 2781, 'froze': 2782, 'kick': 2783, 'sighed': 2784, 'bark': 2785, 'blinked': 2786, 'grinned': 2787, 'groaned': 2788, 'cured': 2789, 'aah': 2790, 'below': 2791, \"time's\": 2792, 'rocks': 2793, 'dig': 2794, 'absurd': 2795, 'human': 2796, 'cpr': 2797, 'relented': 2798, 'humble': 2799, 'pooped': 2800, 'phony': 2801, 'snores': 2802, 'gloat': 2803, 'adore': 2804, 'assume': 2805, 'exercised': 2806, 'nailed': 2807, 'protested': 2808, 'baker': 2809, 'widow': 2810, 'fasting': 2811, 'humming': 2812, 'fatal': 2813, '50': 2814, 'warmer': 2815, 'clap': 2816, 'record': 2817, 'stick': 2818, 'slim': 2819, 'sweated': 2820, 'bore': 2821, 'dump': 2822, 'backup': 2823, 'ghosts': 2824, 'exist': 2825, 'cranky': 2826, 'driven': 2827, 'dare': 2828, 'rewrote': 2829, 'lion': 2830, 'beaten': 2831, 'eighteen': 2832, 'reformed': 2833, 'restless': 2834, 'ticklish': 2835, 'unbiased': 2836, 'worn': 2837, 'solid': 2838, 'iron': 2839, 'bounce': 2840, 'review': 2841, 'approve': 2842, 'adults': 2843, 'doomed': 2844, 'heroes': 2845, 'minors': 2846, 'slipping': 2847, 'exhale': 2848, 'cracked': 2849, 'senior': 2850, 'insecure': 2851, 'diabetic': 2852, 'queasy': 2853, 'rights': 2854, 'grapes': 2855, 'autumn': 2856, 'hockey': 2857, 'funds': 2858, 'queen': 2859, 'bacon': 2860, 'mask': 2861, 'poems': 2862, 'dentist': 2863, 'soldier': 2864, 'orphan': 2865, 'easygoing': 2866, 'plastered': 2867, 'unmarried': 2868, 'voting': 2869, 'damaged': 2870, 'bat': 2871, 'wig': 2872, 'hoax': 2873, 'viral': 2874, 'rental': 2875, 'instinct': 2876, 'stealing': 2877, 'italian': 2878, 'stir': 2879, 'dvd': 2880, 'false': 2881, 'touchy': 2882, 'elderly': 2883, 'anxious': 2884, 'hypocrite': 2885, 'morons': 2886, 'wicked': 2887, 'struggle': 2888, 'holidays': 2889, 'owes': 2890, 'respects': 2891, 'author': 2892, 'brakes': 2893, 'nail': 2894, 'decorated': 2895, 'spinach': 2896, 'picnics': 2897, 'seafood': 2898, 'oven': 2899, 'stamp': 2900, 'surgery': 2901, 'serve': 2902, 'barefoot': 2903, 'captured': 2904, 'outdoors': 2905, 'unharmed': 2906, 'freshman': 2907, 'dehydrated': 2908, 'exercising': 2909, 'illiterate': 2910, 'methodical': 2911, 'quitter': 2912, 'bitter': 2913, 'wednesday': 2914, 'undamaged': 2915, 'ache': 2916, 'tune': 2917, 'angel': 2918, 'wheel': 2919, 'sir': 2920, 'bunch': 2921, 'alright': 2922, 'evident': 2923, 'melted': 2924, 'theirs': 2925, 'ford': 2926, 'callous': 2927, 'immoral': 2928, 'nodding': 2929, 'recover': 2930, 'sweating': 2931, 'landed': 2932, 'partners': 2933, 'causes': 2934, 'adjust': 2935, 'bullet': 2936, 'nails': 2937, 'defend': 2938, 'freak': 2939, 'danced': 2940, 'popcorn': 2941, 'gloomy': 2942, 'southpaw': 2943, 'mud': 2944, 'spain': 2945, 'disobeyed': 2946, 'sunburned': 2947, 'reptiles': 2948, 'laptop': 2949, 'screams': 2950, 'rains': 2951, 'tape': 2952, 'biking': 2953, 'refund': 2954, 'acquitted': 2955, 'coma': 2956, 'tipsy': 2957, 'owl': 2958, 'begging': 2959, 'cooperating': 2960, 'daydreaming': 2961, 'left-handed': 2962, 'replaceable': 2963, 'sympathetic': 2964, 'ages': 2965, 'disgrace': 2966, 'inadequate': 2967, 'sweltering': 2968, 'tax': 2969, 'covered': 2970, 'sticky': 2971, 'frankly': 2972, 'puzzle': 2973, 'peculiar': 2974, \"answer's\": 2975, \"baby's\": 2976, 'engine': 2977, 'actors': 2978, \"book's\": 2979, 'reality': 2980, 'resolute': 2981, 'skittish': 2982, 'sneezing': 2983, 'tactless': 2984, 'wavering': 2985, 'mouse': 2986, 'sees': 2987, 'earned': 2988, 'waffles': 2989, 'retreat': 2990, 'impartial': 2991, 'past': 2992, 'picky': 2993, '8': 2994, 'wizard': 2995, 'spell': 2996, 'consider': 2997, 'deceive': 2998, 'disturb': 2999, 'faces': 3000, 'rip': 3001, 'lover': 3002, 'intelligent': 3003, 'professor': 3004, 'ripped': 3005, 'reasons': 3006, 'computers': 3007, 'allergies': 3008, 'hay': 3009, 'standards': 3010, 'ropes': 3011, 'elephants': 3012, 'yolks': 3013, 'soul': 3014, 'fortune': 3015, 'kleenex': 3016, 'blanket': 3017, 'escort': 3018, 'tires': 3019, 'soap': 3020, 'pointed': 3021, 'rubbed': 3022, 'gladly': 3023, 'alcoholic': 3024, 'conservative': 3025, 'freaking': 3026, 'paranoid': 3027, 'riddle': 3028, 'valuable': 3029, 'virus': 3030, 'excessive': 3031, 'april': 3032, 'settled': 3033, 'transparent': 3034, 'smokes': 3035, 'tiny': 3036, 'stomach': 3037, 'parrots': 3038, 'tb': 3039, '1960': 3040, 'disliked': 3041, 'troubling': 3042, 'upsetting': 3043, 'limits': 3044, 'accurate': 3045, 'required': 3046, 'pianist': 3047, 'emotional': 3048, 'improving': 3049, 'oblivious': 3050, 'smiles': 3051, 'deported': 3052, 'goggles': 3053, 'eater': 3054, 'nightmare': 3055, 'mirror': 3056, 'quote': 3057, 'seventh': 3058, 'religious': 3059, 'ambulance': 3060, 'copies': 3061, 'blackmailed': 3062, 'earns': 3063, 'influential': 3064, 'twisted': 3065, 'pink': 3066, 'spelled': 3067, 'bathe': 3068, 'verify': 3069, 'bags': 3070, 'vulnerable': 3071, 'grades': 3072, 'passport': 3073, 'sleeve': 3074, 'practicing': 3075, 'confidence': 3076, 'hats': 3077, 'balance': 3078, 'protection': 3079, 'ignorance': 3080, 'airplane': 3081, 'known': 3082, 'bug': 3083, 'swept': 3084, '6:30': 3085, 'flabbergasted': 3086, 'guessing': 3087, 'persuaded': 3088, 'dubious': 3089, 'pride': 3090, 'rumors': 3091, 'inflation': 3092, 'nonstop': 3093, 'cumbersome': 3094, 'destiny': 3095, 'greasy': 3096, 'wobbly': 3097, 'conspiracy': 3098, 'rage': 3099, \"brother's\": 3100, 'misses': 3101, 'reconsider': 3102, 'pretend': 3103, 'rising': 3104, 'teen': 3105, \"somebody's\": 3106, 'aspirin': 3107, 'lemon': 3108, 'foxes': 3109, 'alike': 3110, 'temporary': 3111, 'moldy': 3112, 'thursday': 3113, 'praying': 3114, 'articulate': 3115, 'protective': 3116, 'recovering': 3117, 'remarkable': 3118, 'hopeful': 3119, 'bait': 3120, 'battle': 3121, 'stain': 3122, 'major': 3123, 'scratched': 3124, 'applause': 3125, 'flute': 3126, 'murder': 3127, 'blog': 3128, 'snails': 3129, 'choosy': 3130, 'king': 3131, 'remote': 3132, 'breathed': 3133, 'mile': 3134, 'classmate': 3135, 'colleague': 3136, 'd': 3137, 'unimpressed': 3138, 'kilos': 3139, 'scapegoat': 3140, 'baggage': 3141, 'refill': 3142, 'boiling': 3143, 'imagine': 3144, 'carpet': 3145, 'complaint': 3146, 'religion': 3147, 'mission': 3148, 'candlelight': 3149, 'mathematics': 3150, 'custom': 3151, 'windsurfing': 3152, 'outfit': 3153, 'inspiration': 3154, 'blamed': 3155, 'explosion': 3156, 'consulted': 3157, 'nagasaki': 3158, 'hire': 3159, 'learner': 3160, 'health': 3161, 'beginning': 3162, 'invincible': 3163, 'terribly': 3164, 'christian': 3165, 'board': 3166, 'improved': 3167, 'handcrafted': 3168, 'concern': 3169, 'possibility': 3170, 'recipe': 3171, 'bound': 3172, 'disappointing': 3173, 'lesson': 3174, 'suitcase': 3175, 'owls': 3176, 'slip': 3177, 'melting': 3178, 'path': 3179, 'server': 3180, 'fits': 3181, 'shoelaces': 3182, 'comforted': 3183, 'downhearted': 3184, 'names': 3185, 'frazzled': 3186, 'remains': 3187, 'distraught': 3188, 'affects': 3189, 'wheat': 3190, 'contributing': 3191, 'halfway': 3192, 'stock': 3193, 'saving': 3194, 'hidden': 3195, 'butter': 3196, 'considerate': 3197, 'egotistical': 3198, 'four': 3199, 'mammal': 3200, 'credit': 3201, 'lap': 3202, 'objection': 3203, 'square': 3204, 'talents': 3205, 'tightly': 3206, 'sixty': 3207, 'treated': 3208, 'kisser': 3209, 'behaving': 3210, 'oddly': 3211, 'public': 3212, 'barks': 3213, 'concert': 3214, 'wedding': 3215, 'swimmer': 3216, 'research': 3217, 'fully': 3218, 'uniform': 3219, 'dishwasher': 3220, 'attitude': 3221, 'most': 3222, 'managed': 3223, 'doorbell': 3224, 'steak': 3225, 'usual': 3226, 'sleeper': 3227, 'progress': 3228, 'blaming': 3229, 'undecided': 3230, 'worries': 3231, 'laundry': 3232, 'locker': 3233, 'serves': 3234, 'dated': 3235, 'loop': 3236, 'appointment': 3237, 'gums': 3238, 'complete': 3239, '1': 3240, '000': 3241, 'cheek': 3242, \"she'll\": 3243, 'slice': 3244, 'spread': 3245, 'preposterous': 3246, 'ringing': 3247, 'coal': 3248, 'closing': 3249, 'howling': 3250, \"father's\": 3251, 'favorite': 3252, 'challenged': 3253, 'encouraged': 3254, 'gifted': 3255, 'resumed': 3256, 'intently': 3257, 'shaking': 3258, 'overtime': 3259, 'eavesdropping': 3260, 'utilities': 3261, 'extra': 3262, 'squirrel': 3263, 'language': 3264, 'inform': 3265, 'occur': 3266, 'library': 3267, 'fancy': 3268, 'ladder': 3269, 'attained': 3270, 'nervously': 3271, 'finger': 3272, 'necklace': 3273, 'earrings': 3274, 'disrespect': 3275, 'putting': 3276, 'biggest': 3277, 'dignity': 3278, 'irritating': 3279, 'easier': 3280, 'discuss': 3281, 'cakes': 3282, 'basketball': 3283, 'bedroom': 3284, 'cuts': 3285, 'investigating': 3286, 'overemotional': 3287, 'unimaginative': 3288, 'peeled': 3289, 'ignition': 3290, 'autopsy': 3291, 'contain': 3292, 'ruin': 3293, 'recognize': 3294, 'critical': 3295, 'tuna': 3296, 'mitts': 3297, 'magazine': 3298, 'confirmed': 3299, 'faq': 3300, 'explained': 3301, 'intriguing': 3302, 'explode': 3303, 'pampered': 3304, 'dreading': 3305, 'stressful': 3306, 'definitely': 3307, 'hop': 3308, '19': 3309, 'swore': 3310, 'goofed': 3311, 'moaned': 3312, 'dj': 3313, 'sexy': 3314, 'humor': 3315, 'inhaled': 3316, 'shouted': 3317, 'tripped': 3318, '8:30': 3319, 'higher': 3320, 'swiss': 3321, 'objected': 3322, 'shrugged': 3323, 'whistled': 3324, 'immune': 3325, 'soaked': 3326, 'wasted': 3327, 'bogus': 3328, 'chat': 3329, 'mama': 3330, 'braked': 3331, 'gasped': 3332, 'unscrew': 3333, 'sunk': 3334, 'specific': 3335, \"beer's\": 3336, 'bowl': 3337, 'shout': 3338, 'flip': 3339, 'nasty': 3340, 'hunk': 3341, 'slob': 3342, 'monk': 3343, 'oppose': 3344, 'surrender': 3345, 'neutral': 3346, 'foggy': 3347, 'futile': 3348, 'release': 3349, 'icky': 3350, 'glum': 3351, 'wary': 3352, 'drag': 3353, 'loss': 3354, 'abandon': 3355, 'litter': 3356, 'ramble': 3357, 'slouch': 3358, 'examine': 3359, 'avoids': 3360, 'heroic': 3361, 'jogging': 3362, 'honor': 3363, 'b': 3364, 'canned': 3365, 'wimped': 3366, '99%': 3367, 'barber': 3368, 'surfer': 3369, 'autistic': 3370, 'cultured': 3371, 'managing': 3372, 'amazed': 3373, 'setup': 3374, 'suicide': 3375, 'ladies': 3376, 'itch': 3377, 'shrieked': 3378, 'pouting': 3379, 'whining': 3380, 'yawning': 3381, 'enlisted': 3382, 'grumbled': 3383, 'insisted': 3384, 'obese': 3385, 'stoic': 3386, 'vegan': 3387, 'ufo': 3388, 'vanished': 3389, 'amuse': 3390, 'imbecile': 3391, 'moody': 3392, 'blindfold': 3393, 'despair': 3394, 'peas': 3395, 'dies': 3396, 'haircut': 3397, 'braces': 3398, 'bled': 3399, 'honk': 3400, 'horn': 3401, 'thrilling': 3402, 'bribed': 3403, 'classes': 3404, 'designed': 3405, 'poker': 3406, 'exaggerated': 3407, 'reborn': 3408, 'forbid': 3409, 'bonus': 3410, 'scammed': 3411, 'flying': 3412, 'sirens': 3413, 'camels': 3414, 'cities': 3415, 'clocks': 3416, 'trains': 3417, 'poetry': 3418, 'crew': 3419, 'crushed': 3420, 'dazzled': 3421, 'drugged': 3422, 'surgeon': 3423, 'adaptable': 3424, 'bilingual': 3425, 'efficient': 3426, 'strike': 3427, 'surviving': 3428, 'gag': 3429, 'superb': 3430, 'homemade': 3431, 'occupied': 3432, 'suicidal': 3433, 'hustling': 3434, 'aches': 3435, \"hair's\": 3436, 'aloud': 3437, 'russia': 3438, 'clapping': 3439, 'spitting': 3440, 'straighten': 3441, 'saturn': 3442, 'myth': 3443, 'doable': 3444, 'untrue': 3445, 'asian': 3446, 'spies': 3447, 'unhurt': 3448, 'upbeat': 3449, 'winded': 3450, 'staggered': 3451, 'tensed': 3452, 'frank': 3453, 'choking': 3454, 'wax': 3455, 'assumed': 3456, 'candy': 3457, 'sync': 3458, 'bummer': 3459, 'absent': 3460, 'legibly': 3461, 'charlatan': 3462, 'hoot': 3463, 'snob': 3464, 'clichés': 3465, 'shovel': 3466, 'juggle': 3467, \"dinner's\": 3468, 'tigers': 3469, 'crude': 3470, 'force': 3471, 'tease': 3472, 'tempt': 3473, 'enter': 3474, 'afternoon': 3475, 'lip': 3476, 'dislikes': 3477, 'hungarian': 3478, 'slacker': 3479, 'suntan': 3480, 'expelled': 3481, 'guarantee': 3482, 'stroke': 3483, 'mondays': 3484, 'sundays': 3485, 'hiccups': 3486, 'voices': 3487, 'hiccup': 3488, 'lobster': 3489, 'mahjong': 3490, 'puzzles': 3491, 'stories': 3492, 'cattle': 3493, 'korean': 3494, 'hammered': 3495, 'impolite': 3496, 'agony': 3497, 'pardoned': 3498, 'prosper': 3499, 'musician': 3500, 'salesman': 3501, 'dependable': 3502, 'firing': 3503, 'kyoto': 3504, 'meditating': 3505, 'prejudiced': 3506, 'dishonest': 3507, 'revolting': 3508, 'vibrating': 3509, 'searching': 3510, 'idiots': 3511, 'biting': 3512, 'bach': 3513, 'sings': 3514, 'hottie': 3515, 'gossiping': 3516, 'grumbling': 3517, 'quibbling': 3518, 'sniffling': 3519, 'tower': 3520, 'siren': 3521, 'snag': 3522, 'muddy': 3523, 'tricky': 3524, 'dice': 3525, 'pear': 3526, '65': 3527, 'cynical': 3528, 'shaving': 3529, 'unfazed': 3530, 'retaliated': 3531, 'improve': 3532, 'clueless': 3533, 'crash': 3534, 'disgust': 3535, 'amusing': 3536, 'elusive': 3537, 'obscene': 3538, 'pro': 3539, 'insured': 3540, 'whistle': 3541, 'hatch': 3542, 'interfere': 3543, 'remind': 3544, 'fold': 3545, 'ambition': 3546, 'toyota': 3547, 'racket': 3548, 'robot': 3549, 'slowpoke': 3550, '12:45': 3551, 'humiliating': 3552, 'bachelor': 3553, 'chickened': 3554, 'dealt': 3555, 'downloaded': 3556, 'feverish': 3557, 'isolated': 3558, 'seizure': 3559, 'fanatics': 3560, 'politics': 3561, 'heat': 3562, 'weddings': 3563, 'bruise': 3564, 'internet': 3565, 'guidance': 3566, 'outwitted': 3567, 'scored': 3568, 'vitamins': 3569, 'assaulted': 3570, 'convicted': 3571, 'arrange': 3572, 'assist': 3573, 'double': 3574, 'carpenter': 3575, 'foreigner': 3576, 'geologist': 3577, 'catching': 3578, 'frying': 3579, 'hardworking': 3580, 'spontaneous': 3581, 'unconvinced': 3582, 'option': 3583, 'handmade': 3584, 'outrage': 3585, 'improbable': 3586, 'misleading': 3587, 'secure': 3588, 'refreshing': 3589, 'typical': 3590, 'sufficient': 3591, 'humid': 3592, 'paging': 3593, 'lemons': 3594, 'improvise': 3595, 'squeak': 3596, 'planning': 3597, 'pour': 3598, 'lid': 3599, 'sharks': 3600, 'graceful': 3601, 'stabbed': 3602, 'nosy': 3603, 'plastic': 3604, 'doubtful': 3605, 'net': 3606, 'pilots': 3607, 'dances': 3608, 'tailor': 3609, 'athletic': 3610, 'knocking': 3611, 'perverse': 3612, 'spirited': 3613, 'unafraid': 3614, 'unnerved': 3615, 'stops': 3616, 'sleeps': 3617, 'slowed': 3618, 'yawn': 3619, 'walls': 3620, 'fools': 3621, 'raw': 3622, 'experts': 3623, 'shared': 3624, 'sailing': 3625, 'newcomers': 3626, 'newlyweds': 3627, 'resigning': 3628, 'unrelated': 3629, 'treasure': 3630, 'oar': 3631, 'devil': 3632, 'menace': 3633, 'wings': 3634, 'invisible': 3635, 'maniac': 3636, 'dyslexic': 3637, 'boxing': 3638, 'brace': 3639, 'normally': 3640, 'blinds': 3641, 'supply': 3642, 'delicately': 3643, 'exaggerate': 3644, 'yell': 3645, 'meals': 3646, 'veggies': 3647, 'hamster': 3648, 'gardening': 3649, 'flow': 3650, 'croissant': 3651, 'recently': 3652, 'backward': 3653, 'moves': 3654, 'ratted': 3655, 'bartender': 3656, 'biologist': 3657, 'senile': 3658, 'brazil': 3659, 'reschedule': 3660, 'confiscated': 3661, 'deliver': 3662, 'drugs': 3663, 'protected': 3664, 'chemistry': 3665, 'hypocrisy': 3666, 'paperwork': 3667, 'gunshots': 3668, 'lifted': 3669, 'temper': 3670, 'adventure': 3671, 'hedgehogs': 3672, 'umbrellas': 3673, 'divorce': 3674, 'rematch': 3675, 'vengeance': 3676, '13': 3677, '2003': 3678, 'unprepared': 3679, 'demonstrate': 3680, 'clerk': 3681, 'bookkeeper': 3682, 'ambidextrous': 3683, 'dissatisfied': 3684, 'housesitting': 3685, 'attic': 3686, 'super': 3687, 'youngest': 3688, 'conscious': 3689, '2': 3690, 'euros': 3691, 'freaks': 3692, 'hype': 3693, 'mandatory': 3694, 'habit': 3695, 'tradition': 3696, 'frightening': 3697, 'asia': 3698, 'lower': 3699, 'itchy': 3700, 'sunburn': 3701, 'bellyaching': 3702, 'hassling': 3703, 'rome': 3704, 'despises': 3705, 'obstinate': 3706, 'rode': 3707, 'camel': 3708, 'worships': 3709, 'bench': 3710, 'apologizing': 3711, 'million': 3712, 'explains': 3713, 'brilliant': 3714, 'curtain': 3715, \"party's\": 3716, 'switch': 3717, 'scoffed': 3718, 'artists': 3719, '839': 3720, 'bounced': 3721, 'forgives': 3722, 'fried': 3723, 'rabbit': 3724, 'chickens': 3725, 'onions': 3726, 'delirious': 3727, 'merciless': 3728, 'observing': 3729, 'campus': 3730, 'suspended': 3731, 'sighing': 3732, 'tulips': 3733, 'overheard': 3734, 'tickled': 3735, 'appalled': 3736, 'watches': 3737, 'big-headed': 3738, 'innovative': 3739, 'undefeated': 3740, 'instead': 3741, 'slower': 3742, 'competed': 3743, 'ambushed': 3744, 'classmates': 3745, 'seek': 3746, 'score': 3747, 'cheaper': 3748, 'developed': 3749, 'uses': 3750, 'notified': 3751, 'nicely': 3752, 'x': 3753, 'marks': 3754, 'practical': 3755, 'unethical': 3756, 'zip': 3757, 'bachelors': 3758, 'knackered': 3759, 'elaborate': 3760, 'click': 3761, 'link': 3762, 'cocaine': 3763, 'compare': 3764, 'imminent': 3765, 'startle': 3766, 'disable': 3767, 'kratom': 3768, 'wanna': 3769, 'haste': 3770, 'employs': 3771, 'blond': 3772, 'curly': 3773, 'physicist': 3774, 'unrealistic': 3775, 'frugally': 3776, 'requested': 3777, 'russian': 3778, 'imprisoned': 3779, 'heed': 3780, 'handrail': 3781, 'tutor': 3782, 'mosquitoes': 3783, 'hangover': 3784, 'proposal': 3785, 'intend': 3786, 'adventures': 3787, 'dam': 3788, 'outlive': 3789, 'volleyball': 3790, 'muscle': 3791, 'jaw': 3792, 'jest': 3793, 'swallowed': 3794, 'plate': 3795, 'plates': 3796, 'passenger': 3797, 'discredited': 3798, 'flirting': 3799, 'shotgun': 3800, 'trainer': 3801, 'concentrating': 3802, 'materialistic': 3803, 'insure': 3804, 'curfew': 3805, 'deliberate': 3806, 'horrendous': 3807, 'flimsy': 3808, 'club': 3809, 'eight-thirty': 3810, 'chin': 3811, 'knock': 3812, 'enjoyable': 3813, 'prevail': 3814, 'prediction': 3815, 'aching': 3816, 'shoulder': 3817, 'attract': 3818, 'toy': 3819, 'unsociable': 3820, 'hyperactive': 3821, 'flower': 3822, 'somehow': 3823, 'badgering': 3824, 'interrupting': 3825, 'rings': 3826, 'classified': 3827, 'crowd': 3828, 'lovers': 3829, 'hunted': 3830, 'tortured': 3831, 'identical': 3832, 'bucket': 3833, 'appalling': 3834, 'permanent': 3835, 'sickening': 3836, 'fishy': 3837, 'claims': 3838, 'appear': 3839, 'imitated': 3840, 'despondent': 3841, 'minor': 3842, 'trained': 3843, 'peeked': 3844, 'peered': 3845, 'poisoned': 3846, 'shifted': 3847, 'gears': 3848, 'strangled': 3849, 'hose': 3850, 'beers': 3851, 'flaws': 3852, '7': 3853, 'p': 3854, 'm': 3855, 'warrant': 3856, 'due': 3857, 'handling': 3858, 'killers': 3859, 'pulling': 3860, 'revelation': 3861, \"where've\": 3862, 'stitches': 3863, 'murderer': 3864, 'mocking': 3865, 'fascinate': 3866, 'advised': 3867, 'subject': 3868, 'pockets': 3869, 'mozart': 3870, 'stones': 3871, 'dollar': 3872, 'blanks': 3873, 'broom': 3874, 'cartwheel': 3875, 'cycling': 3876, 'daydreamer': 3877, 'lottery': 3878, 'walker': 3879, 'critic': 3880, 'aristocrat': 3881, 'print': 3882, 'pace': 3883, 'museum': 3884, 'absolutely': 3885, 'grilling': 3886, 'prophet': 3887, 'fries': 3888, 'potato': 3889, 'sin': 3890, 'miserably': 3891, 'chilly': 3892, 'loads': 3893, 'handed': 3894, 'patience': 3895, 'siblings': 3896, 'cameras': 3897, 'explosions': 3898, 'emailed': 3899, 'places': 3900, 'raspberries': 3901, 'roast': 3902, 'promises': 3903, 'pad': 3904, 'oiled': 3905, 'trunk': 3906, 'repeated': 3907, 'sliced': 3908, 'ankle': 3909, 'unplugged': 3910, '1972': 3911, 'disqualified': 3912, 'television': 3913, 'election': 3914, 'rusty': 3915, 'claustrophobic': 3916, 'gaining': 3917, 'bathtub': 3918, 'laying': 3919, 'denying': 3920, 'selling': 3921, 'somewhat': 3922, 'supporting': 3923, 'supposed': 3924, 'laid': 3925, 'astonishing': 3926, 'frustrating': 3927, 'mesmerizing': 3928, 'relevant': 3929, 'disease': 3930, 'knowledge': 3931, 'rephrase': 3932, 'luckily': 3933, 'moons': 3934, 'hunch': 3935, 'mailbox': 3936, 'immortal': 3937, 'bandage': 3938, 'strength': 3939, 'schools': 3940, 'charity': 3941, 'correcting': 3942, 'losers': 3943, 'tickles': 3944, 'warning': 3945, \"man's\": 3946, 'unimportant': 3947, 'attempt': 3948, \"battery's\": 3949, 'buzzer': 3950, 'rallied': 3951, 'brightened': 3952, 'stars': 3953, 'wandered': 3954, 'wrestlers': 3955, '13th': 3956, 'families': 3957, 'hostages': 3958, 'tents': 3959, 'peaceful': 3960, 'disposable': 3961, 'foreigners': 3962, 'project': 3963, 'surprising': 3964, 'contacted': 3965, 'follows': 3966, 'inefficient': 3967, 'launders': 3968, 'pays': 3969, 'blankly': 3970, 'distressed': 3971, 'persistent': 3972, 'subpoenaed': 3973, 'unbeatable': 3974, \"tomorrow's\": 3975, 'tuck': 3976, 'chartered': 3977, 'chatted': 3978, 'contract': 3979, 'deadline': 3980, 'sacrifices': 3981, 'strategy': 3982, 'passengers': 3983, 'judged': 3984, 'agreement': 3985, 'slowing': 3986, 'unprejudiced': 3987, 'porcupine': 3988, 'bakery': 3989, 'prevent': 3990, 'yeah': 3991, 'oath': 3992, 'intimidate': 3993, 'racists': 3994, 'idealist': 3995, 'unemotional': 3996, \"car's\": 3997, 'acid': 3998, 'facebook': 3999, 'banker': 4000, 'habits': 4001, 'absorbs': 4002, 'rare': 4003, 'darkness': 4004, 'disconnect': 4005, 'plug': 4006, 'vertigo': 4007, 'bowling': 4008, 'jewelry': 4009, 'cigars': 4010, 'ketamine': 4011, 'cocky': 4012, 'blush': 4013, 'scribble': 4014, 'faults': 4015, 'sorrows': 4016, 'toothpick': 4017, 'journey': 4018, 'averted': 4019, 'gaze': 4020, 'bragged': 4021, 'willingly': 4022, 'excess': 4023, 'bleed': 4024, 'hoped': 4025, '80': 4026, 'jimmied': 4027, 'morocco': 4028, 'response': 4029, 'loses': 4030, 'shined': 4031, 'cardiologist': 4032, 'hunter': 4033, 'virtue': 4034, 'electrician': 4035, 'director': 4036, 'saitama': 4037, 'checking': 4038, 'flights': 4039, 'neck': 4040, 'opponents': 4041, 'brewed': 4042, 't-shirt': 4043, 'costume': 4044, 'reservations': 4045, 'blackboard': 4046, 'medical': 4047, 'instructions': 4048, 'reviewed': 4049, 'motion': 4050, 'simply': 4051, 'solved': 4052, 'sprang': 4053, 'backwards': 4054, 'stumbled': 4055, 'tested': 4056, 'medicine': 4057, 'candor': 4058, 'sack': 4059, 'tolerate': 4060, 'wagon': 4061, 'drafting': 4062, 'incredibly': 4063, 'indebted': 4064, 'intimidated': 4065, 'presentable': 4066, 'santa': 4067, 'bothers': 4068, 'snows': 4069, 'bugged': 4070, 'excruciating': 4071, 'fling': 4072, 'eleven': 4073, 'subjective': 4074, 'time-consuming': 4075, 'jupiter': 4076, 'passion': 4077, 'swollen': 4078, 'throat': 4079, 'package': 4080, 'allies': 4081, '3': 4082, 'limited': 4083, 'ends': 4084, 'poaching': 4085, 'believing': 4086, 'reinforcements': 4087, 'good-natured': 4088, 'sonata': 4089, 'buys': 4090, 'strong-willed': 4091, 'organ': 4092, 'discouraging': 4093, 'specialty': 4094, 'original': 4095, 'faded': 4096, 'tender': 4097, 'monkey': 4098, 'outlook': 4099, 'stakes': 4100, 'investors': 4101, 'inseparable': 4102, 'grave': 4103, 'handbag': 4104, 'metal': 4105, 'appears': 4106, 'approached': 4107, 'pacemaker': 4108, 'consultant': 4109, 'promptly': 4110, 'salted': 4111, 'impatiently': 4112, 'flustered': 4113, 'contest': 4114, 'part-time': 4115, 'hallucinating': 4116, \"tonight's\": 4117, 'text': 4118, 'scandal': 4119, 'ballots': 4120, 'oral': 4121, 'situation': 4122, 'anxiously': 4123, 'shortly': 4124, 'forest': 4125, 'tempting': 4126, 'opportunity': 4127, 'arriving': 4128, 'located': 4129, 'replacing': 4130, 'cursing': 4131, 'correctly': 4132, 'reek': 4133, 'tore': 4134, 'harmed': 4135, 'acting': 4136, 'cantankerous': 4137, 'sweetest': 4138, 'undependable': 4139, 'you’re': 4140, 'show-off': 4141, 'animal': 4142, 'explosives': 4143, 'imitating': 4144, 'imitations': 4145, 'version': 4146, 'least': 4147, 'cotton': 4148, 'exhausting': 4149, 'foresee': 4150, 'dye': 4151, 'blankets': 4152, 'glaucoma': 4153, 'marijuana': 4154, 'contacts': 4155, 'dentures': 4156, 'dramatic': 4157, 'brake': 4158, 'borders': 4159, 'smoked': 4160, 'counted': 4161, 'filed': 4162, 'nerves': 4163, 'dollars': 4164, 'foreign': 4165, 'conscience': 4166, 'daughters': 4167, 'bewildered': 4168, 'stone': 4169, 'clothed': 4170, 'smooth': 4171, 'talker': 4172, 'half-brother': 4173, 'inspired': 4174, 'yard': 4175, 'mt': 4176, 'fuji': 4177, 'bears': 4178, 'awoke': 4179, 'punctuality': 4180, 'pry': 4181, 'flushed': 4182, 'kidney': 4183, 'alternative': 4184, 'salary': 4185, 'reservation': 4186, 'slight': 4187, 'stomachache': 4188, 'thirteen': 4189, 'boots': 4190, 'rib': 4191, 'memorized': 4192, 'january': 4193, '$200': 4194, 'parked': 4195, 'rechecked': 4196, 'sincerely': 4197, 'underestimated': 4198, 'analysis': 4199, 'posted': 4200, 'welfare': 4201, 'citizen': 4202, 'disposal': 4203, 'options': 4204, 'good-looking': 4205, 'marrying': 4206, 'servant': 4207, 'pressing': 4208, 'charges': 4209, 'amateur': 4210, 'unreasonable': 4211, 'timetable': 4212, 'ketchup': 4213, 'smoothly': 4214, '99': 4215, '9%': 4216, 'leather': 4217, 'classroom': 4218, 'predictable': 4219, 'gander': 4220, 'clouds': 4221, 'leap': 4222, 'unattractive': 4223, 'judging': 4224, 'marriage': 4225, 'planes': 4226, 'account': 4227, 'scalpel': 4228, 'sharpen': 4229, 'ironed': 4230, 'skipping': 4231, 'impolitely': 4232, 'shrug': 4233, 'shoulders': 4234, 'main': 4235, 'ticking': 4236, \"company's\": 4237, 'results': 4238, 'antidote': 4239, 'vacancy': 4240, 'logs': 4241, 'approaching': 4242, 'vegetarians': 4243, 'smoothies': 4244, 'formed': 4245, 'westward': 4246, 'tourists': 4247, 'prettier': 4248, 'fragile': 4249, 'houses': 4250, 'hesitantly': 4251, 'salute': 4252, 'chopping': 4253, 'uninteresting': 4254, 'resisted': 4255, 'mesmerized': 4256, 'awkwardly': 4257, 'chanting': 4258, 'grinning': 4259, 'groaning': 4260, 'mumbling': 4261, 'trembled': 4262, 'americans': 4263, 'advantage': 4264, 'disconnected': 4265, 'protecting': 4266, 'underage': 4267, 'duties': 4268, 'brings': 4269, 'commotion': 4270, 'restroom': 4271, 'deleted': 4272, 'ditch': 4273, 'messages': 4274, 'overestimate': 4275, 'beautifully': 4276, 'snooze': 4277, 'ticked': 4278, 'flattering': 4279, 'unpredictable': 4280, \"phone's\": 4281, 'dolphin': 4282, 'africa': 4283, 'picking': 4284, 'pickpockets': 4285, 'stats': 4286, 'propose': 4287, 'deposit': 4288, 'digitalis': 4289, 'aftershave': 4290, 'massage': 4291, 'satisfy': 4292, 'bubble': 4293, 'confuse': 4294, 'floss': 4295, 'swear': 4296, 'faucet': 4297, 'quieted': 4298, 'admitted': 4299, 'delivered': 4300, 'allergy': 4301, 'absolute': 4302, 'heroin': 4303, 'wisdom': 4304, 'eager': 4305, 'licked': 4306, 'unbuckled': 4307, 'excommunicated': 4308, 'bravery': 4309, 'anticipated': 4310, 'satisfaction': 4311, 'wit': 4312, 'tubs': 4313, 'dove': 4314, 'woozy': 4315, 'afterwards': 4316, 'pounds': 4317, 'errands': 4318, 'explanation': 4319, 'participate': 4320, 'toe': 4321, 'personally': 4322, 'misspelled': 4323, 'interpreter': 4324, 'event': 4325, 'puppies': 4326, 'tend': 4327, 'falsely': 4328, 'accused': 4329, 'sandwiches': 4330, 'updated': 4331, 'biology': 4332, 'heights': 4333, 'narrow-minded': 4334, 'hospitals': 4335, 'tuesday': 4336, 'creeps': 4337, 'written': 4338, 'conclusive': 4339, 'quarter': 4340, 'insanely': 4341, 'formality': 4342, 'self-explanatory': 4343, 'showers': 4344, 'mountain': 4345, 'dorm': 4346, 'fled': 4347, 'pair': 4348, 'cheer': 4349, 'cuff': 4350, 'cursed': 4351, '$5': 4352, 'frowned': 4353, 'gloated': 4354, 'grunted': 4355, 'prepaid': 4356, 'needy': 4357, 'poured': 4358, '3:30': 4359, 'dived': 4360, 'knits': 4361, 'limps': 4362, 'bottoms': 4363, 'shivered': 4364, 'flabby': 4365, '7:30': 4366, 'bulky': 4367, 'taboo': 4368, 'lasts': 4369, 'shadow': 4370, 'cheats': 4371, 'cusses': 4372, 'sobbed': 4373, 'yawned': 4374, 'faking': 4375, 'tapes': 4376, 'glue': 4377, '17': 4378, 'curt': 4379, \"tv's\": 4380, 'gambles': 4381, 'gargled': 4382, 'meek': 4383, 'vain': 4384, 'reacted': 4385, 'sneered': 4386, 'sniffed': 4387, 'snorted': 4388, 'hell': 4389, 'heel': 4390, \"what'd\": 4391, 'warmly': 4392, 'mocked': 4393, 'caviar': 4394, 'carded': 4395, 'ax': 4396, 'hives': 4397, 'improvised': 4398, 'r': 4399, '&': 4400, 'sympathize': 4401, 'framed': 4402, 'weighed': 4403, 'priest': 4404, 'purist': 4405, 'agent': 4406, 'famished': 4407, 'hungover': 4408, 'rebel': 4409, 'off-duty': 4410, 'elk': 4411, 'heal': 4412, 'plant': 4413, 'hip': 4414, 'cared': 4415, 'filming': 4416, 'gawking': 4417, 'whiff': 4418, 'spam': 4419, 'approves': 4420, 'pudgy': 4421, 'sniffled': 4422, 'stutters': 4423, 'arabs': 4424, 'starve': 4425, 'gross': 4426, 'drown': 4427, 'mock': 4428, 'sass': 4429, 'healthily': 4430, 'advises': 4431, 'dug': 4432, 'british': 4433, 'grouch': 4434, 'jesuit': 4435, 'tycoon': 4436, 'acquired': 4437, 'unwell': 4438, 'crowds': 4439, 'prunes': 4440, 'yacht': 4441, 'squash': 4442, 'resent': 4443, 'firefox': 4444, 'pony': 4445, 'nights': 4446, 'trainee': 4447, 'parole': 4448, 'resentful': 4449, 'sickens': 4450, 'bomb': 4451, 'parody': 4452, 'sequel': 4453, 'indecent': 4454, 'obsolete': 4455, 'rat': 4456, 'paddling': 4457, 'mortal': 4458, 'lungs': 4459, 'gentle': 4460, 'obeys': 4461, 'livid': 4462, 'cutie': 4463, 'frowning': 4464, 'heap': 4465, 'rad': 4466, 'mooed': 4467, 'embraced': 4468, 'pun': 4469, 'basic': 4470, 'exercises': 4471, 'graduated': 4472, 'sexist': 4473, 'somber': 4474, 'stable': 4475, 'overdosed': 4476, 'shuddered': 4477, 'stiffened': 4478, 'testified': 4479, 'tools': 4480, 'rebuild': 4481, 'stalled': 4482, 'winners': 4483, 'matured': 4484, 'fiasco': 4485, 'hassle': 4486, 'coke': 4487, 'intruding': 4488, 'boats': 4489, 'sink': 4490, 'purr': 4491, 'farts': 4492, 'gasps': 4493, 'lines': 4494, 'tan': 4495, 'gazed': 4496, 'bankrupt': 4497, 'delicate': 4498, 'jelly': 4499, 'ex-con': 4500, 'outlaw': 4501, 'henpecked': 4502, 'ached': 4503, 'perceptive': 4504, 'draft': 4505, 'seasick': 4506, 'snubbed': 4507, 'mishap': 4508, 'hailed': 4509, 'insects': 4510, 'ironing': 4511, 'karaoke': 4512, 'zealots': 4513, 'amnesia': 4514, 'thud': 4515, 'almonds': 4516, 'castles': 4517, 'sashimi': 4518, 'upstate': 4519, 'lasagna': 4520, 'sunsets': 4521, 'muffins': 4522, 'decline': 4523, 'asap': 4524, '$100': 4525, 'predicted': 4526, 'sneeze': 4527, 'urge': 4528, 'memo': 4529, 'scold': 4530, 'merchant': 4531, 'minister': 4532, 'thumbs': 4533, 'farsighted': 4534, 'remodeling': 4535, 'killer': 4536, 'credible': 4537, 'fluke': 4538, 'magical': 4539, 'classic': 4540, 'firefly': 4541, 'ambush': 4542, 'forbidden': 4543, 'inspiring': 4544, 'clues': 4545, \"mum's\": 4546, 'joints': 4547, 'itches': 4548, 'tummy': 4549, 'ditched': 4550, 'brains': 4551, 'prudish': 4552, 'types': 4553, 'looker': 4554, 'poking': 4555, 'resisting': 4556, 'flag': 4557, 'quarreled': 4558, 'babies': 4559, 'unsafe': 4560, 'hectic': 4561, 'draws': 4562, 'issues': 4563, 'scurvy': 4564, 'felon': 4565, 'giant': 4566, 'lefty': 4567, 'mason': 4568, 'pilot': 4569, 'devoted': 4570, 'pompous': 4571, 'radical': 4572, 'unkempt': 4573, 'tofu': 4574, 'maps': 4575, 'stranded': 4576, 'unstable': 4577, 'sauce': 4578, 'rear': 4579, 'butchers': 4580, 'letdown': 4581, 'atm': 4582, 'reinstated': 4583, 'suggestions': 4584, 'purple': 4585, 'anytime': 4586, 'boxes': 4587, 'clip': 4588, 'crows': 4589, 'rap': 4590, 'fetch': 4591, 'onto': 4592, 'daddy': 4593, 'intrigues': 4594, 'ethiopian': 4595, 'sweets': 4596, 'puts': 4597, 'airs': 4598, 'whisky': 4599, 'shouts': 4600, 'swindled': 4601, 'comedian': 4602, 'frat': 4603, 'gardener': 4604, 'newcomer': 4605, 'hoist': 4606, 'sails': 4607, 'hypnotism': 4608, 'egypt': 4609, 'booked': 4610, 'compete': 4611, 'carp': 4612, 'dried': 4613, 'funerals': 4614, 'raccoons': 4615, 'rug': 4616, 'dandruff': 4617, 'diabetes': 4618, 'immunity': 4619, 'imagined': 4620, 'cartoons': 4621, 'westerns': 4622, 'hyogo': 4623, 'interest': 4624, 'barbecue': 4625, 'comedies': 4626, 'eggplant': 4627, 'brownies': 4628, 'caffeine': 4629, 'orchids': 4630, 'respected': 4631, 'pattern': 4632, 'patrol': 4633, 'petrified': 4634, 'wondering': 4635, 'azerbaijani': 4636, 'cameraman': 4637, 'chauffeur': 4638, 'housewife': 4639, 'lifeguard': 4640, 'masochist': 4641, 'color-blind': 4642, 'zambia': 4643, 'nearsighted': 4644, 'deck': 4645, 'hazardous': 4646, 'poisonous': 4647, 'ethical': 4648, 'poorly': 4649, 'burnt': 4650, 'enticing': 4651, 'mushroom': 4652, 'travesty': 4653, '11': 4654, 'artificial': 4655, 'dirt': 4656, 'scarce': 4657, 'koalas': 4658, 'kites': 4659, \"life's\": 4660, 'merry': 4661, 'shrank': 4662, \"shift's\": 4663, 'natto': 4664, 'wonders': 4665, 'rake': 4666, 'saddle': 4667, 'brazilian': 4668, 'spanish': 4669, 'squabbling': 4670, 'whimpering': 4671, 'pagoda': 4672, 'barbaric': 4673, \"bike's\": 4674, 'growled': 4675, \"food's\": 4676, 'stank': 4677, \"soup's\": 4678, 'tub': 4679, 'howled': 4680, 'melons': 4681, 'farce': 4682, 'hogwash': 4683, 'private': 4684, 'pleases': 4685, 'burps': 4686, 'exaggerates': 4687, 'ipad': 4688, 'client': 4689, 'welder': 4690, 'anorexic': 4691, 'depraved': 4692, 'drenched': 4693, 'eloquent': 4694, 'immobile': 4695, 'insolent': 4696, 'likeable': 4697, 'reckless': 4698, 'studious': 4699, 'tireless': 4700, 'tolerant': 4701, 'learns': 4702, 'dazed': 4703, 'falls': 4704, 'photos': 4705, 'evasive': 4706, 'moaning': 4707, 'paralyzed': 4708, 'declared': 4709, 'ponchos': 4710, 'farmers': 4711, 'camp': 4712, 'attorneys': 4713, 'comedians': 4714, 'gardeners': 4715, 'gentlemen': 4716, 'incorrect': 4717, 'relatives': 4718, 'soulmates': 4719, 'blessing': 4720, 'prospect': 4721, 'weakling': 4722, 'dude': 4723, 'gpa': 4724, 'jello': 4725, 'unsure': 4726, \"mustn't\": 4727, 'atlantis': 4728, 'consult': 4729, '110': 4730, 'pasta': 4731, 'groans': 4732, 'floating': 4733, 'hobo': 4734, 'picasso': 4735, 'joker': 4736, 'acrobat': 4737, 'well-liked': 4738, 'shares': 4739, 'soundly': 4740, 'tenacious': 4741, 'historian': 4742, 'nonsmoker': 4743, 'sophomore': 4744, 'hone': 4745, 'skills': 4746, 'melodramatic': 4747, 'norway': 4748, 'witch': 4749, 'weekly': 4750, 'appreciated': 4751, 'bumped': 4752, 'budge': 4753, 'reach': 4754, 'pizzas': 4755, 'disregarded': 4756, 'dilemma': 4757, 'refreshed': 4758, 'goosebumps': 4759, 'texts': 4760, 'fireworks': 4761, 'diploma': 4762, 'grenade': 4763, 'heartburn': 4764, 'pneumonia': 4765, 'astrology': 4766, 'uncles': 4767, 'mysteries': 4768, 'pop': 4769, 'astronomy': 4770, 'libraries': 4771, 'envelopes': 4772, 'subtitles': 4773, 'strongly': 4774, 'martini': 4775, 'pal': 4776, 'raccoon': 4777, 'scooter': 4778, 'dumbstruck': 4779, 'raffle': 4780, '18': 4781, '25': 4782, 'programmer': 4783, 'shutterbug': 4784, 'croatia': 4785, 'romania': 4786, 'inviting': 4787, 'beggar': 4788, 'row': 4789, 'accessible': 4790, '223-1374': 4791, 'snowstorm': 4792, 'sunflower': 4793, 'balmy': 4794, 'conceivable': 4795, 'cooler': 4796, 'far-fetched': 4797, 'regrettable': 4798, 'camping': 4799, 'darts': 4800, 'fleas': 4801, 'inbox': 4802, \"rifle's\": 4803, \"wallet's\": 4804, 'oil': 4805, 'pump': 4806, 'sock': 4807, 'ending': 4808, 'idolized': 4809, 'scene': 4810, 'repulses': 4811, 'pitied': 4812, 'precautions': 4813, 'kindly': 4814, 'avoidable': 4815, 'blackmail': 4816, 'idle': 4817, 'affair': 4818, 'creaked': 4819, 'jury': 4820, 'mass': 4821, 'noes': 4822, 'icy': 4823, 'singers': 4824, 'amateurs': 4825, 'traitors': 4826, \"guy's\": 4827, 'insanity': 4828, 'official': 4829, 'puzzling': 4830, 'sabotage': 4831, 'shameful': 4832, 'norm': 4833, \"seat's\": 4834, 'admires': 4835, 'avoided': 4836, 'raft': 4837, 'coughs': 4838, 'charisma': 4839, 'ex': 4840, 'drummer': 4841, 'gourmet': 4842, 'gymnast': 4843, 'hipster': 4844, 'realtor': 4845, 'trucker': 4846, 'intern': 4847, 'competent': 4848, 'deceitful': 4849, 'inventive': 4850, 'legendary': 4851, 'overjoyed': 4852, 'regretful': 4853, 'shameless': 4854, 'owner': 4855, 'ponies': 4856, 'steals': 4857, 'suggested': 4858, 'swears': 4859, 'abducted': 4860, 'babbling': 4861, 'cremated': 4862, 'ecstatic': 4863, 'executed': 4864, 'unshaven': 4865, 'berserk': 4866, 'bonkers': 4867, 'headstrong': 4868, \"war's\": 4869, 'robbery': 4870, 'swordfish': 4871, 'crisis': 4872, 'injuries': 4873, 'evacuate': 4874, 'withdraw': 4875, 'supplies': 4876, 'downsizing': 4877, 'historians': 4878, 'lifeguards': 4879, 'mates': 4880, 'fails': 4881, 'razor': 4882, '303': 4883, 'hamlet': 4884, 'wool': 4885, 'dyes': 4886, 'distant': 4887, 'failure': 4888, 'lunatic': 4889, 'leaf': 4890, \"screw's\": 4891, 'nests': 4892, 'champagne': 4893, 'chuck': 4894, 'ants': 4895, 'lager': 4896, 'latin': 4897, 'ignorant': 4898, 'petty': 4899, 'fry': 4900, 'rung': 4901, 'carried': 4902, 'chewed': 4903, 'gum': 4904, 'grain': 4905, 'roughly': 4906, 'fills': 4907, 'hanged': 4908, 'ego': 4909, 'remorse': 4910, 'daredevil': 4911, 'dramatist': 4912, 'osaka': 4913, 'miles': 4914, 'wakes': 4915, 'raging': 4916, 'scripts': 4917, 'buff': 4918, 'timer': 4919, 'undergrad': 4920, 'georgia': 4921, 'warnings': 4922, 'darkened': 4923, \"room's\": 4924, 'hamburger': 4925, 'baited': 4926, 'bid': 4927, 'cactus': 4928, 'webcam': 4929, 'shelter': 4930, 'register': 4931, 'sting': 4932, 'breakdown': 4933, 'hypocrites': 4934, 'interviews': 4935, 'desert': 4936, 'backache': 4937, 'migraine': 4938, 'sailboat': 4939, 'earache': 4940, 'discs': 4941, 'savings': 4942, 'jackpot': 4943, 'navy': 4944, 'bitten': 4945, 'challenges': 4946, 'folk': 4947, 'sauerkraut': 4948, 'spicy': 4949, 'odds': 4950, 'watermelon': 4951, 'hamburgers': 4952, 'performing': 4953, 'album': 4954, 'keyboard': 4955, 'toothpaste': 4956, 'oversleep': 4957, 'hood': 4958, '100': 4959, 'paused': 4960, 'tambourine': 4961, 'pruned': 4962, 'geography': 4963, 'otherwise': 4964, 'highway': 4965, '58': 4966, 'confess': 4967, 'workout': 4968, 'sympathy': 4969, 'mugged': 4970, 'misinformed': 4971, 'trespassing': 4972, 'harvard': 4973, 'salesperson': 4974, 'accountant': 4975, 'astronomer': 4976, 'bringing': 4977, 'bulgaria': 4978, 'irreplaceable': 4979, 'evicted': 4980, 'diarrhea': 4981, 'notarized': 4982, 'warranted': 4983, 'reward': 4984, 'stunning': 4985, 'pieces': 4986, 'ways': 4987, 'cooled': 4988, 'optional': 4989, 'massacre': 4990, 'convenient': 4991, 'disastrous': 4992, \"boys'\": 4993, 'confidential': 4994, 'questionable': 4995, 'imprecise': 4996, 'unauthorized': 4997, 'onerous': 4998, 'straws': 4999, 'investigate': 5000, 'peek': 5001, 'conquers': 5002, 'vivacious': 5003, \"heart's\": 5004, \"stomach's\": 5005, 'opposites': 5006, 'production': 5007, 'thorns': 5008, 'appeals': 5009, 'figure': 5010, 'thirty-one': 5011, 'turner': 5012, 'golden': 5013, 'lullaby': 5014, 'scale': 5015, 'termites': 5016, 'essential': 5017, 'fir': 5018, 'defense': 5019, 'undeniable': 5020, 'donkey': 5021, 'brayed': 5022, 'squeaked': 5023, 'rotates': 5024, 'jammed': 5025, 'dull': 5026, \"lock's\": 5027, 'motor': 5028, 'meager': 5029, \"pizza's\": 5030, 'thick': 5031, 'tactic': 5032, \"train's\": 5033, 'verdict': 5034, 'gods': 5035, 'cannibals': 5036, 'murderers': 5037, 'coconut': 5038, 'extortion': 5039, 'gibberish': 5040, 'insulting': 5041, 'irregular': 5042, 'justified': 5043, 'pointless': 5044, 'priceless': 5045, 'tasteless': 5046, 'worrisome': 5047, 'silver': 5048, 'arrives': 5049, 'behaved': 5050, 'despised': 5051, 'flinch': 5052, 'expects': 5053, 'iq': 5054, 'iphone': 5055, 'arthritis': 5056, 'skin': 5057, 'frostbite': 5058, 'seniority': 5059, 'don': 5060, 'juan': 5061, 'bookworm': 5062, 'jeweller': 5063, 'pushover': 5064, 'teenager': 5065, 'werewolf': 5066, 'believable': 5067, 'custody': 5068, 'therapy': 5069, 'indecisive': 5070, 'insightful': 5071, 'intolerant': 5072, 'passionate': 5073, 'perspiring': 5074, 'possessive': 5075, 'stuttering': 5076, 'unfaithful': 5077, 'mumbles': 5078, 'outlived': 5079, 'sneezes': 5080, 'vomited': 5081, 'updates': 5082, 'fanatic': 5083, 'negligent': 5084, 'imaginative': 5085, 'hibernate': 5086, 'acrylic': 5087, 'liquid': 5088, 'vaccine': 5089, 'suppliers': 5090, 'parks': 5091, 'canoe': 5092, 'mothers': 5093, 'journalists': 5094, 'collection': 5095, 'tacky': 5096, 'delay': 5097, 'confucius': 5098, 'drama': 5099, 'c': 5100, 'woods': 5101, 'wriggle': 5102, 'actresses': 5103, 'error': 5104, 'particular': 5105, 'scaring': 5106, 'unfriendly': 5107, 'revolt': 5108, 'brewing': 5109, 'admission': 5110, 'demanding': 5111, 'buddhist': 5112, 'believer': 5113, 'attendance': 5114, 'contains': 5115, 'hops': 5116, 'chirping': 5117, 'pillow': 5118, 'rackets': 5119, 'divide': 5120, 'conquer': 5121, 'copycat': 5122, 'patronize': 5123, 'relaxes': 5124, 'dust': 5125, 'shelf': 5126, 'endorse': 5127, 'breakable': 5128, 'lab': 5129, 'wrench': 5130, 'thanksgiving': 5131, \"od'd\": 5132, 'foolishly': 5133, 'footsteps': 5134, 'fishmonger': 5135, 'sharp-witted': 5136, 'heartless': 5137, 'thick-headed': 5138, 'judgement': 5139, 'retaliate': 5140, 'gives': 5141, 'rolled': 5142, 'thrust': 5143, 'weighs': 5144, '70': 5145, 'ghostwriter': 5146, 'keeper': 5147, 'meth': 5148, 'englishman': 5149, 'torn': 5150, 'sooty': 5151, 'eludes': 5152, 'quickened': 5153, 'untidy': 5154, 'economy': 5155, 'customers': 5156, 'portugal': 5157, 'shizuoka': 5158, 'chips': 5159, 'peanuts': 5160, 'clutch': 5161, 'exclude': 5162, 'clicked': 5163, 'detest': 5164, 'vodka': 5165, 'tests': 5166, 'fractured': 5167, 'goat': 5168, 'telescope': 5169, 'frizzy': 5170, 'appetite': 5171, 'invoice': 5172, 'rehearse': 5173, 'nephews': 5174, 'pans': 5175, 'jog': 5176, 'redecorated': 5177, 'irish': 5178, 'disco': 5179, 'translating': 5180, 'kakogawa': 5181, 'yokohama': 5182, 'poverty': 5183, 'bearded': 5184, 'butterflies': 5185, 'fairy': 5186, 'tales': 5187, 'photocopies': 5188, 'mopped': 5189, 'secretary': 5190, 'envelope': 5191, 'lotion': 5192, 'nutmeg': 5193, 'doubted': 5194, 'trumpet': 5195, 'slammed': 5196, 'cigarettes': 5197, 'psychology': 5198, 'unloaded': 5199, '1979': 5200, 'paraphrasing': 5201, 'introduce': 5202, 'photographer': 5203, 'bats': 5204, \"parents'\": 5205, 'harassed': 5206, 'singapore': 5207, 'poorer': 5208, 'gangster': 5209, 'magician': 5210, 'pacifist': 5211, 'delusional': 5212, 'slave': 5213, 'balcony': 5214, 'unenthusiastic': 5215, 'bliss': 5216, 'satisfactory': 5217, 'chained': 5218, 'milkman': 5219, 'deadly': 5220, 'parallel': 5221, 'pitch-black': 5222, 'preventable': 5223, 'distraction': 5224, 'proven': 5225, 'typo': 5226, 'experiment': 5227, 'investment': 5228, 'booby-trapped': 5229, 'disconcerting': 5230, 'heartbreaking': 5231, 'brass': 5232, 'merely': 5233, 'pertinent': 5234, 'greece': 5235, 'profile': 5236, 'trade': 5237, 'squabble': 5238, 'monopolies': 5239, 'universal': 5240, 'battery': 5241, 'budget': 5242, 'meows': 5243, 'fuel': 5244, 'goals': 5245, 'lofty': 5246, \"wife's\": 5247, \"now's\": 5248, 'restored': 5249, 'breed': 5250, 'postcard': 5251, 'aid': 5252, '35': 5253, 'pigeon-toed': 5254, 'ghostly': 5255, 'lonesome': 5256, 'antiques': 5257, 'happily': 5258, 'teaser': 5259, 'supermodel': 5260, 'phoning': 5261, 'destroyed': 5262, 'intent': 5263, 'promising': 5264, 'maximum': 5265, 'area': 5266, 'stale': 5267, \"cat's\": 5268, 'coast': 5269, 'crow': 5270, 'doorknob': 5271, 'flame': 5272, 'fog': 5273, 'caved': 5274, \"paint's\": 5275, 'drying': 5276, 'backfired': 5277, 'shops': 5278, 'squealed': 5279, 'waves': 5280, \"there're\": 5281, 'carnations': 5282, 'shaggy': 5283, 'triangle': 5284, 'apricot': 5285, 'octagon': 5286, 'astounding': 5287, 'outlandish': 5288, 'outrageous': 5289, 'plagiarism': 5290, 'unbearable': 5291, 'rag': 5292, 'tighten': 5293, 'instantly': 5294, 'lemonade': 5295, 'enjoys': 5296, 'unwanted': 5297, 'headaches': 5298, 'mustache': 5299, 'ponytail': 5300, \"john's\": 5301, 'candidate': 5302, 'librarian': 5303, 'machinist': 5304, 'activist': 5305, 'imposter': 5306, 'competitive': 5307, 'independent': 5308, 'insensitive': 5309, 'intoxicated': 5310, 'stark': 5311, 'supervising': 5312, 'parent': 5313, 'partying': 5314, 'drum': 5315, 'refuses': 5316, 'pacing': 5317, 'crusader': 5318, 'hysterical': 5319, 'irrational': 5320, 'payday': 5321, 'argued': 5322, 'assistance': 5323, 'sacrifice': 5324, 'convince': 5325, 'writers': 5326, 'eaters': 5327, 'honeymooning': 5328, 'pumpkin': 5329, 'vile': 5330, 'behavior': 5331, 'funeral': 5332, \"where're\": 5333, 'chapel': 5334, 'float': 5335, 'sulking': 5336, 'scar': 5337, 'softy': 5338, 'gal': 5339, 'princess': 5340, 'wimp': 5341, 'stray': 5342, 'whale': 5343, 'metals': 5344, 'pinch': 5345, 'sales': 5346, 'final': 5347, 'anyhow': 5348, \"anything's\": 5349, 'optimist': 5350, 'ducks': 5351, 'jellyfish': 5352, 'bunnies': 5353, 'chew': 5354, 'chivalry': 5355, 'cicadas': 5356, 'complaints': 5357, 'increasing': 5358, 'confusing': 5359, 'tip': 5360, 'detect': 5361, 'sarcasm': 5362, 'slam': 5363, 'grandma': 5364, 'samosa': 5365, 'grief': 5366, 'abused': 5367, 'irritated': 5368, 'boarded': 5369, 'illness': 5370, 'ferrari': 5371, 'sigh': 5372, 'mutton': 5373, 'chops': 5374, 'fellow': 5375, 'apt': 5376, 'indeed': 5377, 'lean': 5378, 'sociable': 5379, 'motivation': 5380, 'lays': 5381, 'wisecrack': 5382, 'motioned': 5383, 'muttered': 5384, 'cages': 5385, 'reached': 5386, 'saluted': 5387, 'swearing': 5388, 'ohio': 5389, 'chain': 5390, 'smoker': 5391, 'bloomer': 5392, 'cannon': 5393, 'scriptwriter': 5394, 'stand-up': 5395, 'fifties': 5396, 'sentry': 5397, 'cheeks': 5398, 'pudding': 5399, 'honesty': 5400, 'thai': 5401, 'reunion': 5402, 'noodles': 5403, 'india': 5404, 'peeling': 5405, 'vip': 5406, 'gauge': 5407, 'collect': 5408, 'postcards': 5409, 'poultry': 5410, 'cent': 5411, 'bribes': 5412, 'cereal': 5413, 'radios': 5414, 'premonition': 5415, 'nowhere': 5416, 'runny': 5417, 'appendicitis': 5418, 'chapped': 5419, 'lucid': 5420, 'elbow': 5421, 'woodpecker': 5422, 'whisper': 5423, 'rambling': 5424, 'chairs': 5425, 'blackberries': 5426, 'hangers': 5427, 'property': 5428, 'revised': 5429, 'footage': 5430, 'nude': 5431, 'suppressed': 5432, 'blend': 5433, 'worms': 5434, 'home-schooled': 5435, 'daiquiri': 5436, 'skim': 5437, 'butt': 5438, 'perfectionist': 5439, 'thirst': 5440, 'underwear': 5441, 'basement': 5442, 'loner': 5443, 'disagreeing': 5444, 'customer': 5445, 'practising': 5446, 'judo': 5447, 'victim': 5448, 'figured': 5449, 'claus': 5450, 'comprehensive': 5451, 'significant': 5452, 'jasmine': 5453, 'permissible': 5454, 'profitable': 5455, 'drizzle': 5456, 'appetizing': 5457, 'shark': 5458, 'solar': 5459, 'mind-numbing': 5460, 'unpardonable': 5461, 'cause': 5462, 'brain-teaser': 5463, 'comedy': 5464, 'dreary': 5465, 'slippery': 5466, 'arranged': 5467, 'backpack': 5468, 'fantasy': 5469, 'placebo': 5470, 'non-refundable': 5471, 'negotiable': 5472, 'clunky': 5473, 'limbo': 5474, 'stuffy': 5475, 'unbearably': 5476, 'asians': 5477, 'overreact': 5478, 'fiancée': 5479, 'napkin': 5480, 'merlin': 5481, 'monkeys': 5482, '1791': 5483, 'aunt': 5484, 'rise': 5485, 'catnip': 5486, 'gritty': 5487, 'items': 5488, 'supported': 5489, 'excluded': 5490, 'nutritious': 5491, 'ostriches': 5492, 'mumble': 5493, 'curb': 5494, 'safety': 5495, 'paramount': 5496, 'boards': 5497, 'boiled': 5498, 'convulsions': 5499, 'chatterbox': 5500, 'bad-mannered': 5501, 'dark-skinned': 5502, 'laced': 5503, 'shinjuku': 5504, 'shaved': 5505, 'penniless': 5506, 'self-employed': 5507, 'someday': 5508, 'scales': 5509, 'strap': 5510, 'taxis': 5511, 'thailand': 5512, 'info': 5513, \"idea's\": 5514, 'suffice': 5515, 'months': 5516, 'imitation': 5517, 'reasoning': 5518, 'uncommon': 5519, 'self-evident': 5520, 'blouse': 5521, 'cheering': 5522, 'ceased': 5523, 'crops': 5524, 'folder': 5525, 'decent': 5526, 'dusty': 5527, 'collapsed': 5528, 'rags': 5529, 'shining': 5530, 'deepens': 5531, 'leaked': 5532, 'pond': 5533, 'stores': 5534, 'bare': 5535, 'abated': 5536, 'spoons': 5537, 'motive': 5538, 'condition': 5539, 'elevator': 5540, 'chorus': 5541, \"son's\": 5542, 'wormy': 5543, 'minds': 5544, 'forum': 5545, 'newspaper': 5546, 'devastating': 5547, 'encouraging': 5548, 'indian': 5549, 'mango': 5550, 'sheet': 5551, 'tin': 5552, 'botched': 5553, 'collects': 5554, 'comics': 5555, 'googled': 5556, 'tonsillitis': 5557, 'biochemist': 5558, 'con': 5559, 'diver': 5560, 'lumberjack': 5561, 'pharmacist': 5562, 'politician': 5563, 'anarchist': 5564, 'astronaut': 5565, 'economist': 5566, 'inspector': 5567, 'intellectual': 5568, 'level-headed': 5569, 'multilingual': 5570, 'presumptuous': 5571, 'right-handed': 5572, 'cream': 5573, 'spaghetti': 5574, 'cave': 5575, 'banjo': 5576, 'prefers': 5577, 'blondes': 5578, 'sorted': 5579, 'blacklisted': 5580, 'cooperative': 5581, 'interrupted': 5582, 'magnificent': 5583, 'cellmate': 5584, 'traumatized': 5585, 'ties': 5586, 'races': 5587, 'full-time': 5588, 'provide': 5589, 'shade': 5590, 'coffees': 5591, 'vegemite': 5592, 'concerns': 5593, 'teams': 5594, 'cast': 5595, 'ourselves': 5596, 'among': 5597, 'strangers': 5598, 'champions': 5599, 'bizarre': 5600, 'achievement': 5601, 'dragons': 5602, 'brunch': 5603, 'sunset': 5604, 'fare': 5605, 'forks': 5606, 'goats': 5607, 'luggage': 5608, 'airport': 5609, 'addressing': 5610, 'forgetting': 5611, 'bible': 5612, 'babe': 5613, 'limping': 5614, 'neptune': 5615, 'duped': 5616, 'irresistible': 5617, 'zebras': 5618, 'stripes': 5619, 'amputation': 5620, 'slippers': 5621, 'backstage': 5622, 'extend': 5623, 'colonize': 5624, 'buck': 5625, 'loving': 5626, 'context': 5627, 'damascus': 5628, 'syria': 5629, 'bagpipes': 5630, 'kimono': 5631, 'dolphins': 5632, 'bump': 5633, 'exert': 5634, 'spoil': 5635, 'dublin': 5636, 'ireland': 5637, 'detail': 5638, 'fears': 5639, 'clumsiness': 5640, 'extension': 5641, '45': 5642, 'differences': 5643, 'bedding': 5644, 'hatred': 5645, 'aimed': 5646, 'begged': 5647, 'bent': 5648, 'rescue': 5649, 'clipped': 5650, 'geneva': 5651, 'hardware': 5652, 'devoured': 5653, 'emptied': 5654, 'dander': 5655, 'doctorate': 5656, 'income': 5657, 'accent': 5658, 'nimble': 5659, 'harsh': 5660, 'unsung': 5661, 'energy': 5662, 'diving': 5663, 'self': 5664, 'precious': 5665, 'savage': 5666, 'sadly': 5667, 'gloves': 5668, 'willing': 5669, 'leaned': 5670, 'towards': 5671, 'steaks': 5672, 'pressed': 5673, 'sketched': 5674, 'ligament': 5675, 'cell': 5676, 'busboy': 5677, 'influence': 5678, 'lung': 5679, 'offered': 5680, 'clown': 5681, 'unknown': 5682, 'amazes': 5683, 'sacred': 5684, 'huskies': 5685, 'basque': 5686, 'drawing': 5687, 'weighing': 5688, 'applied': 5689, 'malice': 5690, 'ashtray': 5691, 'daydreamed': 5692, 'mince': 5693, 'badge': 5694, 'grudges': 5695, 'mussels': 5696, 'peaches': 5697, 'vomiting': 5698, 'hard-boiled': 5699, 'dubbed': 5700, 'goodbyes': 5701, 'tumor': 5702, 'wooden': 5703, 'invitation': 5704, 'bottled': 5705, 'objections': 5706, 'statistics': 5707, 'twig': 5708, 'district': 5709, 'fruits': 5710, 'diversity': 5711, 'optimism': 5712, 'flashlight': 5713, 'sunglasses': 5714, 'track': 5715, 'economics': 5716, 'blacked': 5717, 'pleaded': 5718, 'pumped': 5719, 'lightning': 5720, 'plot': 5721, 'afoot': 5722, 'e-mail': 5723, 'skimmed': 5724, '9:00': 5725, 'topic': 5726, 'switched': 5727, 'tightened': 5728, 'react': 5729, 'tap': 5730, 'mp3': 5731, 'go-between': 5732, 'corn': 5733, 'eighth': 5734, 'grader': 5735, 'attracted': 5736, 'depending': 5737, 'fluent': 5738, 'folding': 5739, 'juggling': 5740, 'hitting': 5741, 'specialist': 5742, 'sides': 5743, 'meetings': 5744, 'vindicated': 5745, 'filling': 5746, '23': 5747, 'regular': 5748, 'stern': 5749, 'sprinkle': 5750, 'glows': 5751, 'fashion': 5752, '$10': 5753, '00': 5754, 'tedious': 5755, 'grueling': 5756, 'heart-warming': 5757, 'sham': 5758, 'giveaway': 5759, 'longish': 5760, 'scalp': 5761, 'thankless': 5762, 'greek': 5763, 'courtesy': 5764, 'peninsula': 5765, 'entertained': 5766, 'kindness': 5767, 'beget': 5768, 'begins': 5769, 'lincoln': 5770, '1865': 5771, 'lions': 5772, 'colorblind': 5773, 'blinding': 5774, 'ruler': 5775, 'program': 5776, 'lobby': 5777, 'misery': 5778, 'accomplished': 5779, 'watering': 5780, 'grows': 5781, 'exploding': 5782, 'frayed': 5783, 'rockets': 5784, 'escapes': 5785, 'expendable': 5786, 'forcing': 5787, 'oops': 5788, 'phew': 5789, 'insert': 5790, 'postman': 5791, 'herself': 5792, 'hostile': 5793, 'mended': 5794, 'picnic': 5795, 'belly': 5796, 'smog': 5797, 'permitted': 5798, 'squirrels': 5799, 'acorns': 5800, 'clowning': 5801, 'bandit': 5802, 'becomes': 5803, 'narrows': 5804, 'blatant': 5805, \"woman's\": 5806, 'pseudoscience': 5807, 'basket': 5808, 'bin': 5809, \"coffee's\": 5810, 'nipped': 5811, \"feeling's\": 5812, 'mutual': 5813, 'gang': 5814, 'heater': 5815, 'haunted': 5816, 'ablaze': 5817, 'lakes': 5818, 'bulb': 5819, 'bleak': 5820, 'flop': 5821, 'penalty': 5822, 'trivial': 5823, 'roads': 5824, 'rigged': 5825, 'shifting': 5826, 'conditions': 5827, 'exceptions': 5828, 'threats': 5829, 'plums': 5830, 'ripe': 5831, 'tenderly': 5832, 'sending': 5833, 'benefits': 5834, 'diamond': 5835, 'essay': 5836, 'wand': 5837, \"child's\": 5838, 'blowing': 5839, 'unacceptable': 5840, 'cramped': 5841, '€30': 5842, 'overboard': 5843, 'subjects': 5844, 'congratulated': 5845, 'craves': 5846, 'sloppy': 5847, 'slanted': 5848, 'sox': 5849, 'bass': 5850, 'billionaire': 5851, 'businessman': 5852, 'firefighter': 5853, 'glassblower': 5854, 'sleepwalker': 5855, 'disrespectful': 5856, 'morgue': 5857, 'indispensable': 5858, 'philosophical': 5859, 'schizophrenic': 5860, 'self-centered': 5861, 'strongest': 5862, 'wiser': 5863, 'arithmetic': 5864, 'ceremonies': 5865, 'perused': 5866, 'reloaded': 5867, 'rinsed': 5868, 'fence': 5869, 'unbothered': 5870, 'fertilizer': 5871, 'thanked': 5872, 'competitor': 5873, 'clean-shaven': 5874, 'electrocuted': 5875, 'straw': 5876, 'cellphone': 5877, 'healing': 5878, 'stake': 5879, 'naturally': 5880, 'unemployment': 5881, 'reflects': 5882, 'canoed': 5883, 'downstream': 5884, 'unsuccessful': 5885, 'factory': 5886, 'recession': 5887, 'barbarians': 5888, 'evacuating': 5889, 'terrorists': 5890, 'opposed': 5891, 'bullets': 5892, 'planting': 5893, 'seeds': 5894, 'discussed': 5895, 'blindfolded': 5896, 'splendid': 5897, 'seagulls': 5898, 'involve': 5899, 'aiming': 5900, 'plus': 5901, 'nickname': 5902, 'username': 5903, 'guards': 5904, 'meters': 5905, 'chainsaw': 5906, 'entrance': 5907, 'washroom': 5908, 'pies': 5909, 'coaches': 5910, 'gonna': 5911, 'twinkle': 5912, \"why's\": 5913, 'workaholic': 5914, 'impress': 5915, 'bullseye': 5916, \"guard's\": 5917, 'continent': 5918, 'ah': 5919, 'barcelona': 5920, 'berries': 5921, 'brad': 5922, 'pitt': 5923, 'scissors': 5924, 'braille': 5925, 'communication': 5926, 'compasses': 5927, 'sentence': 5928, 'sucks': 5929, 'dishonor': 5930, 'caesar': 5931, 'transfer': 5932, 'lighter': 5933, 'anchovies': 5934, 'bean': 5935, 'geraniums': 5936, 'bones': 5937, 'cheapskate': 5938, 'commit': 5939, 'delude': 5940, 'riled': 5941, 'hesitate': 5942, 'double-click': 5943, 'icon': 5944, 'asks': 5945, 'suffering': 5946, 'seatbelts': 5947, 'intrusion': 5948, 'attended': 5949, 'spoken': 5950, 'fur': 5951, 'coats': 5952, 'created': 5953, 'universe': 5954, \"valentine's\": 5955, 'woken': 5956, 'avenged': 5957, 'several': 5958, 'nor': 5959, 'certainly': 5960, 'england': 5961, 'crawled': 5962, 'furniture': 5963, 'shed': 5964, 'tear': 5965, 'overwork': 5966, 'sudden': 5967, '90%': 5968, 'poise': 5969, 'hopes': 5970, 'interpreted': 5971, 'prankster': 5972, 'fossil': 5973, 'wealth': 5974, 'self-made': 5975, 'sharp-shooter': 5976, 'officer': 5977, 'blinded': 5978, 'ordinary': 5979, 'tallest': 5980, 'ninety': 5981, 'village': 5982, 'grid': 5983, 'practices': 5984, 'presented': 5985, 'proved': 5986, 'slipped': 5987, 'sprained': 5988, 'tends': 5989, 'choke': 5990, 'unzipped': 5991, 'limp': 5992, 'painfully': 5993, 'bronze': 5994, 'hurriedly': 5995, 'notorious': 5996, 'oceanographer': 5997, 'anger': 5998, 'numbered': 5999, 'waiter': 6000, 'deodorant': 6001, 'biwa': 6002, 'huh': 6003, 'courage': 6004, '100%': 6005, 'harvesting': 6006, 'curry': 6007, 'miracles': 6008, 'exists': 6009, 'dozen': 6010, 'collarbone': 6011, 'fingernail': 6012, 'farther': 6013, 'jar': 6014, 'chopped': 6015, 'crammed': 6016, 'push-ups': 6017, 'wink': 6018, 'brag': 6019, 'riddles': 6020, 'advisers': 6021, 'recall': 6022, 'salsa': 6023, 'extended': 6024, 'earthquake': 6025, 'briefcase': 6026, 'sickness': 6027, 'pierced': 6028, 'thoughts': 6029, 'wrist': 6030, 'self-esteem': 6031, 'plenty': 6032, 'pains': 6033, 'ex-wives': 6034, 'honestly': 6035, 'stubbed': 6036, 'mosquito': 6037, 'frankness': 6038, 'musicians': 6039, 'romance': 6040, 'novels': 6041, 'unwind': 6042, 'blues': 6043, 'bucks': 6044, 'pigged': 6045, 'pine': 6046, 'postponed': 6047, 'vividly': 6048, 'sharpened': 6049, 'urgently': 6050, 'korea': 6051, 'sedated': 6052, 'hoping': 6053, 'spirits': 6054, 'videos': 6055, 'overly': 6056, 'europe': 6057, 'embassy': 6058, \"mcdonald's\": 6059, 'jiff': 6060, 'margarita': 6061, 'court': 6062, 'needles': 6063, 'tricks': 6064, 'undercover': 6065, 'restaurant': 6066, 'brushing': 6067, 'failing': 6068, 'undressed': 6069, 'languages': 6070, 'inclined': 6071, 'disbeliever': 6072, 'millionaire': 6073, 'unsympathetic': 6074, 'mechanic': 6075, 'swamped': 6076, 'blocks': 6077, 'mall': 6078, 'okayama': 6079, 'install': 6080, 'helicopter': 6081, 'perfume': 6082, 'code': 6083, 'gravy': 6084, 'frosted': 6085, 'luxury': 6086, 'cruise': 6087, 'bleach': 6088, 'impulse': 6089, 'chaotic': 6090, 'stiflingly': 6091, 'understandable': 6092, 'cultural': 6093, 'one-time': 6094, 'senseless': 6095, 'work-related': 6096, 'deeper': 6097, 'brighter': 6098, 'relatively': 6099, 'sentences': 6100, 'hairs': 6101, 'dodge': 6102, 'poster': 6103, 'opens': 6104, 'delayed': 6105, 'cries': 6106, 'expense': 6107, 'spared': 6108}\n",
            "<keras_preprocessing.text.Tokenizer object at 0x7f247342ce50>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxg19hXE4PL-",
        "outputId": "edab29bf-bb38-4ca8-9635-69db531ba3b3"
      },
      "source": [
        "#creating bacthes for training and validation \n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40000 40000 10000 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS51-N5P4Q4o"
      },
      "source": [
        "def convert(lang, tensor):\n",
        "    for t in tensor:\n",
        "        if t!=0:\n",
        "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZyK0imm4SUJ",
        "outputId": "8cd780be-d53f-4c12-836a-03fbb99fdfb1"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "117 ----> what's\n",
            "11 ----> the\n",
            "726 ----> message\n",
            "5 ----> ?\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "136 ----> quel\n",
            "12 ----> est\n",
            "14 ----> le\n",
            "3934 ----> message \n",
            "5 ----> ?\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl3CbnyH4Tt7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a91e66aa-fe0f-4b46-d121-e69a1b23b18c"
      },
      "source": [
        "BUFFER_SIZE=len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedin_dim = 256\n",
        "units=1024\n",
        "vocab_inp_size=len(inp_lang.word_index)+1\n",
        "vocab_tar_size=len(targ_lang.word_index)+1\n",
        "print(vocab_inp_size)\n",
        "print(vocab_tar_size)\n",
        "print(BUFFER_SIZE)\n",
        "\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train,target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE,drop_remainder=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6109\n",
            "14075\n",
            "40000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isEMNW2B4XDa",
        "outputId": "47c53566-065f-4cd4-8b45-595884772106"
      },
      "source": [
        "example_input_batch,example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape,example_target_batch.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 11]), TensorShape([64, 18]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-cH2P0V4Zgd"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self,vocab_size,embedding_dim,enc_units,batch_sz):\n",
        "        super(Encoder,self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size,embedin_dim)\n",
        "        self.gru = tf.keras.layers.GRU(\n",
        "            self.enc_units,\n",
        "            return_sequences=True,\n",
        "            return_state=True,\n",
        "            recurrent_initializer='glorot_uniform'\n",
        "        )\n",
        "        \n",
        "    def call(self,x,hidden):\n",
        "        #x is our input\n",
        "        x=self.embedding(x)\n",
        "        output,state = self.gru(x,initial_state=hidden)\n",
        "        return output,state\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz,self.enc_units))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYGsGOJR4a3x"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size,embedin_dim,units,BATCH_SIZE)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APzFcSQX4chY",
        "outputId": "93ae5dce-bdf0-49a1-9616-fc670fefa6df"
      },
      "source": [
        "#sample to check the layers are working \n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output,sample_hidden = encoder(example_input_batch,sample_hidden)\n",
        "\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 11, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GNyBgGo4gqV"
      },
      "source": [
        "# I am Using the Bahdanau Attention for encoding the parameters are:-\n",
        "* FC = Fully connected (dense) layer\n",
        "* EO = Encoder output\n",
        "* H = hidden state\n",
        "* X = input to the decoder\n",
        "* The pseudo code for each is:-\n",
        "* 1)score = FC(tanh(FC(EO) + FC(H)))\n",
        "* 2)attention weights = softmax(score, axis = 1)\n",
        "* 3)context vector = sum(attention weights * EO, axis = 1)\n",
        "* 4)embedding output = It is got from the input passed to the Decoder Embedding Layer.\n",
        "* 5)merged vector = concat(embedding output, context vector)\n",
        "* note:-\n",
        "* This merged vector is then passed to gru layer as hidden state\n",
        "* note:-\n",
        "* axis=1 is there because we have to make change accross the max_len field so we took axis 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pAhUPzz4dqz"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self,units):\n",
        "        super(BahdanauAttention,self).__init__()\n",
        "        self.w1=tf.keras.layers.Dense(units)\n",
        "        self.w2=tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "        \n",
        "    def call(self,query,values):\n",
        "        #we will be doing it to get addition along the time axis to calculate the score\n",
        "        query_with_time_axis = tf.expand_dims(query,1)\n",
        "        \n",
        "        #shape of the score will be(batchsize,maxlength,1)\n",
        "        #1 is because it is passing through the final dense layer having units ==1\n",
        "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "        score = self.V(tf.nn.tanh(self.w1(query_with_time_axis)+self.w2(values)))\n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(score,axis=1)\n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector=attention_weights * values\n",
        "        context_vector=tf.reduce_sum(context_vector,axis=1)\n",
        "        \n",
        "        return context_vector,attention_weights"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-El59rpF4qsK",
        "outputId": "5936c858-96f5-4e9a-a952-06839251211f"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result,attention_weights=attention_layer(sample_hidden,sample_output)\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 11, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUKeehOx4uNX"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,vocab_size,embedding_dim,dec_units,batch_sz):\n",
        "        super(Decoder,self).__init__()\n",
        "        self.batch_sz=batch_sz\n",
        "        self.dec_units=dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size,embedding_dim)\n",
        "        self.gru=tf.keras.layers.GRU(\n",
        "            self.dec_units,\n",
        "            return_sequences=True,\n",
        "            return_state=True,\n",
        "            recurrent_initializer='glorot_uniform'\n",
        "        )\n",
        "        self.fc=tf.keras.layers.Dense(\n",
        "            vocab_size\n",
        "        )\n",
        "        \n",
        "        #used for attention\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "    def call(self,x,hidden,enc_output):\n",
        "        context_vector,attention_weights=self.attention(hidden,enc_output)\n",
        "        \n",
        "        x=self.embedding(x)\n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        output,state = self.gru(x)\n",
        "        output=tf.reshape(output,(-1,output.shape[2]))\n",
        "        \n",
        "        x = self.fc(output)\n",
        "        \n",
        "        return x,state,attention_weights"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZSHPQXc4wa8",
        "outputId": "a54b995a-662e-46b5-80d0-87919f4b46e5"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedin_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 14075)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m8TUJ0m4x_i"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,reduction='none'\n",
        ")\n",
        "def loss_function(real,pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real,0))\n",
        "    loss_ = loss_object(real,pred)\n",
        "    \n",
        "    mask = tf.cast(mask,dtype=loss_.dtype)\n",
        "    loss_ *=mask\n",
        "    \n",
        "    return loss_"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srvboxn94z3-"
      },
      "source": [
        "checkpoint_dir = 'training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ubQyZi441VR"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp,targ,enc_hidden):\n",
        "    loss=0\n",
        "    #gradient tape is typically diffrention for complex tensors\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output,enc_hidden=encoder(inp,enc_hidden)\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "        \n",
        "        #using teacher forcing method to feed the target as next input\n",
        "        for t in range(1,targ.shape[1]):\n",
        "            #passing the enc_output to the decoder\n",
        "            predictions,dec_hidden,_=decoder(dec_input,dec_hidden,enc_output)\n",
        "            \n",
        "            loss +=loss_function(targ[:,t],predictions)\n",
        "            \n",
        "            dec_input = tf.expand_dims(targ[:,t],1)\n",
        "        batch_loss = (loss/int(targ.shape[1]))\n",
        "        variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "        gradients = tape.gradient(loss,variables)\n",
        "        \n",
        "        optimizer.apply_gradients(zip(gradients,variables))\n",
        "        return batch_loss"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PmhmQKd42zY",
        "outputId": "60d3623d-5ab7-49a2-e136-5aa9aa5bc7af"
      },
      "source": [
        "EPOCHS=10\n",
        "for epoch in range(EPOCHS):\n",
        "    start =time.time()\n",
        "    \n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss=0\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp,targ,enc_hidden)\n",
        "        total_loss+=batch_loss\n",
        "        if batch %100==0:\n",
        "            print(f'Epoch {epoch + 1} Batch {batch} Loss {batch_loss.numpy()}')\n",
        "    if(epoch+1)%2==0:\n",
        "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "        \n",
        "    print(f'Epoch {epoch + 1} Loss {total_loss / steps_per_epoch}')\n",
        "    print(f'Time taken for 1 epoch {time.time() - start} sec\\n')    "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss [5.837497  2.6531856 4.2450824 4.245537  2.122713  3.1840444 3.1837907\n",
            " 3.7147496 3.7148361 1.5922009 3.7153466 3.1842995 3.1844156 3.7149591\n",
            " 2.1229002 3.1841407 3.7154355 2.1230056 3.7153313 2.6535425 3.714708\n",
            " 3.1840699 2.6534212 4.2453117 5.307643  3.7152667 3.7149036 2.6535983\n",
            " 4.7762322 3.1847517 3.714926  2.6536958 3.7145674 2.653354  2.1225865\n",
            " 4.2459936 2.6530106 3.7150438 1.5923212 3.1841862 2.6538885 3.1838129\n",
            " 3.1839268 2.6533082 3.7149022 3.183662  3.1840181 2.6535897 4.2454233\n",
            " 2.6532261 3.184066  2.653236  3.1838372 1.5922056 3.7148726 3.1840603\n",
            " 3.7149134 2.6534066 2.6534772 3.1839325 3.7145076 2.653475  2.1227167\n",
            " 3.184739 ]\n",
            "Epoch 1 Batch 100 Loss [1.4213924  2.116158   1.4574189  1.0247284  1.4611018  1.103369\n",
            " 1.5620304  0.94940263 1.518529   1.4542809  2.183061   1.1603969\n",
            " 1.6230484  1.5375245  1.0882508  2.3778205  1.5599217  1.2781733\n",
            " 1.296487   1.5415001  1.4695408  1.6050098  1.2004621  1.4313941\n",
            " 1.852975   1.7475029  1.7176414  1.9606192  0.8880293  2.134762\n",
            " 1.6287575  1.4481725  1.5689852  1.9301476  2.3663654  0.7799244\n",
            " 2.0667655  1.5741268  1.7433671  3.0787594  2.2908835  1.2251034\n",
            " 1.1359638  0.69366425 1.6449072  1.4718069  2.0624235  2.281992\n",
            " 1.9044846  1.6113921  1.7726607  1.5252813  1.8148092  1.433765\n",
            " 1.8264318  1.7668219  1.9657121  1.4832832  1.2535477  1.4583799\n",
            " 2.0888293  1.4634585  1.8710147  1.0283244 ]\n",
            "Epoch 1 Batch 200 Loss [1.8547099  1.8869765  1.4784466  1.709792   0.97803086 0.97355354\n",
            " 0.989499   1.90459    1.5531152  1.7372417  1.8386323  1.3335664\n",
            " 1.8134766  1.3998009  1.5847787  1.1553828  0.92147565 1.3932555\n",
            " 2.8215883  1.3340318  1.1700035  1.1935259  1.9845115  1.856342\n",
            " 1.8617022  1.8785629  2.6142385  2.3152583  1.6289603  1.3971297\n",
            " 1.6537768  2.777202   1.7380911  1.5263687  1.4858439  1.2597414\n",
            " 0.8737074  1.9895003  1.3037345  1.9192137  1.8990781  1.1657712\n",
            " 1.5282364  1.4402951  1.480192   1.5884247  1.5456184  1.0631613\n",
            " 1.119623   1.6716772  1.3106046  1.8400522  0.97970986 0.6864485\n",
            " 1.1056219  0.7868999  2.440187   1.7308327  1.1390454  0.61124945\n",
            " 1.4775969  0.9502555  1.5863484  1.667273  ]\n",
            "Epoch 1 Batch 300 Loss [1.4176855  1.7617896  0.6285656  1.8615845  0.8215191  0.9634977\n",
            " 1.973708   1.2991666  1.8685226  1.7372706  1.4314467  1.5668193\n",
            " 0.64728075 0.9624996  1.1716601  1.9643742  1.0083613  1.482944\n",
            " 1.8314137  1.3699719  1.6707667  0.98507524 1.8843776  1.4964911\n",
            " 1.2173529  0.9308541  1.2009939  1.7593018  1.0390735  0.9287491\n",
            " 2.5865831  1.5400186  1.5267658  1.1246834  1.5997736  1.2115661\n",
            " 1.4779786  1.8567069  1.7253946  1.0602624  1.3419707  1.4653469\n",
            " 2.0013242  1.5345762  0.84166414 1.2184514  1.307346   1.1457752\n",
            " 1.5200539  1.9990128  1.1865209  1.424483   1.5203112  1.9552915\n",
            " 1.3599554  0.88767046 1.4598993  0.6542919  1.5645489  1.3521159\n",
            " 0.8921796  0.9179035  1.3413414  1.4666792 ]\n",
            "Epoch 1 Batch 400 Loss [1.1592096  1.2427114  0.9883622  2.17818    0.8911849  1.0359418\n",
            " 0.8209624  0.75394905 1.2930309  0.7083599  2.1835332  1.3537992\n",
            " 0.8572753  1.5966619  1.7079655  1.0407825  0.8790091  2.328195\n",
            " 1.3795773  1.3952783  1.664175   1.3603116  1.7786568  2.3074734\n",
            " 2.107872   1.4891149  1.2190579  1.3283263  1.1934876  1.1252743\n",
            " 1.3601223  1.0101175  0.92411655 1.9459915  1.0758847  1.0854768\n",
            " 1.6129124  1.1403525  0.9736366  1.3420056  0.9297905  0.76386994\n",
            " 1.7180809  1.5543722  0.8518866  1.0644464  1.6899642  1.4216629\n",
            " 0.8493948  1.0414758  0.8030324  1.0833902  1.3202057  0.68882984\n",
            " 1.4996526  0.8437311  1.1262453  1.5513878  1.0365225  1.1902614\n",
            " 1.0358473  1.040601   1.0772237  1.0952591 ]\n",
            "Epoch 1 Batch 500 Loss [1.5983835  1.0384485  1.0174023  1.7206743  1.2716042  1.4430289\n",
            " 1.145503   1.9389416  1.0942211  1.3429506  1.4851867  1.2478303\n",
            " 1.1765469  0.88813084 0.65599114 0.8623155  0.65020645 1.3483704\n",
            " 1.0585018  0.8068085  0.7014067  2.3204906  1.0705551  0.6805577\n",
            " 1.3778322  1.3073237  0.77945316 1.8076615  1.5336514  1.0034424\n",
            " 0.8052856  0.7255025  2.1986933  0.7790402  0.99010426 0.8435408\n",
            " 1.1782525  1.8529271  1.3736556  1.1253651  1.1619611  0.98447216\n",
            " 0.66651505 1.345137   1.0700153  1.5072278  1.5013578  1.4365836\n",
            " 1.425458   1.3749294  0.9621014  0.85795444 1.0988908  1.0207803\n",
            " 1.3051687  1.0266783  1.1180283  2.013299   0.6656331  1.084923\n",
            " 1.1385214  0.69968396 1.0304528  1.764159  ]\n",
            "Epoch 1 Batch 600 Loss [1.1786896  1.6170866  1.1767758  0.9165378  1.1385587  1.1345823\n",
            " 1.152263   1.009138   2.010997   1.0057576  3.3130682  0.7443106\n",
            " 0.89882046 1.8635314  1.1414534  0.9700625  1.0604259  1.3487301\n",
            " 0.5091103  0.8931529  2.3640416  0.8197455  0.9213563  0.94967395\n",
            " 0.6581412  1.533825   1.3588736  1.482139   0.9713082  1.994705\n",
            " 1.3258939  1.0542065  1.3851768  0.9866703  1.2520237  1.0599904\n",
            " 0.8284978  1.0059804  0.6523564  0.84528095 0.9454833  2.5581925\n",
            " 0.84573656 1.5265648  1.2371166  1.0493349  0.96718526 1.313893\n",
            " 1.0645741  1.416357   1.209549   2.2855248  1.8940455  1.5690842\n",
            " 2.132243   1.4004163  1.0537349  1.3570045  0.72636086 1.5610011\n",
            " 0.8822716  0.50011045 1.5471739  0.9299023 ]\n",
            "Epoch 1 Loss [1.4549248 1.4297923 1.4133185 1.4048605 1.400369  1.4434472 1.4449823\n",
            " 1.4269155 1.4228642 1.4117804 1.4328903 1.4225272 1.4050553 1.4113069\n",
            " 1.4473491 1.4329172 1.4128177 1.4279448 1.4309133 1.3833936 1.4165113\n",
            " 1.453935  1.4270225 1.4299036 1.4334198 1.4238565 1.4053861 1.4085845\n",
            " 1.4319103 1.3921094 1.4108921 1.3996618 1.4408219 1.4331588 1.3930936\n",
            " 1.4377834 1.4554868 1.4374884 1.4191744 1.451114  1.415376  1.423954\n",
            " 1.4189053 1.4244713 1.4301685 1.4294466 1.4164836 1.4266236 1.4150447\n",
            " 1.4178679 1.4190241 1.4541771 1.4435437 1.4239764 1.4134127 1.4253027\n",
            " 1.3991451 1.4340852 1.4411958 1.4365942 1.4238918 1.422821  1.4239007\n",
            " 1.4194711]\n",
            "Time taken for 1 epoch 97.95131349563599 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss [0.96246827 0.5923441  0.50294626 1.0470113  2.4046626  0.5140573\n",
            " 0.9492052  0.83942056 1.5146501  1.1644534  0.8294031  0.6658264\n",
            " 1.040642   0.8183084  0.6421569  1.024826   1.261688   0.9136346\n",
            " 0.8192911  0.7671939  1.2177976  0.7829339  0.77387315 2.3668315\n",
            " 0.7212565  1.5361879  1.0987557  0.65380365 1.6126401  1.2750117\n",
            " 1.0291214  1.1654449  1.9545037  1.2714139  1.4417089  0.79464513\n",
            " 1.4938357  1.8463658  0.85432535 0.69841546 1.0639673  1.8023142\n",
            " 1.2770466  1.0732889  0.837412   0.68401116 0.8308994  1.265596\n",
            " 1.1167256  0.7691063  1.0073581  0.83501405 0.5019542  0.6546602\n",
            " 0.5506909  0.77227235 1.0187955  1.8727705  1.6622851  0.6140648\n",
            " 0.53628296 1.085541   1.0526491  1.0257365 ]\n",
            "Epoch 2 Batch 100 Loss [0.8487582  0.8914832  0.92012966 0.9331029  1.0156206  0.79238904\n",
            " 1.0082031  1.6064345  1.0377979  0.94129044 1.1569976  1.166501\n",
            " 0.96182907 1.3904369  1.3998339  0.43633237 1.5623686  1.6911833\n",
            " 0.97736496 1.2975527  1.310537   0.61803526 1.0239588  1.0256137\n",
            " 0.8967141  1.3127128  0.58531845 1.2405565  0.79946    1.1282709\n",
            " 0.7266728  0.63481176 0.7028269  0.6806529  0.63830787 0.7443404\n",
            " 1.1708428  1.5600865  1.280212   0.78705674 1.1686558  1.3647562\n",
            " 1.1198574  1.2440249  1.2286954  0.6535763  1.567794   1.3531265\n",
            " 1.6841127  1.4336607  0.6046429  1.59227    0.7717442  0.56925076\n",
            " 1.1047267  1.6845943  0.8166208  1.5149398  1.4663607  1.121144\n",
            " 3.0773313  0.6869922  1.3723983  0.6019488 ]\n",
            "Epoch 2 Batch 200 Loss [1.4072684  1.1339114  1.0407999  0.73982185 0.7802079  1.8424217\n",
            " 0.70574397 1.1019633  0.67512894 1.0674187  1.3449906  0.8119436\n",
            " 1.0653827  0.43478578 1.2627127  1.8705163  1.542701   1.13198\n",
            " 0.9902529  0.93831086 0.9487408  1.1202213  1.1138018  1.2185694\n",
            " 1.1384975  0.99354744 1.6415232  1.0554421  1.445707   1.509925\n",
            " 0.969947   0.9562095  1.138756   0.92404103 1.1312153  0.7935742\n",
            " 1.2556483  0.57185775 0.9239134  1.8443568  1.6924746  1.0807528\n",
            " 1.9542798  0.74056226 0.9755212  1.4632821  1.6015652  1.5758168\n",
            " 1.1763262  1.3316475  0.67446834 0.6254702  0.83414376 1.6819849\n",
            " 0.86664623 0.91479856 1.3455215  0.9062695  1.0419104  0.81878173\n",
            " 1.3726858  1.1960553  1.7641629  0.79655725]\n",
            "Epoch 2 Batch 300 Loss [0.53315294 1.1114608  0.90421146 0.8291784  1.2120055  1.4468801\n",
            " 2.2841272  1.3894737  1.5437341  0.66880256 0.68514234 0.9931202\n",
            " 0.74457717 0.50849843 0.5564701  0.9263067  1.3292384  1.4069695\n",
            " 0.8874516  0.92831314 1.0193896  1.0854547  1.1735884  1.5174242\n",
            " 1.1798632  0.64726627 1.3808457  1.5334356  0.60227    0.87166214\n",
            " 0.716646   1.3043653  1.1421617  1.0348506  1.0106653  1.0700775\n",
            " 1.5567393  0.8114732  0.6922708  0.48346198 0.87803805 0.75191575\n",
            " 0.80500954 1.4370409  1.5543262  0.9909895  0.97226864 0.6177275\n",
            " 0.751377   1.1644737  0.969292   0.9719823  0.99228764 0.8768174\n",
            " 3.667772   1.3621985  0.8867941  0.89716977 0.80126345 0.62593645\n",
            " 0.43980905 0.36537328 0.8180321  1.4412336 ]\n",
            "Epoch 2 Batch 400 Loss [0.49376795 0.9974072  0.8355918  2.2024467  0.8537963  1.0124738\n",
            " 0.95073533 1.7242686  1.1591207  1.0311981  1.0002469  2.3376203\n",
            " 0.60933316 0.9010668  0.70889825 1.0304297  0.6448365  1.2520615\n",
            " 0.68455774 0.6000619  1.2024224  0.6589363  1.2131362  0.9245738\n",
            " 1.5274501  1.0323719  1.2279528  0.64499855 1.2968858  0.98198575\n",
            " 0.58690417 1.1064167  0.9590146  0.87977725 0.5051332  0.9436706\n",
            " 0.49092442 1.6757514  2.0287445  1.0622345  0.6247451  0.6771792\n",
            " 1.2206178  1.3265414  0.54058516 1.1114112  1.2771417  1.6062989\n",
            " 1.0155094  1.5186573  1.5824378  1.0366017  0.9435943  1.4643965\n",
            " 0.62234634 0.5483454  0.6794123  0.47559807 0.8463967  1.1661592\n",
            " 1.1240125  1.1382519  1.1106524  1.3714768 ]\n",
            "Epoch 2 Batch 500 Loss [2.117806   0.7966711  0.8267115  0.8303832  1.0550991  0.95173156\n",
            " 0.93641216 1.5154616  0.6820444  0.531277   1.1792065  0.9411177\n",
            " 0.8883754  1.1634821  1.0142065  0.71149    1.0495311  0.7695086\n",
            " 1.627261   0.6448983  0.89108807 0.6407611  1.1020237  1.4287355\n",
            " 1.4179897  1.0731102  0.5951677  0.82292694 1.3157095  1.1539398\n",
            " 0.99672985 0.5305414  0.6833806  1.4227316  0.87818563 1.1496301\n",
            " 0.8468948  1.1244963  2.0236022  0.63465816 1.003158   0.9938713\n",
            " 0.71549475 0.9783843  1.3245136  1.5450633  0.52711034 0.838295\n",
            " 1.0576544  0.76998776 1.6315653  0.6502033  0.8453082  1.2962276\n",
            " 1.1656405  0.57075083 1.2661362  1.0280195  0.8258221  1.8814882\n",
            " 1.323949   0.7572303  1.0283693  0.93297946]\n",
            "Epoch 2 Batch 600 Loss [1.1732395  0.4743459  1.8472472  1.6969551  0.49705765 0.82984823\n",
            " 0.8101069  0.8627333  0.59012175 0.5793168  1.2600757  0.4427771\n",
            " 1.6796591  1.3865552  0.6616708  0.7494653  0.9499781  0.7598506\n",
            " 0.91473293 0.9877455  0.92157584 1.5978663  0.86255646 0.81986356\n",
            " 0.7688911  0.8027695  0.70648146 0.7348307  1.1099931  0.5954592\n",
            " 0.8712867  0.98049366 0.61403763 1.3543713  1.1968582  1.2767117\n",
            " 1.0156308  0.9267041  1.0119135  0.53860897 0.8122615  1.6025126\n",
            " 0.9051907  0.61051935 0.77045995 1.6625854  0.9338996  0.41757345\n",
            " 0.5445473  1.1530157  1.5617296  0.97032356 0.720185   1.9684762\n",
            " 0.7909235  0.939936   0.56019276 1.1404188  1.9077238  1.1819093\n",
            " 1.4839901  1.2209196  0.78228134 1.5462697 ]\n",
            "Epoch 2 Loss [1.0245574  0.99452186 1.0045177  1.0336992  1.0354644  1.0248506\n",
            " 1.0185628  1.024616   1.0230929  1.0208812  1.0187256  1.026305\n",
            " 1.0125562  1.0222517  1.0255433  1.0279815  1.0321084  1.0362933\n",
            " 1.0145199  1.0115031  1.0249077  1.0178175  1.0296339  1.0161625\n",
            " 1.0368633  1.0403477  1.016723   1.0386091  1.0319936  1.0406545\n",
            " 1.041657   1.0184999  1.025016   1.0367537  1.0004766  1.0146213\n",
            " 1.0120322  1.034971   1.0303283  1.040354   1.0180248  1.0197818\n",
            " 1.0249442  1.0177598  1.0416414  1.0188843  1.0243696  1.0283391\n",
            " 1.0447206  1.0232806  1.0469863  1.0502331  1.0227064  1.0265878\n",
            " 1.0207523  1.0403296  1.0372485  1.0290706  1.031441   1.0293916\n",
            " 1.0296943  1.0233479  1.0167867  1.048523  ]\n",
            "Time taken for 1 epoch 83.87208652496338 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss [0.40403658 1.5256821  0.47094303 1.5690837  0.79416203 0.67146343\n",
            " 0.46034825 0.66137826 0.5765491  0.83116883 0.69388694 0.7846978\n",
            " 1.2157279  0.98913246 1.300929   0.79835534 0.56929874 1.2101128\n",
            " 0.81783146 0.3946039  1.5732534  0.5014551  1.0792321  0.70693016\n",
            " 1.0370206  0.53427994 0.39106423 0.9158066  0.98705727 0.67144907\n",
            " 0.47592986 0.7377723  0.95629394 1.3508519  0.8412161  1.0671206\n",
            " 1.2060629  0.62209004 1.0532581  0.6936362  1.1638955  1.0904185\n",
            " 1.4504406  0.7972134  1.9337883  0.6788064  0.8389839  0.61581165\n",
            " 1.3688309  0.60109097 0.56378186 0.54390347 0.4652372  0.53960186\n",
            " 0.82611114 0.8902944  1.1959894  0.5920089  1.1418226  0.64305145\n",
            " 0.88403106 1.6679064  0.46405157 0.71781635]\n",
            "Epoch 3 Batch 100 Loss [1.1772861  0.97041935 0.57693404 1.2584767  0.40043995 0.65407306\n",
            " 0.7875555  0.48296124 0.5678139  0.88197356 1.378415   0.37794352\n",
            " 1.1541431  1.4418858  0.6657095  0.50998133 0.59550726 0.71483487\n",
            " 1.2206134  1.1098543  0.84586793 0.69855106 0.70787984 1.5988549\n",
            " 0.54688025 1.1006417  0.89519024 0.47317892 1.3717839  0.4693841\n",
            " 0.56426543 0.805153   1.0130944  0.84397095 0.782929   0.6613354\n",
            " 0.58946294 1.5284516  0.93404514 0.5501325  0.77946913 0.7256316\n",
            " 0.9910148  0.6596778  0.6758545  1.5286096  0.58432806 1.2891494\n",
            " 0.7549021  0.84878117 0.7063436  1.3123248  1.6028215  0.8196158\n",
            " 0.64296603 1.2474031  0.6838357  1.0352993  1.1368885  0.83896667\n",
            " 0.9370342  1.0176328  0.6225832  1.1469604 ]\n",
            "Epoch 3 Batch 200 Loss [0.8546615  0.6242301  1.6445493  1.0911022  0.455169   1.1157246\n",
            " 0.5485407  1.043014   0.5733143  0.8069725  0.6624277  0.9695185\n",
            " 0.7004195  0.5796345  1.2127576  0.9384891  1.55274    0.6109958\n",
            " 1.2279867  0.80238354 1.1746434  0.9364173  0.72733074 0.7743557\n",
            " 0.925686   0.71383274 0.6008408  0.8676672  1.0864859  1.2204281\n",
            " 1.1182749  0.9589632  1.3283583  1.2597895  0.5383657  0.60334736\n",
            " 1.0201563  1.2404295  0.8215776  0.839049   0.49455956 0.6998704\n",
            " 0.7796544  0.41914716 0.43162394 1.2918763  1.0506071  1.1285328\n",
            " 1.1057043  0.704296   0.61131066 0.7665619  0.7334698  1.1547911\n",
            " 1.2660738  0.93951684 0.6687382  0.4460123  0.78142864 1.1540821\n",
            " 0.53951615 0.87474525 0.89033127 0.6274981 ]\n",
            "Epoch 3 Batch 300 Loss [1.3268512  0.8113596  1.4546926  0.7164393  0.9944368  0.5985342\n",
            " 0.5178896  0.82537955 0.48862442 0.61394286 0.71469337 0.721436\n",
            " 0.5498966  0.7344125  0.4323391  1.3716245  0.8945658  0.4547465\n",
            " 0.42974424 0.7509715  0.47785935 0.9676756  0.84470445 0.5058144\n",
            " 0.55579    0.81618434 0.5062848  0.7077407  0.67004496 0.8998116\n",
            " 0.7885385  0.48933595 1.0600387  0.9984616  0.42650536 0.85878307\n",
            " 0.6217255  0.41608682 0.60396016 0.45087877 0.5223861  0.85578483\n",
            " 0.7490282  0.5261998  0.6383096  0.39439908 0.7502858  1.7225415\n",
            " 1.3747154  0.9614348  1.1677235  0.65047055 0.82584345 0.9195756\n",
            " 1.11886    1.1253726  0.5824516  1.1454095  1.1039112  0.6337555\n",
            " 0.5695105  0.86039    1.3417766  0.3230652 ]\n",
            "Epoch 3 Batch 400 Loss [0.9378003  0.3576663  0.5800134  1.4162854  1.2106663  0.53064615\n",
            " 0.75137603 0.89918286 0.6073583  0.4438847  0.7154874  1.107931\n",
            " 0.66027576 0.71390426 0.7475356  0.85544556 0.4292898  0.6845521\n",
            " 0.93672806 0.9819606  0.6104086  0.41374123 0.3457678  1.9328351\n",
            " 0.8558352  0.8590606  0.7332701  0.9222122  0.5669537  0.53523964\n",
            " 0.57454574 0.6825247  0.45890787 0.6383756  0.37271154 3.36823\n",
            " 0.9091795  1.1600665  1.2682656  0.8011577  0.5943875  0.5866045\n",
            " 0.8738993  1.1103655  0.76280624 0.5552892  0.4472597  0.545539\n",
            " 0.8500288  1.5004288  0.42670774 0.83024895 0.7279302  0.5377217\n",
            " 0.8685992  1.940687   0.50328285 0.8343301  1.6400254  0.33741668\n",
            " 0.72498745 0.6039276  0.9893386  0.53907394]\n",
            "Epoch 3 Batch 500 Loss [0.4362554  0.9770298  0.53013307 1.2895559  1.4746997  0.5991305\n",
            " 0.8395913  1.1123886  1.0915037  1.371927   0.46891642 0.64962614\n",
            " 0.5796951  0.4730121  0.61938345 1.1823487  0.54538363 0.5403458\n",
            " 1.0322558  0.8874321  0.41117492 0.9529427  1.1727061  1.3561046\n",
            " 0.774526   0.65221614 0.37835124 0.4105454  0.59788793 1.9171431\n",
            " 0.20365651 0.37758258 0.54298466 1.1462858  0.3892556  0.35913473\n",
            " 1.006068   0.7806888  0.63631994 0.5983213  0.60947543 0.9392005\n",
            " 0.668526   0.7961236  0.85466194 0.9023549  0.53357786 0.54312634\n",
            " 0.7565011  0.65428174 0.69235396 0.6300648  0.46018368 0.23875038\n",
            " 1.1122556  0.3998479  1.0213038  0.5509078  1.8327906  1.5412401\n",
            " 0.38767093 0.872746   1.3227758  0.6761635 ]\n",
            "Epoch 3 Batch 600 Loss [1.1073458  0.46845764 0.37713364 0.29127893 0.510102   0.72568506\n",
            " 0.3173231  0.34415647 0.9231303  1.8087125  0.6387704  1.1146444\n",
            " 0.737783   0.508848   1.1817907  0.9022864  0.6082025  0.6639192\n",
            " 0.61977303 0.20473929 0.7733663  0.9634519  1.6546954  0.59647834\n",
            " 0.49000058 0.88046825 0.86889035 0.7353417  1.2803293  1.0661713\n",
            " 0.5739814  1.04173    1.7070796  0.43804112 0.4679532  1.1220052\n",
            " 0.31818193 0.30698887 0.62208563 0.709088   0.7861218  0.55957365\n",
            " 0.75575507 0.6254713  0.72292536 0.47663552 0.50760806 0.9142415\n",
            " 0.5634261  0.66285676 0.31196707 0.46167958 0.87356645 0.5624943\n",
            " 0.5625604  0.76918507 0.42661366 0.8536797  0.84850484 0.5712572\n",
            " 0.6906057  0.78320587 0.54023165 0.61129665]\n",
            "Epoch 3 Loss [0.7837833  0.82763934 0.8219046  0.7996603  0.82014865 0.8060404\n",
            " 0.79840994 0.8177063  0.78112364 0.82590663 0.81035763 0.8426258\n",
            " 0.7998699  0.844599   0.8179401  0.8031712  0.8253995  0.80345833\n",
            " 0.83904094 0.8311365  0.80186844 0.8202717  0.80685115 0.85348946\n",
            " 0.8073283  0.816643   0.807631   0.79437506 0.8280482  0.8215587\n",
            " 0.80345047 0.8065495  0.8095545  0.80346763 0.7949041  0.8290586\n",
            " 0.8191989  0.8202835  0.8123042  0.83545965 0.8026156  0.8236662\n",
            " 0.8369976  0.80270046 0.81180143 0.8184184  0.7907216  0.83430594\n",
            " 0.82232976 0.815535   0.7946025  0.8129424  0.8114237  0.80605584\n",
            " 0.80891854 0.83666056 0.8063416  0.82637376 0.81000686 0.83008474\n",
            " 0.78443015 0.81524944 0.8260359  0.8362011 ]\n",
            "Time taken for 1 epoch 82.87351179122925 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss [0.39923838 1.0739304  0.6981778  0.41784477 0.45198917 0.4216918\n",
            " 0.27720225 0.5886934  0.6307137  0.4254631  0.44597456 0.35441113\n",
            " 0.6353854  1.2692392  1.2193944  0.22107166 0.5479787  1.451281\n",
            " 0.407773   0.42428514 1.303434   0.5839669  1.2965783  0.6754744\n",
            " 0.25232792 0.6894196  0.48298445 0.64608365 0.63540554 0.34651962\n",
            " 0.303649   0.5135701  0.8358835  0.16307527 0.5800509  0.10081277\n",
            " 0.2246073  0.25816318 0.31977674 0.05256842 0.6054773  0.3821229\n",
            " 0.8687918  0.597046   0.82532173 0.2845318  1.3242623  0.47007594\n",
            " 0.53703123 0.7175953  0.4991229  0.65587837 0.33426717 0.8435511\n",
            " 0.56208134 0.5244523  1.1716453  0.4247558  1.0269983  0.58138055\n",
            " 1.0457352  0.0788876  0.71282864 0.37406617]\n",
            "Epoch 4 Batch 100 Loss [0.41835293 0.24192087 1.9828256  0.5659115  0.46446127 0.8674777\n",
            " 0.746219   1.3738602  1.0896969  0.47533798 0.91491973 0.5201589\n",
            " 0.67189145 0.40609983 0.34422854 0.60848117 0.51416856 0.18909474\n",
            " 1.8411677  0.5240558  0.83885324 0.8650901  0.49999884 0.81746\n",
            " 0.9120106  0.69186425 0.72146076 0.5812384  0.5467208  0.36636952\n",
            " 1.0650957  0.42450204 0.23181275 0.6552095  0.43562984 0.67498004\n",
            " 0.6148055  0.20930599 1.9980149  0.37730047 0.36285448 1.8213345\n",
            " 0.4828299  0.39203897 0.84686977 0.66487706 0.29412824 0.70683104\n",
            " 0.26815978 1.0560606  0.85307187 0.6536273  0.22478294 0.76774323\n",
            " 0.32798994 0.39149168 0.8593513  0.43558824 1.2246596  0.5002569\n",
            " 0.9688764  0.15997131 0.4957365  1.0311934 ]\n",
            "Epoch 4 Batch 200 Loss [0.15618572 1.5221719  0.25304887 0.55337495 0.3035997  0.8346315\n",
            " 0.906841   0.20549761 0.9148617  0.48108414 0.738989   0.23736902\n",
            " 0.21732016 0.3785251  0.94057846 0.39064503 0.22457378 1.0444608\n",
            " 0.24577567 0.21239403 0.63392687 0.68211216 0.49078545 0.8748881\n",
            " 0.9351459  1.2172133  0.86198026 1.0039937  0.91112137 0.6806186\n",
            " 0.6080768  0.24200197 0.7079327  0.33815867 0.5606331  0.3901722\n",
            " 0.64839387 0.35538113 0.5027695  0.7499154  1.2492559  0.45874542\n",
            " 0.15904808 0.48893827 0.74149585 0.3370223  0.78570956 0.20892888\n",
            " 0.15821083 1.2253344  0.9977162  0.37018368 0.7549287  0.77811664\n",
            " 0.11095456 0.9754963  0.5046548  0.54140157 0.39066628 0.30978766\n",
            " 0.5561536  0.6151572  0.88331944 0.42039573]\n",
            "Epoch 4 Batch 300 Loss [0.4636383  0.14980058 0.53893167 0.4432152  0.38276136 0.9664933\n",
            " 0.596334   0.27324602 0.69155645 0.41507772 0.7020438  0.94024724\n",
            " 0.5450456  0.5055983  0.3847646  1.4417778  0.3886515  0.5540396\n",
            " 0.30715033 0.3736416  0.20480932 0.41937733 0.7404428  0.7782693\n",
            " 0.43315092 0.8387783  0.11868604 0.3512806  0.30040324 0.45326868\n",
            " 0.25336447 0.8022406  1.2476865  0.57772607 0.437889   1.3893831\n",
            " 0.4437469  0.48166028 0.8919629  0.4885326  0.44705057 0.95050937\n",
            " 0.27105245 0.39451367 0.5009286  0.20752732 0.89619255 0.18415987\n",
            " 0.70291406 0.52711606 0.11703847 0.5005434  0.8338729  0.25844797\n",
            " 0.12703578 0.35269514 0.8609016  0.5210708  0.48891932 0.7719379\n",
            " 1.2055624  0.58423615 0.39171627 1.281411  ]\n",
            "Epoch 4 Batch 400 Loss [0.46408314 1.5385185  0.05333465 0.2765594  0.16491392 0.16862053\n",
            " 0.07063507 0.21189655 0.2962193  0.8987284  0.39102685 0.12051185\n",
            " 0.5496443  0.8190969  0.7270916  0.6094361  0.6903125  0.15283732\n",
            " 1.0241685  0.7116626  0.5403102  0.49906936 0.05357297 0.2615318\n",
            " 0.90383273 0.71759284 0.83818877 0.37418264 0.5477563  0.38146773\n",
            " 0.7597222  0.53696513 0.6310385  0.25631875 0.67866176 0.3015718\n",
            " 0.5185214  0.52632266 0.72463137 0.50972956 0.6070069  0.24450453\n",
            " 0.22159523 0.27619976 0.79488397 0.5881759  0.47156334 0.56530565\n",
            " 0.5084246  0.28919247 0.14903893 0.8964814  0.26705974 0.35873678\n",
            " 0.52154064 0.15235004 0.3796135  0.20305657 0.375772   0.21470849\n",
            " 0.62385774 0.25680378 0.6061724  0.18350682]\n",
            "Epoch 4 Batch 500 Loss [0.27746463 0.7600854  0.37343988 0.18572195 0.5998483  0.29906994\n",
            " 0.46466678 0.5356446  0.5589456  0.34276536 1.0157839  0.24273331\n",
            " 0.73733467 0.24863002 0.21902859 0.56712705 0.15724818 0.11578993\n",
            " 0.29513422 0.29810107 0.947802   0.86467266 0.6298666  0.32550514\n",
            " 0.52200264 1.0365363  0.69072664 0.02959442 0.98718476 0.26686272\n",
            " 0.53347903 0.12530968 0.18165384 1.233706   0.57585853 0.84655076\n",
            " 0.52399904 0.32138747 1.2077801  1.5068471  0.14582011 0.6281212\n",
            " 0.39050287 0.21528593 0.89068836 0.15412076 0.22876316 0.4936105\n",
            " 0.4438688  0.6756706  0.15443617 0.51395404 0.14995983 0.5682194\n",
            " 0.49637243 0.5180195  0.4634169  0.2579865  0.2898718  0.14997728\n",
            " 0.53775316 0.2856006  0.24571975 0.5480029 ]\n",
            "Epoch 4 Batch 600 Loss [0.64094174 0.80139095 0.62254226 0.1194723  0.52170545 0.7616802\n",
            " 0.45353854 0.21217902 0.9668289  0.35970712 0.3146774  0.33894756\n",
            " 0.12254433 0.45974678 0.4558143  0.21216936 1.1756915  0.56728315\n",
            " 0.14778464 0.45082888 0.30498573 0.404109   0.96676266 0.22340496\n",
            " 0.41615954 0.37749436 0.08496197 0.53526664 0.20258343 1.8731172\n",
            " 0.71226597 0.44450888 0.6508719  0.36569658 0.8163249  0.40870836\n",
            " 0.38856927 1.06991    0.9295341  0.5362767  0.3735352  0.05138494\n",
            " 0.71566534 0.6009064  0.01510359 0.43677723 0.6557389  0.6208033\n",
            " 0.36074358 0.30891973 0.41040784 0.34754077 0.24754003 0.663199\n",
            " 0.3331178  0.07619369 0.64907616 0.68305576 0.16165264 0.50477266\n",
            " 0.28269958 0.87736756 0.16349731 0.5638629 ]\n",
            "Epoch 4 Loss [0.5875668  0.5852099  0.5826398  0.58387107 0.55716664 0.56470084\n",
            " 0.582216   0.5734124  0.550045   0.5766203  0.5737422  0.58657503\n",
            " 0.56757814 0.5546316  0.5823687  0.5682323  0.5735899  0.59056795\n",
            " 0.56483114 0.5814909  0.58254176 0.5415786  0.5753391  0.56533796\n",
            " 0.5576143  0.5746391  0.55604917 0.5903671  0.55930394 0.5727726\n",
            " 0.5759558  0.55201286 0.58244056 0.5643331  0.59035265 0.56169504\n",
            " 0.5806709  0.57551104 0.5666658  0.5779926  0.5536302  0.5533102\n",
            " 0.5618585  0.5937263  0.5615114  0.5785475  0.57192785 0.5732252\n",
            " 0.5747583  0.5735359  0.57249343 0.5742359  0.568398   0.58279985\n",
            " 0.5655449  0.5721802  0.55646414 0.56897455 0.58379877 0.57512486\n",
            " 0.578621   0.5786156  0.5580057  0.57638425]\n",
            "Time taken for 1 epoch 83.8912410736084 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss [0.46095052 0.42015246 0.2848267  0.13281655 0.29084826 0.21054094\n",
            " 0.2434375  0.26146936 0.07451648 0.4999047  0.67948323 0.680233\n",
            " 0.15919961 0.53969985 0.1771557  0.10235281 0.37482947 0.5311668\n",
            " 0.62535435 2.2291014  0.28233686 0.18844128 0.45377323 0.22853279\n",
            " 0.48330796 0.18129691 0.49715963 0.6015375  0.04523211 0.31224376\n",
            " 0.15673007 0.95117855 0.48482937 0.32582346 0.3625022  0.3540637\n",
            " 0.143954   0.537999   0.33985195 0.47336355 0.25173262 0.32251742\n",
            " 0.41679057 0.5449086  0.23043282 0.4565803  1.8910667  0.19130729\n",
            " 0.7482661  0.23889    0.36825553 0.49500623 0.2743262  0.5805705\n",
            " 0.28159738 0.2741854  0.13822463 0.43924245 0.13752466 0.15500604\n",
            " 0.8954985  0.284269   0.13306488 0.22598842]\n",
            "Epoch 5 Batch 100 Loss [0.55189013 0.13961193 0.34214082 0.21057248 0.22014014 0.39539766\n",
            " 0.25848892 0.3895724  0.88083893 0.8465609  0.09027519 0.11853165\n",
            " 0.21160306 0.16553128 0.4222946  0.43863067 0.37368324 0.2898442\n",
            " 0.13733988 0.5965058  0.22643839 0.12557618 0.23291853 0.23813312\n",
            " 0.5010387  0.31112716 0.25384092 0.22442889 0.30947626 0.3221662\n",
            " 0.25411275 0.57747644 0.41025627 0.18650027 0.3576041  0.5470088\n",
            " 0.3966609  0.1170119  0.6986713  0.4943838  0.31733105 0.3120513\n",
            " 0.37173298 0.07348287 0.10047174 0.47715527 0.63653255 0.22818653\n",
            " 0.30170277 0.23696347 0.16005197 0.107898   0.6332925  0.01586023\n",
            " 0.37963194 0.16717635 0.35348585 1.1997392  0.2069105  0.62288326\n",
            " 0.29791903 0.2737573  0.6002881  0.4897664 ]\n",
            "Epoch 5 Batch 200 Loss [0.74516326 0.869028   0.11121809 0.1258205  0.36074302 0.29985473\n",
            " 0.5104024  0.12340411 0.03275352 0.45961475 0.3301662  0.8520098\n",
            " 0.56772447 0.06293055 0.16399115 0.42312422 0.34627637 0.09068264\n",
            " 0.12088624 0.18211488 0.46901956 0.50752693 0.07073107 0.15035881\n",
            " 0.26663512 0.842752   0.24685995 0.50741124 0.6552781  0.46064207\n",
            " 0.5001969  0.3162507  0.3901069  0.3037317  0.21752825 0.4532803\n",
            " 0.559527   0.7161927  0.7090037  0.70652527 0.08325395 0.4221723\n",
            " 0.23879062 0.74009246 0.21299602 0.392013   0.3371977  0.38735193\n",
            " 0.13579011 1.7195464  0.26524332 0.39635983 0.42259592 0.08662655\n",
            " 0.08426807 0.3488512  0.6040301  0.46260998 0.1166625  0.45825693\n",
            " 0.03646322 0.3056452  0.26284274 0.40254804]\n",
            "Epoch 5 Batch 300 Loss [0.50518835 0.52669126 0.43371665 0.2069592  0.06518948 0.1295369\n",
            " 0.72428936 0.60185724 0.29635635 0.2841761  0.3774109  1.230633\n",
            " 0.4806342  0.33412594 0.7573489  0.47991657 0.24259745 0.30291933\n",
            " 0.34488472 0.5550529  0.0527051  0.33707166 0.19472532 0.46459925\n",
            " 0.1938655  0.01907242 0.25519174 0.1844353  0.11638812 0.07641495\n",
            " 0.26071376 0.15829046 0.28341904 0.6523576  0.06906857 0.24841028\n",
            " 0.3894443  0.33097023 0.31675172 0.22306769 0.5124093  0.5598119\n",
            " 0.06153517 0.10695757 0.2843061  0.30826762 0.280126   0.17957243\n",
            " 0.5187993  1.4300213  0.36267954 0.4029415  0.37762514 1.8418276\n",
            " 0.17402616 0.14964797 0.2605065  0.3789222  0.12021843 0.11831011\n",
            " 0.67819494 0.13597803 0.21139456 0.1186011 ]\n",
            "Epoch 5 Batch 400 Loss [0.0695558  0.51953936 0.44755262 0.37918368 0.12831365 0.33138368\n",
            " 0.79788715 0.19869782 0.3284748  0.16897981 0.62387174 0.12724324\n",
            " 0.28158292 0.18148395 0.3945182  0.37259465 0.80804574 0.40717486\n",
            " 0.34902588 0.5854256  0.60089415 0.17068113 0.14311011 0.3185004\n",
            " 0.10483161 0.38079274 0.17456542 0.2274909  0.7800929  0.98415744\n",
            " 0.30341938 0.30268362 0.32080314 0.38982695 0.72275794 0.7806925\n",
            " 0.2277537  0.02884496 0.5562334  0.4694421  0.386649   0.05636678\n",
            " 0.15691419 0.54926217 0.65518665 0.25616243 0.4690433  0.12427465\n",
            " 0.5517557  0.22267342 0.7344213  1.5662482  0.08822274 0.64716816\n",
            " 0.10479987 0.26561245 0.807853   0.06236248 0.9529777  0.41657224\n",
            " 0.127929   0.4819712  0.54128736 0.7377827 ]\n",
            "Epoch 5 Batch 500 Loss [0.30034587 0.36350453 0.34100142 0.32584208 0.44985905 0.27729836\n",
            " 0.5880025  0.43871757 0.70191836 0.32610145 0.25630224 1.7583157\n",
            " 0.612618   0.2573948  0.33605987 0.16996026 0.20000798 0.07310937\n",
            " 0.48897225 0.48912627 0.43527713 0.3391507  0.18936072 0.04676898\n",
            " 0.2326039  0.54626745 1.2102264  0.3742423  0.5274105  0.262268\n",
            " 0.08636806 0.07688514 0.59399325 0.6971675  0.3817505  0.35234353\n",
            " 0.09986737 0.22426564 0.24023427 0.18488236 0.74506176 0.50584203\n",
            " 0.01048713 0.06870471 0.26642936 0.30206126 0.22820441 0.23956037\n",
            " 0.6877368  0.5547862  0.03690749 0.02222992 0.18184389 0.2818294\n",
            " 0.41826147 0.41631243 0.20100412 0.24943495 0.15553707 0.38153568\n",
            " 0.06216575 0.0173122  0.60120106 0.17198607]\n",
            "Epoch 5 Batch 600 Loss [0.9759511  0.45024475 0.11670265 0.43688914 0.05004556 0.5217566\n",
            " 0.8934443  0.52087337 0.79686195 0.3240449  0.4462597  0.20138295\n",
            " 0.36336538 0.16317363 0.34405386 0.45540938 0.22276309 0.31718373\n",
            " 0.3827771  0.23310168 0.32545722 0.31119934 0.1065087  0.33054963\n",
            " 0.03546237 0.03829028 0.32368812 0.0567797  0.65079457 0.9226375\n",
            " 0.19665383 1.1844985  0.06496326 0.34080955 0.44663742 0.56325454\n",
            " 0.10942577 0.20025896 0.57822394 0.22514309 0.4439773  0.12947343\n",
            " 0.36184266 0.1852401  0.07895635 0.45188633 0.5010144  0.44446337\n",
            " 0.12414683 0.5534638  0.4668025  0.93335706 0.09305386 0.36206195\n",
            " 0.75951576 0.57758427 0.51882595 0.27407137 0.17473933 0.96015096\n",
            " 0.44973496 0.05685943 0.25067982 0.34052148]\n",
            "Epoch 5 Loss [0.3772437  0.38017234 0.39065093 0.38586065 0.38556337 0.37054428\n",
            " 0.4122586  0.3830619  0.40062147 0.3950107  0.3922122  0.37310293\n",
            " 0.39957967 0.39334783 0.37232852 0.40418175 0.35570213 0.40161964\n",
            " 0.40162814 0.4168537  0.38029164 0.39622906 0.390132   0.395846\n",
            " 0.38564402 0.3914281  0.39919376 0.37596607 0.3897267  0.39010713\n",
            " 0.4003858  0.40313536 0.3897138  0.39996892 0.38784242 0.39077047\n",
            " 0.38047728 0.39434105 0.38018483 0.39304656 0.3916993  0.38621622\n",
            " 0.4024158  0.39930332 0.3769304  0.39077908 0.3966693  0.38230845\n",
            " 0.38870484 0.39806184 0.3974572  0.39536512 0.38012755 0.39040446\n",
            " 0.4045735  0.37531862 0.39731717 0.4108314  0.39575896 0.38637733\n",
            " 0.3714227  0.39298934 0.3793441  0.36878645]\n",
            "Time taken for 1 epoch 82.83436942100525 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss [0.19324179 0.65177375 0.15990403 1.1756297  0.03253799 0.07846143\n",
            " 0.11046348 0.22290249 0.31712613 0.2438869  0.2113922  0.38541538\n",
            " 0.26217222 0.00955755 0.64440423 0.20217066 0.24171133 0.10219006\n",
            " 0.31755593 0.3134808  0.22002295 0.2776067  0.4358804  0.30856743\n",
            " 0.21233696 0.17842676 0.32482997 0.11196242 0.17938812 0.15058811\n",
            " 0.19066973 0.45588478 0.21321663 0.16968359 0.34094134 0.3800986\n",
            " 0.11924274 0.0907064  0.18023936 0.38193065 0.47891235 0.24895927\n",
            " 0.11516668 0.1318964  0.22314231 0.10997643 0.2540994  0.23941575\n",
            " 0.7959898  0.2241326  0.1012219  0.13460906 0.110609   0.31875375\n",
            " 0.36400864 0.12873806 0.2773855  0.28365278 0.29185268 0.49378178\n",
            " 0.6940477  0.3031642  0.24490033 0.92599475]\n",
            "Epoch 6 Batch 100 Loss [0.2754657  0.57125396 0.05754695 0.410182   0.07361718 0.12663378\n",
            " 0.1973981  0.9992809  0.06047546 0.13411589 0.12094381 0.12749687\n",
            " 0.3587363  0.09927253 0.07037747 0.31292477 0.13179557 0.25105754\n",
            " 0.02617213 0.14072883 0.07215833 0.04102989 0.36441883 0.27367204\n",
            " 0.24142128 0.2945244  0.11297373 0.0786315  0.04043922 0.2870649\n",
            " 0.1074682  0.4110546  0.26313496 0.0301003  0.130119   0.22403598\n",
            " 0.50886124 0.1469893  0.27148098 0.28292242 0.13252702 0.4549192\n",
            " 0.03661487 0.23562407 0.3041859  0.1716492  1.0082031  0.15509671\n",
            " 0.24396893 0.13509493 0.307818   0.03546721 0.12716505 0.31438726\n",
            " 0.64202064 0.32242295 0.02284031 0.20245281 0.48276678 0.34781796\n",
            " 0.22273919 0.2682077  0.43370825 0.3325379 ]\n",
            "Epoch 6 Batch 200 Loss [0.23507378 0.43286234 0.5078564  0.3035443  0.04426362 0.02206077\n",
            " 0.33911878 0.05614328 0.43033972 0.5149974  0.5027616  0.40680325\n",
            " 0.36985937 0.14795794 0.06836962 0.4722439  1.4827027  0.23120591\n",
            " 0.43715832 0.6956002  0.44749165 0.08798674 0.38490623 0.10109447\n",
            " 0.18690918 0.15826295 0.42554617 0.5041312  0.02996499 0.11458286\n",
            " 0.34130374 0.28931433 0.28917983 0.01112691 0.03168254 0.2793994\n",
            " 0.16982551 0.22665988 0.34177914 0.18030356 0.37018576 0.04274426\n",
            " 0.3472024  0.10194901 0.4297666  0.92243505 0.11190281 0.18774958\n",
            " 0.34197518 0.30445462 0.5181619  0.3167456  0.5252728  0.5475281\n",
            " 0.17563747 0.15446782 0.11084171 0.47778332 0.11907516 0.76976717\n",
            " 0.27475998 0.0115859  0.33449045 0.1538602 ]\n",
            "Epoch 6 Batch 300 Loss [0.20815067 0.1532712  0.33541453 0.1529905  0.20133086 0.02055929\n",
            " 0.27317038 0.20293005 0.23529525 0.02002998 0.01415163 0.47136852\n",
            " 0.40745482 1.000569   0.40133592 0.06600793 0.24117467 0.07951766\n",
            " 0.20818387 0.04602724 0.0236435  0.35839316 0.26439908 0.47566876\n",
            " 0.54260063 0.5463467  0.318116   0.15058358 0.11177156 0.32581505\n",
            " 0.22548223 0.16700615 0.05855222 0.24655649 0.2558725  0.68210304\n",
            " 0.3801964  0.04983705 0.27222598 0.7086876  0.15816551 0.16342531\n",
            " 0.65752184 0.30129617 0.3357763  0.02265578 0.12527971 0.03769083\n",
            " 0.07606777 0.29175743 0.14322011 0.13628751 0.21018834 0.23633572\n",
            " 0.03773763 0.29688984 0.1058319  0.19166915 0.56843364 0.10295513\n",
            " 0.14452018 0.7045854  0.07897371 0.5109718 ]\n",
            "Epoch 6 Batch 400 Loss [0.60089284 0.59451836 0.4785391  0.05767857 0.6820871  0.5011892\n",
            " 0.03695313 0.01966678 0.03843105 0.12243344 0.15216155 0.30623952\n",
            " 0.2040946  0.00860752 0.3877639  0.04047733 0.12415469 0.36354303\n",
            " 0.33795616 0.23527633 0.7505153  0.17897065 0.64909405 0.04356679\n",
            " 0.03987326 0.15142217 0.343415   0.21207982 0.18027139 0.09693936\n",
            " 0.09259699 0.31171298 0.18445374 0.25491536 0.48134863 0.27182144\n",
            " 0.34225056 0.2225843  0.0111975  0.15056445 0.21727528 0.13831204\n",
            " 0.02904795 0.14751633 0.12493087 0.26882756 0.26732138 0.52378625\n",
            " 0.20440452 0.2925583  0.07880578 0.22712724 0.01386271 0.2588251\n",
            " 0.3508121  0.48626885 0.04884737 0.24088815 0.36424208 0.27033448\n",
            " 0.17109588 0.33084288 0.14710493 0.1132679 ]\n",
            "Epoch 6 Batch 500 Loss [0.04822101 0.16634935 0.10708559 0.05486382 0.07943045 0.37874234\n",
            " 0.06727423 0.2776199  0.31708366 0.02291423 0.2969498  0.2590069\n",
            " 1.2111115  0.246182   0.45162472 0.22938319 0.49651602 0.15491717\n",
            " 0.30725807 0.0731589  0.10573414 0.12358794 0.04513558 0.4187338\n",
            " 0.23539867 0.22901747 0.32618773 0.08356259 0.02173565 0.18054207\n",
            " 0.13109674 0.05949011 0.51350695 0.27596298 0.41508114 0.5072219\n",
            " 0.38882723 0.22129066 0.2212002  0.5328594  0.205527   0.13925599\n",
            " 0.26541096 0.46895355 0.28708252 0.1758646  0.54405    0.15500991\n",
            " 0.5615075  0.01707178 0.0896626  0.43862665 0.03364833 0.2347798\n",
            " 0.06464962 0.13355209 0.220748   0.32428503 0.07712994 0.11483228\n",
            " 0.09533501 0.03492187 0.42279148 0.41475075]\n",
            "Epoch 6 Batch 600 Loss [0.45417178 0.13481551 0.21337293 0.04213759 0.35694462 0.21154098\n",
            " 0.32500914 0.32686788 0.28933913 0.31195727 0.13134348 0.30729076\n",
            " 0.1306016  0.21787529 0.38190144 0.01509166 0.09819381 0.49861586\n",
            " 0.12607794 0.4332714  0.19756241 0.29216117 0.14065142 0.42550287\n",
            " 0.21070845 0.07884175 0.09382536 0.25047022 0.07596316 0.33373085\n",
            " 0.19600579 0.31766868 0.05985087 0.36677045 0.12065967 0.13666423\n",
            " 0.31063786 0.1052682  0.05505259 0.20455492 0.09736157 0.6397325\n",
            " 0.654856   0.15284768 0.14255448 0.05894533 0.19943291 0.13474567\n",
            " 0.24795389 0.06053432 0.38597786 0.13886134 0.08028018 0.591165\n",
            " 0.20466472 0.23572943 0.29019588 0.3280303  0.409519   0.39925086\n",
            " 0.04499183 0.05170369 0.01228109 0.61359787]\n",
            "Epoch 6 Loss [0.25780153 0.26463598 0.26612765 0.26617262 0.28679603 0.2700235\n",
            " 0.27991253 0.29028112 0.28239763 0.28328562 0.26735032 0.29008403\n",
            " 0.28772587 0.26757628 0.2826444  0.28421238 0.28729632 0.28748494\n",
            " 0.26824114 0.29564327 0.2656704  0.28940067 0.27878666 0.2847378\n",
            " 0.2925396  0.2716423  0.27082184 0.28219873 0.28026837 0.28572544\n",
            " 0.2897098  0.28041786 0.28721485 0.27815384 0.27858537 0.2915226\n",
            " 0.2797426  0.28452095 0.2949675  0.2925829  0.28248438 0.2961834\n",
            " 0.2732453  0.28352946 0.273891   0.28169623 0.26600003 0.27522656\n",
            " 0.28466934 0.28317854 0.29582462 0.30270982 0.2788497  0.26953804\n",
            " 0.29946265 0.28529546 0.28520826 0.26853147 0.27332687 0.2982985\n",
            " 0.27732098 0.2747948  0.27505454 0.27622554]\n",
            "Time taken for 1 epoch 83.98338317871094 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss [0.14454682 0.22205672 0.25070822 0.10713781 0.21312407 0.21013293\n",
            " 0.30561697 0.05258983 0.12879881 0.21987896 0.07716229 0.17945033\n",
            " 0.03597349 0.34847587 0.1262703  0.24721713 0.15537597 0.1941519\n",
            " 0.11112227 0.09094542 0.0188377  0.23246002 0.03182867 0.12741826\n",
            " 0.05160353 0.11591653 0.17941193 0.19787474 0.07161284 0.23202504\n",
            " 0.12045876 0.16176397 0.36946264 0.10665454 0.10860238 0.0248147\n",
            " 0.0338739  0.15036379 0.20476808 0.1348708  0.24221045 0.12701331\n",
            " 0.08002514 0.5312489  0.24185984 0.26075333 0.1130018  0.35810763\n",
            " 0.37211093 0.17765178 0.1772136  0.23202947 0.25103107 0.05434851\n",
            " 0.21435659 0.21068417 0.36790535 0.18762526 0.2081768  0.23677833\n",
            " 0.20547277 0.17020722 0.05635203 0.30503047]\n",
            "Epoch 7 Batch 100 Loss [0.09876262 0.3373457  0.36450014 0.18176773 0.18391167 0.31039646\n",
            " 0.2335985  0.01874515 0.01598821 0.15288407 0.23992544 0.23984496\n",
            " 0.0593573  0.37699804 0.07762764 0.01631152 0.03324163 0.05493204\n",
            " 0.12065486 0.02386766 0.46205112 0.3314241  0.2774128  0.21738198\n",
            " 0.27352238 0.0179801  0.05760294 0.23686239 0.18185012 0.23480588\n",
            " 0.15343413 0.33348814 0.29750076 0.06348429 0.28349987 0.03878025\n",
            " 0.24178416 0.07255691 0.21710725 0.35238406 0.02186916 0.37526143\n",
            " 0.1808881  0.19299944 0.06750113 0.16933197 0.09154931 0.16030878\n",
            " 0.11119293 0.28656873 0.16751218 0.06178935 0.23023033 0.06567582\n",
            " 0.05978937 0.23342377 0.33736187 0.13103314 0.19275124 0.24199097\n",
            " 0.12467805 0.12119509 0.09484417 0.15965153]\n",
            "Epoch 7 Batch 200 Loss [0.07303423 0.42418763 0.26826936 0.11913434 0.18071163 0.3227567\n",
            " 0.17415608 0.3495914  0.4386147  0.106613   0.25562748 0.15181835\n",
            " 0.3185319  0.31977734 0.20110425 0.04258215 0.16682474 0.2739242\n",
            " 0.45420218 0.36373624 0.5339693  0.2173077  0.38087478 0.02658037\n",
            " 0.06319249 0.10440795 0.5844395  0.07322914 0.22057894 0.16009074\n",
            " 0.3988185  0.27416494 0.3179636  0.14489472 0.15157    0.6305523\n",
            " 0.22070761 0.26223907 0.01894321 0.1719354  0.15748195 0.23681413\n",
            " 0.02996348 0.1762425  0.02366928 0.00451357 0.18660946 0.08740044\n",
            " 0.19011305 0.2188619  0.15128207 0.01517606 0.164431   0.01059583\n",
            " 0.0387226  0.34449807 0.8368049  0.03604226 0.30576316 0.13002095\n",
            " 0.15084338 0.13222854 0.02079625 0.07607672]\n",
            "Epoch 7 Batch 300 Loss [0.02729467 0.0927221  0.26522675 0.21585624 0.02922528 0.08488214\n",
            " 0.6676417  0.10520434 0.12800775 0.3945845  0.15705477 0.0504348\n",
            " 0.1151903  0.12994581 0.09559866 0.4510571  0.71670043 0.39571714\n",
            " 1.0308616  0.03506961 0.20333402 0.23007709 0.2340347  0.20424749\n",
            " 0.45914403 0.06963947 0.22344626 0.4810559  0.06550154 0.2174201\n",
            " 0.09520034 0.05962588 0.41273132 0.17027481 0.02080747 0.09760942\n",
            " 0.09425737 0.0441466  0.3135899  0.25663483 0.06854827 0.01817311\n",
            " 0.25996917 0.56578    0.2289458  0.38089302 0.10639986 0.31879595\n",
            " 0.08054358 0.31238842 0.11359572 0.05831932 0.44769633 0.05827646\n",
            " 0.7689342  0.32409975 0.4549606  0.02233992 0.4434126  0.03407569\n",
            " 0.06776976 0.26914868 0.01294547 0.30461907]\n",
            "Epoch 7 Batch 400 Loss [0.28183398 0.184033   0.42998752 0.01099869 0.06411183 0.02654476\n",
            " 0.17336763 0.29860088 0.38368386 0.11860732 0.08714471 0.301175\n",
            " 0.11739037 0.12554316 0.5211209  0.3463181  0.2688459  0.30242297\n",
            " 0.32969937 0.36853272 0.06569554 0.18096355 0.63982475 0.00739337\n",
            " 0.12559767 0.06939171 0.12315423 0.22988611 0.24735345 0.24873741\n",
            " 0.07940304 0.06504082 0.19973287 0.06470868 0.19671322 0.31134966\n",
            " 0.13856559 0.30950394 0.2335155  0.19557388 0.08456944 0.5642617\n",
            " 0.2730533  0.13831584 0.04920422 0.26869938 0.33254883 0.23063305\n",
            " 0.36208925 0.19559377 0.06539088 0.24391958 0.48269188 0.3594542\n",
            " 0.03018505 0.22655159 0.09411871 0.02663256 0.47317758 0.15165508\n",
            " 0.07833852 0.27331796 0.12348705 0.17072363]\n",
            "Epoch 7 Batch 500 Loss [0.1484262  0.17275436 0.5372363  0.11437029 0.1753446  0.46761355\n",
            " 0.14454854 0.40903416 0.33194157 0.00603197 0.08708372 0.15546653\n",
            " 0.44646925 0.05575638 0.24114758 0.85178643 0.00720683 0.27048764\n",
            " 0.01927608 0.06085269 0.36083522 0.30129406 0.04559156 0.22592834\n",
            " 0.02306559 0.31463137 0.37186927 0.24555829 0.20607908 0.19386123\n",
            " 0.3085734  0.12244768 0.11486185 0.34568623 0.16008143 0.13758616\n",
            " 0.10669767 0.04220431 0.17732693 0.13043638 0.06204769 0.09634376\n",
            " 0.35403088 0.03152993 0.5687028  0.38400507 0.19218574 1.0791765\n",
            " 0.05676643 0.32054406 0.51363474 0.02176976 0.41495782 0.12948124\n",
            " 0.12353329 0.38399628 0.18289506 0.20820545 0.27195826 0.12203263\n",
            " 0.01053094 0.39612484 0.54974663 1.1347347 ]\n",
            "Epoch 7 Batch 600 Loss [0.18547995 0.28744474 0.09967204 0.24354346 0.44311753 0.09009467\n",
            " 0.15268463 0.08936975 0.01594707 0.38378647 0.22269244 0.06271969\n",
            " 0.26524904 0.02195409 0.24356039 0.22527769 0.02060414 0.32252464\n",
            " 0.08924564 0.21581128 0.19906832 0.3749846  0.43148884 0.12987657\n",
            " 0.25435045 0.09262358 0.35847872 0.09179335 0.15798438 0.3303347\n",
            " 0.15586632 0.5454169  0.18474823 0.0492757  0.33687106 0.56053877\n",
            " 0.15730786 0.11116522 0.3927723  0.05003137 0.00444099 0.41308627\n",
            " 0.18248768 0.09918503 0.18221931 0.4320656  0.37794712 0.9780955\n",
            " 0.2707843  0.18966883 0.9477606  0.3239252  0.14399299 0.7614839\n",
            " 0.2978057  0.39060453 0.24791165 0.05335201 0.00813868 0.4601087\n",
            " 0.16078514 0.3905138  0.04388179 0.04006239]\n",
            "Epoch 7 Loss [0.21134627 0.21376252 0.23169336 0.20957002 0.20376012 0.22265014\n",
            " 0.21818593 0.2223637  0.2272093  0.21510664 0.21328658 0.2076771\n",
            " 0.20788157 0.21391213 0.21421494 0.22046342 0.21311447 0.216202\n",
            " 0.20547524 0.20604157 0.20649742 0.2224274  0.22238183 0.22695085\n",
            " 0.20972602 0.21821181 0.21778919 0.21141978 0.20647512 0.21664418\n",
            " 0.213978   0.21169998 0.22697446 0.21822244 0.2152877  0.21819529\n",
            " 0.22021626 0.21007241 0.20474322 0.20730327 0.21808569 0.21339597\n",
            " 0.22837056 0.2176256  0.21504876 0.22195694 0.22137298 0.21485445\n",
            " 0.2113052  0.21210638 0.22366777 0.22331738 0.23126122 0.20750798\n",
            " 0.20679802 0.22231607 0.2134114  0.20888193 0.2089065  0.20809092\n",
            " 0.22106452 0.22019091 0.2046427  0.20791724]\n",
            "Time taken for 1 epoch 82.81995224952698 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss [0.01150177 0.0381955  0.0228351  0.01323808 0.25185934 0.2691938\n",
            " 0.07437502 0.20258904 0.2302866  0.3058017  0.24470523 0.29045653\n",
            " 0.02979028 0.05389617 0.19452311 0.3840731  0.40736684 0.181511\n",
            " 0.36364514 0.12480901 0.23693241 0.04684554 0.02106446 0.09095692\n",
            " 0.03511045 0.48571506 0.0710602  0.0147185  0.02518813 0.1097126\n",
            " 0.06096308 0.02447917 0.07895139 0.01555512 0.19818579 0.9303929\n",
            " 0.06065964 0.06908637 0.02964153 0.25281435 0.33973745 0.02520891\n",
            " 0.04797997 0.05776574 0.02864949 0.243078   0.34276524 0.22116943\n",
            " 0.10294773 0.17574015 0.02357602 0.01628658 0.01839174 0.3239927\n",
            " 0.202229   0.01498236 0.03936831 0.06499157 0.36983848 0.18881093\n",
            " 0.35648656 0.08920854 0.1241907  0.5090241 ]\n",
            "Epoch 8 Batch 100 Loss [0.05119847 0.19000275 0.29962528 0.37057808 0.15430814 0.19442184\n",
            " 0.00463289 0.04530566 0.17441598 0.23457333 0.6526746  0.22420952\n",
            " 0.43293452 0.01571941 0.50121385 0.28877556 0.47497368 0.01969468\n",
            " 0.03997665 0.38171646 0.1468549  0.14486024 0.0031916  0.18618737\n",
            " 0.00669143 0.13836868 0.04294125 0.03212075 0.1553377  0.00383705\n",
            " 0.21754785 0.37207317 0.27493978 0.23191386 0.18202029 0.08475562\n",
            " 0.03592995 0.17000504 0.76142913 0.27554864 0.30024588 0.05605917\n",
            " 0.27467698 0.04382544 0.03540437 0.202422   0.15838332 0.10473254\n",
            " 0.24539317 0.05874662 0.2866025  0.02535459 0.00453895 0.31412214\n",
            " 0.3577039  0.01249777 0.03484188 0.04997    0.04018218 0.09185059\n",
            " 0.13352625 0.04228311 0.23065959 0.24047828]\n",
            "Epoch 8 Batch 200 Loss [0.32673788 0.16966128 0.45237234 0.1675658  0.29413757 0.08643156\n",
            " 0.22996375 0.00266271 0.01212629 0.15260665 0.09840362 0.10551339\n",
            " 0.291227   0.00399559 0.6359003  0.1870475  0.3304827  0.38852507\n",
            " 0.06107817 0.16137528 0.07246324 0.5187766  0.08645372 0.06761951\n",
            " 0.04175298 0.0068565  0.16210505 0.14809114 0.3198237  0.06533219\n",
            " 0.23962471 0.32335395 0.00294807 0.17251238 0.00758358 0.22847372\n",
            " 0.06239637 0.41690367 0.07493253 0.03939341 0.02162328 0.34126583\n",
            " 1.4186395  0.21063216 0.29150194 0.08142548 0.2509306  0.20090298\n",
            " 0.26855814 0.36700326 0.11551656 0.09332094 0.15797602 0.09726103\n",
            " 0.07756785 0.26773033 0.08731049 0.23065469 0.4195216  0.37934574\n",
            " 0.3102458  0.19072893 0.23208186 0.05328052]\n",
            "Epoch 8 Batch 300 Loss [0.16740127 0.38145941 0.2359999  0.10163579 0.3001292  0.08426436\n",
            " 0.04247079 0.15122864 0.05034022 0.13749345 0.13125613 0.04823146\n",
            " 0.06619544 0.01538269 0.01726966 0.34480408 0.03264984 0.22711928\n",
            " 0.38540906 0.01676823 0.00264847 0.773041   0.079129   0.1560911\n",
            " 0.09967038 0.5324745  0.04821837 0.10326178 0.19278526 0.22224413\n",
            " 0.2789228  0.25895563 0.2875313  0.00792547 0.05186227 0.3633702\n",
            " 0.30834103 0.18721676 0.00936945 0.00455698 0.01250213 0.02344708\n",
            " 0.08650831 0.35307804 0.33659336 0.01151787 0.26438883 0.04932768\n",
            " 0.18781145 0.01210478 0.27154228 0.168131   0.30138862 0.0194667\n",
            " 0.00543707 0.285564   0.04844202 0.21106024 0.0210156  0.17366332\n",
            " 0.24810407 0.15099712 0.26828268 0.26366895]\n",
            "Epoch 8 Batch 400 Loss [0.287117   0.12075414 0.09394695 0.1331571  0.21458113 0.32365543\n",
            " 0.02133803 0.14450386 0.19475885 0.08468774 0.17060657 0.20993389\n",
            " 0.155544   0.25267735 0.40706483 0.22965156 0.2605085  0.17413579\n",
            " 0.16557401 0.00335696 0.16023107 0.3479592  0.4478736  0.1166907\n",
            " 0.10332432 0.11234041 0.17473885 0.2555561  0.15057203 0.06533214\n",
            " 0.1356545  0.4462358  0.09294645 0.20447044 0.5398437  0.09987629\n",
            " 0.12772323 0.17876156 0.13470466 0.22678812 0.15624093 0.02772088\n",
            " 0.0755794  0.06323427 0.02602879 0.23389554 0.24204135 0.1355565\n",
            " 0.20052318 0.41646233 0.17716363 0.04079302 0.06162171 0.6615332\n",
            " 0.24180378 0.10642365 0.07543305 0.41421548 0.18989348 0.25928035\n",
            " 0.2217678  0.0725225  0.13218352 0.02788086]\n",
            "Epoch 8 Batch 500 Loss [0.05080925 0.26194462 0.34592548 0.03761506 0.22996312 0.693027\n",
            " 0.07394099 0.11629644 0.47278255 0.27414253 0.36092776 0.06849331\n",
            " 0.02166549 0.21419078 0.16307685 0.02500927 0.16698664 0.01489998\n",
            " 0.127435   0.01337019 0.2855493  0.02226736 0.04997627 0.27165976\n",
            " 0.30619532 0.07850949 0.11997607 0.36645284 0.12131585 0.43947896\n",
            " 0.23961513 0.26126826 0.36494294 0.09219929 0.2338229  0.115338\n",
            " 0.2789636  0.17515346 0.097788   0.42455554 0.19780357 0.04662629\n",
            " 0.02767862 0.1927431  0.25984082 0.06729151 0.19292672 0.08555301\n",
            " 0.16039877 0.09650775 0.19717868 0.4260617  0.23554021 0.02247991\n",
            " 0.30759543 0.34102216 0.18423109 0.46475664 0.18106005 0.20891733\n",
            " 0.14586352 0.0263094  0.46518353 0.23082232]\n",
            "Epoch 8 Batch 600 Loss [0.25290978 0.04569233 0.02451796 0.41111025 0.03910052 0.39612547\n",
            " 0.03991421 0.4403223  0.10703941 0.20760725 0.13214536 0.23890634\n",
            " 0.24035989 0.1120514  0.00966606 0.0958168  0.01643405 0.22069831\n",
            " 0.02051505 0.20990096 0.32626206 0.34660393 0.5959059  0.04665149\n",
            " 0.0918294  0.03683602 0.03143168 0.16877426 0.44376737 0.32383093\n",
            " 0.07732357 0.08687928 0.08311259 0.34647292 0.16547662 0.12930973\n",
            " 0.08217471 0.49333185 0.31420428 0.35206553 0.40598455 0.19975996\n",
            " 0.19031234 0.16949597 0.00959454 0.45090675 0.31944096 0.09192557\n",
            " 0.18118313 0.20744267 0.03852076 0.20270851 0.2444145  0.09624077\n",
            " 0.13434383 0.1320191  0.31068945 0.3794108  0.13342233 0.26895887\n",
            " 0.17402092 0.09820423 0.1674244  0.08171082]\n",
            "Epoch 8 Loss [0.17166916 0.17476347 0.18426464 0.17399597 0.17707044 0.17863584\n",
            " 0.16548616 0.1743399  0.18099616 0.16388819 0.17477702 0.16795947\n",
            " 0.18040551 0.18127216 0.16474757 0.183575   0.17231424 0.17157438\n",
            " 0.1794281  0.17712258 0.17936748 0.19088799 0.17378554 0.17349692\n",
            " 0.17420524 0.17827703 0.1853272  0.17290488 0.17089574 0.17899147\n",
            " 0.16939656 0.17787194 0.17851712 0.17835711 0.17477132 0.17251977\n",
            " 0.18342538 0.17019567 0.17095865 0.17400856 0.18283994 0.17482585\n",
            " 0.17138436 0.16548578 0.16748035 0.17548741 0.18412617 0.16778341\n",
            " 0.17414016 0.17682698 0.17618024 0.16848771 0.17082754 0.1877079\n",
            " 0.16755523 0.17781354 0.1742336  0.18036826 0.17507492 0.18510589\n",
            " 0.1727688  0.18204136 0.17381969 0.17175357]\n",
            "Time taken for 1 epoch 84.04396319389343 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss [0.0673987  0.3333857  0.18244056 0.08957855 0.21868478 0.01450898\n",
            " 0.3149142  0.329303   0.01651208 0.33431277 0.05973812 0.02936994\n",
            " 0.03005273 0.35814103 0.01001395 0.08319852 0.309011   0.2488876\n",
            " 0.07076371 0.0287726  0.2953041  0.06732906 0.10956255 0.62619984\n",
            " 0.03668552 0.06064301 0.04314221 0.05546713 0.24710748 0.02554231\n",
            " 0.04658644 0.05437881 0.2136131  0.30379263 0.08451881 0.25300488\n",
            " 0.2200033  0.26508173 0.89065427 0.05623    0.05065835 0.02134979\n",
            " 0.33165684 0.09338209 0.07697622 0.37492895 0.03378463 0.11531511\n",
            " 0.14871997 0.04572123 0.01364436 0.01006749 0.58321935 0.0462223\n",
            " 0.0294007  0.13689676 0.05294232 0.2532318  0.03167921 0.10190858\n",
            " 0.28187433 0.05486754 0.10768843 0.04295809]\n",
            "Epoch 9 Batch 100 Loss [0.13800624 0.14150022 0.06180505 0.03447229 0.01352905 0.01846739\n",
            " 0.1397614  0.13300699 0.48749563 0.25405082 0.00993208 0.09832556\n",
            " 0.00764502 0.0041598  0.0261969  0.01022592 0.06410825 0.02167565\n",
            " 0.25707904 0.11171932 0.11448773 0.23104855 0.34529993 0.00738136\n",
            " 0.07071775 0.10396558 0.26501316 0.09241234 0.03010035 0.14589772\n",
            " 0.15579216 0.11673597 0.03086742 0.10297599 0.17864065 0.26353765\n",
            " 0.07207835 0.01268007 0.09801552 0.14106001 0.2779431  0.15060623\n",
            " 0.1922247  0.08949243 0.01386216 0.01037347 0.297424   0.04802204\n",
            " 0.07959712 0.1345373  0.60558736 0.03139535 0.02980628 0.02998643\n",
            " 0.04270155 0.0568383  0.01368902 0.00715355 0.12358709 0.12852858\n",
            " 0.09519912 0.05765411 0.04794728 0.06029643]\n",
            "Epoch 9 Batch 200 Loss [0.19943674 0.06431239 0.0675418  0.24699678 0.06173153 0.05382677\n",
            " 0.25690225 0.05231287 0.24523862 0.03135199 0.11045219 0.07361479\n",
            " 0.15020402 0.27549827 0.12528558 0.32748973 0.0291752  0.09118785\n",
            " 0.03127384 0.04501696 0.08812735 0.00266498 0.3263197  0.03735383\n",
            " 0.04208663 0.29697397 0.05306059 0.01834776 0.12819512 0.02366622\n",
            " 0.48010477 0.15812434 0.12539758 0.03653264 0.12892114 0.03847643\n",
            " 0.01976472 0.13846397 0.0082777  0.00804879 0.0136206  0.5464739\n",
            " 0.0841507  0.22341816 0.14122684 0.15041862 0.36593017 0.10624646\n",
            " 0.0755211  0.0477178  0.08773926 0.29764327 0.16546272 0.10441761\n",
            " 0.01065168 0.27498317 0.25823957 0.0236259  0.20247675 0.01835712\n",
            " 0.06846598 0.20485023 0.15783437 0.03711103]\n",
            "Epoch 9 Batch 300 Loss [0.01254598 0.23471387 0.02209203 0.00775188 0.07102378 0.2241122\n",
            " 0.06437515 0.10082487 0.07547751 0.03449995 0.00400114 0.33504692\n",
            " 0.13157529 0.19455607 0.17115667 0.02663166 0.18081689 0.71835506\n",
            " 0.0106496  0.09315042 0.0689771  0.32599986 0.08411796 0.12964997\n",
            " 0.04598589 0.4704831  0.0511995  0.21688794 0.5670094  0.2556271\n",
            " 0.02614677 0.10390214 0.16521771 0.05459707 0.10235646 0.01699401\n",
            " 0.26867178 0.0155029  0.05288136 0.17292047 0.18873993 0.07534938\n",
            " 0.69278556 0.21488018 0.08501525 0.06618003 0.03835611 0.00701173\n",
            " 0.00980956 0.11340465 0.14328437 0.1805121  0.01569916 0.01125843\n",
            " 0.11368356 0.01481222 0.27897254 0.00836262 0.18896292 0.04242657\n",
            " 0.18289958 0.12648928 0.5551842  0.1944563 ]\n",
            "Epoch 9 Batch 400 Loss [0.00435714 0.20515357 0.00405473 0.21754925 0.02515208 0.07024992\n",
            " 0.00818547 0.08978159 0.24801286 0.02793869 0.26921958 0.41921487\n",
            " 0.08907184 0.10827358 0.01315392 0.23903175 0.10931407 0.01805843\n",
            " 0.11187322 0.04066469 0.29144257 0.42031118 0.04122178 0.32101986\n",
            " 0.28506997 0.46791682 0.44536728 0.04871764 0.08612932 0.15919174\n",
            " 0.06113518 0.20732784 0.22214702 0.29179168 0.19994837 0.08685175\n",
            " 0.02495159 0.04602783 0.12549067 0.50543076 0.08458772 0.5802524\n",
            " 0.298903   0.03665561 0.04400999 0.22842556 0.17639372 0.29451606\n",
            " 0.04182949 0.4636043  0.04368674 0.3056477  0.0169732  0.0872656\n",
            " 0.04887792 0.33056915 0.06682978 0.08549915 0.23933478 0.01432899\n",
            " 0.00314055 0.3260661  0.03599576 0.12647505]\n",
            "Epoch 9 Batch 500 Loss [0.06336188 0.01365769 0.42568323 0.07632123 0.149099   0.04178021\n",
            " 0.07305276 0.02983446 0.10830086 0.17462452 0.03565875 0.08983134\n",
            " 0.30168644 0.21521443 0.45908558 0.05220324 0.03811004 0.05960686\n",
            " 0.2623068  0.03738686 0.17398463 0.06709609 0.0070165  0.01657106\n",
            " 0.15738878 0.01198077 0.10418638 0.34651265 0.33996314 0.01132786\n",
            " 0.1704452  0.05599901 0.00380801 0.07163659 0.23413856 0.02037792\n",
            " 0.14115    0.27317655 0.13039067 0.3937673  0.2089089  0.12689252\n",
            " 0.32500914 0.29240602 0.23247163 0.15031761 0.29422075 0.22402631\n",
            " 0.02456727 0.4788858  0.02273816 0.0876832  0.4172863  0.16629094\n",
            " 0.24085487 0.0074552  0.06260101 0.07254825 0.1164228  0.17464592\n",
            " 0.30018315 0.374917   0.1268318  0.5834495 ]\n",
            "Epoch 9 Batch 600 Loss [0.24447343 0.12519224 0.66478074 0.09005315 0.37081677 0.0178554\n",
            " 0.22271048 0.01063348 0.30029187 0.41480228 0.03449412 0.1796933\n",
            " 0.18352546 0.01954135 0.01849052 0.06569701 0.1916571  0.0423018\n",
            " 0.20940444 0.10451303 0.09943179 0.09919189 0.00946582 0.19313927\n",
            " 0.26990667 0.14788595 0.1233831  0.04133209 0.28323138 0.00425907\n",
            " 0.07446301 0.05711086 0.05549322 0.02067211 0.12070993 0.03087731\n",
            " 0.30453503 0.08685062 0.52011824 0.19358476 0.00736148 0.3968022\n",
            " 0.17095613 0.202615   0.18923599 0.10439477 0.02190781 0.12139872\n",
            " 0.0124093  0.10233293 0.23992406 0.23390357 0.035025   0.23816967\n",
            " 0.24543755 0.21482876 0.09327254 0.11712531 0.40925455 0.3391131\n",
            " 0.12874575 0.17801645 0.20560573 0.01733881]\n",
            "Epoch 9 Loss [0.14688459 0.15224439 0.14777577 0.14511968 0.15618272 0.15132692\n",
            " 0.15498757 0.14743741 0.14400703 0.15392043 0.1370314  0.14317341\n",
            " 0.151914   0.14574222 0.14438064 0.14733748 0.14328751 0.15087943\n",
            " 0.15154012 0.15515836 0.15029974 0.14998968 0.16064681 0.15107648\n",
            " 0.15718015 0.15411162 0.13728932 0.14590134 0.15445322 0.14304663\n",
            " 0.15253405 0.15384191 0.15003711 0.1508178  0.15790744 0.15119833\n",
            " 0.1479154  0.14611985 0.14272925 0.15012336 0.15036342 0.1474541\n",
            " 0.14967288 0.15856656 0.1475936  0.15089807 0.15040086 0.14796825\n",
            " 0.15623282 0.16178644 0.14590447 0.14973602 0.15070091 0.15047178\n",
            " 0.14999788 0.14621294 0.14967383 0.14675109 0.14751033 0.14601292\n",
            " 0.1487409  0.14538185 0.15995198 0.1431517 ]\n",
            "Time taken for 1 epoch 82.97778940200806 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss [0.40946132 0.23238593 0.007336   0.07086565 0.04784546 0.21273604\n",
            " 0.29586348 0.2774723  0.05337382 0.15462263 0.06250602 0.21331912\n",
            " 0.02081995 0.07599065 0.03678836 0.01885292 0.02091071 0.29153505\n",
            " 0.16668035 0.02365166 0.07199549 0.06870002 0.03148966 0.19712313\n",
            " 0.00255057 0.0352897  0.01238214 0.01239863 0.01722741 0.05352269\n",
            " 0.11861426 0.27980867 0.3035937  0.27291775 0.07351168 0.5158941\n",
            " 0.00847359 0.11278234 0.44130865 0.43907085 0.07576578 0.00870566\n",
            " 0.03780435 0.02380107 0.09204326 0.01859536 0.12644134 0.01253957\n",
            " 0.07121366 0.03592408 0.11889558 0.02544067 0.02771671 0.1303933\n",
            " 0.02495081 0.00841059 0.11873243 0.06138744 0.03962544 0.08234335\n",
            " 0.05263838 0.00811036 0.36845917 0.03114312]\n",
            "Epoch 10 Batch 100 Loss [0.06866521 0.03916913 0.04989812 0.17345424 0.02529799 0.02739366\n",
            " 0.2993249  0.04369931 0.03169381 0.08425682 0.03471366 0.13135995\n",
            " 0.05653098 0.299658   0.02334322 0.4266012  0.23974378 0.0171631\n",
            " 0.09788886 0.11180034 0.2759494  0.17219532 0.02433831 0.13201931\n",
            " 0.31584907 0.0495157  0.05669107 0.26114032 0.40746576 0.07582881\n",
            " 0.11661903 0.06630766 0.07320431 0.13898125 0.30394474 0.0952245\n",
            " 0.23119585 0.18749031 0.09275487 0.00311068 0.15928513 0.03457216\n",
            " 0.12794991 0.16878724 0.32628536 0.02279858 0.04954142 0.01103052\n",
            " 0.03580353 0.07879565 0.08880196 0.18566962 0.00627403 0.27145496\n",
            " 0.18202177 0.09916163 0.01709042 0.08481779 0.11310478 0.3914328\n",
            " 0.16936255 0.08154035 0.24761547 0.03094948]\n",
            "Epoch 10 Batch 200 Loss [0.03307576 0.13433987 0.40004608 0.03459907 0.02453804 0.0959961\n",
            " 0.03958059 0.02367609 0.16822124 0.06055824 0.0201806  0.04285138\n",
            " 0.23294492 0.17026886 0.05682122 0.0253323  0.2605977  0.08720852\n",
            " 0.01436696 0.02317155 0.08966107 0.06433744 0.02187032 0.10400249\n",
            " 0.14163074 0.06123765 0.3144789  0.04021614 0.24319632 0.03154319\n",
            " 0.42776668 0.3549763  0.06352292 0.03653684 0.01799306 0.01602856\n",
            " 0.14753778 0.1362932  0.21282966 0.3823625  0.11065374 0.09471121\n",
            " 0.08174974 0.23221135 0.20554411 0.07677878 0.20317742 0.18110994\n",
            " 0.10377009 0.09132947 0.2298295  0.0301173  0.0507444  0.17483671\n",
            " 0.25757095 0.06440607 0.03636541 0.06233232 0.10644422 0.28598958\n",
            " 0.32193175 0.08051551 0.06154604 0.0644943 ]\n",
            "Epoch 10 Batch 300 Loss [0.19218622 0.0014982  0.35954055 0.1738549  0.0095433  0.13828571\n",
            " 0.09375463 0.08994799 0.04678087 0.0994948  0.13557695 0.12445816\n",
            " 0.054934   0.2624471  0.08250795 0.00225489 0.01161148 0.30472413\n",
            " 0.00466324 0.42473832 0.10623681 0.01557199 0.0224633  0.08019824\n",
            " 0.07622717 0.03892404 0.00734723 0.00339737 0.42436394 0.23018037\n",
            " 0.01718913 0.25260088 0.04810755 0.38862863 0.43799675 0.2099159\n",
            " 0.07646858 0.20681398 0.26340166 0.03896123 0.06721017 0.15845656\n",
            " 0.07422761 0.04100626 0.08885036 0.05698093 0.25547844 0.18823047\n",
            " 0.01091778 0.09224535 0.10378674 0.19369997 0.02008665 0.01112915\n",
            " 0.08130512 0.00700699 0.14718075 0.4974503  0.18207829 0.0108149\n",
            " 0.02232776 0.38947788 0.2104251  0.03264481]\n",
            "Epoch 10 Batch 400 Loss [0.06634454 0.09638499 0.03218348 0.14817865 0.267176   0.11285327\n",
            " 0.02266137 0.5243904  0.0655011  0.04897248 0.01910039 0.00709603\n",
            " 0.01503914 0.12296014 0.06492531 0.15623537 0.00504998 0.01696067\n",
            " 0.01720762 0.02373877 0.26376787 0.02106444 0.11488803 0.02637924\n",
            " 0.5364673  0.15006082 0.02012404 0.01668171 0.40507573 0.00526595\n",
            " 0.1392763  0.16548061 0.02985813 0.04985142 0.08406387 0.15805538\n",
            " 0.12089939 0.01993432 0.04197078 0.30989096 0.3441852  0.12913486\n",
            " 0.3378844  0.29132044 0.1199827  0.0075997  0.23025043 0.13314258\n",
            " 0.62255275 0.31653315 0.10902909 0.04667654 0.1602616  0.14994068\n",
            " 0.25435558 0.00475025 0.32358393 0.20114572 0.05434737 0.02467997\n",
            " 0.01461102 0.14244579 0.23541231 0.03947227]\n",
            "Epoch 10 Batch 500 Loss [0.0058439  0.12392015 0.32657704 0.03054517 0.43761158 0.04482422\n",
            " 0.01982117 0.01159969 0.04518813 0.24533473 0.16275062 0.00844042\n",
            " 0.20677763 0.1553603  0.19974737 0.25110117 0.08663215 0.05063624\n",
            " 0.16748308 0.299287   0.15942004 0.18284293 0.7623334  0.53668386\n",
            " 0.22371316 0.01764048 0.11839212 0.03709335 0.01773251 0.18768597\n",
            " 0.26704332 0.2982386  0.057765   0.27326182 0.08571258 0.05594912\n",
            " 0.11573669 0.01446173 0.15968826 0.01079372 0.21504028 0.08233453\n",
            " 0.06662128 0.20086628 0.11663239 0.04240398 0.23631664 0.0240924\n",
            " 0.04455823 0.01591527 0.06386344 0.32570925 0.00696938 0.08720134\n",
            " 0.1515886  0.34802833 0.15494771 0.06757396 0.04811918 0.03368\n",
            " 0.21644649 0.05368695 0.01767254 0.2959781 ]\n",
            "Epoch 10 Batch 600 Loss [0.00695531 0.04907551 0.22379827 0.16000848 0.19523798 0.32311258\n",
            " 0.02225413 0.09034484 0.04043744 0.15274224 0.2909239  0.0529713\n",
            " 0.11002223 0.04524496 0.0502363  0.17111214 0.02201725 0.02771995\n",
            " 0.23497921 0.14943042 0.09635461 0.01306883 0.22980963 0.05241086\n",
            " 0.12932405 0.3988761  0.18024206 0.10605112 0.15450722 0.16462691\n",
            " 0.25777686 0.00517777 0.12597835 0.01691877 0.11691051 0.30181515\n",
            " 0.00088935 0.02843822 0.09525135 0.05004629 0.49278355 0.03246459\n",
            " 0.07680675 0.04503141 0.03286886 0.22233234 0.24934562 0.15432057\n",
            " 0.06316262 0.02572724 0.04793817 0.04689552 0.21967301 0.19635092\n",
            " 0.06204615 0.01405528 0.14808357 0.11622993 0.01406834 0.01569613\n",
            " 0.06322557 0.02136453 0.02548365 0.27640533]\n",
            "Epoch 10 Loss [0.13236883 0.13993868 0.14708745 0.13481432 0.1322749  0.12840703\n",
            " 0.13122882 0.13947968 0.13706969 0.1382915  0.12206396 0.1387029\n",
            " 0.12556434 0.13555585 0.13378863 0.13643356 0.13325457 0.13819858\n",
            " 0.13280372 0.13265936 0.13316576 0.1329898  0.13397747 0.13897492\n",
            " 0.13066186 0.12229194 0.13562052 0.1309394  0.1316883  0.12799674\n",
            " 0.13697065 0.1295003  0.1421303  0.1310064  0.13679782 0.12622167\n",
            " 0.1290005  0.13655151 0.13206695 0.1270664  0.13896316 0.13105594\n",
            " 0.13648382 0.13473873 0.13341461 0.12953284 0.12602773 0.12850672\n",
            " 0.12958667 0.12596224 0.13467237 0.14568225 0.1255527  0.12943015\n",
            " 0.13179237 0.1366543  0.13647985 0.12933542 0.13166165 0.12606275\n",
            " 0.12562516 0.13478523 0.13387296 0.1356729 ]\n",
            "Time taken for 1 epoch 83.87463617324829 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xstDf5w44fZ"
      },
      "source": [
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ,max_length_inp))\n",
        "    \n",
        "    sentence = preprocess_sentence(sentence)\n",
        "    inputs = [inp_lang.word_index[i] for i in sentence.split(\" \")]\n",
        "    inputs=tf.keras.preprocessing.sequence.pad_sequences([inputs],maxlen=max_length_inp,padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    result = ''\n",
        "    \n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "        #storing the attention weights\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "        result += targ_lang.index_word[predicted_id] + ' '\n",
        "        if targ_lang.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "    \n",
        "    return result, sentence, attention_plot\n",
        "    "
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQFtTr5F_ASH"
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqpRQAUD_CZa"
      },
      "source": [
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jahWjS9-_Dw-",
        "outputId": "941a510b-8f60-4002-e9db-8f41cbdeabbe"
      },
      "source": [
        "#restore to the latest checkpoint\n",
        "print(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training_checkpoints/ckpt-5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f24cb6b3ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a6uCjB0_Oxb",
        "outputId": "21a8a2bb-f310-4a8f-d95e-5d57d7d47681"
      },
      "source": [
        "translate(u'i love you.')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> i love you . <end>\n",
            "Predicted translation: je t'aime ! <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnqIoT0-Oriy",
        "outputId": "9a74cc6d-fef7-4200-e34a-e771736cc7d0"
      },
      "source": [
        "translate(u\"I'm not going anywhere.\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> i'm not going anywhere . <end>\n",
            "Predicted translation: je ne vais pas manger . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr-KsmjdOreB",
        "outputId": "4bc35430-532d-437e-c126-a6c642599c62"
      },
      "source": [
        "translate(u'You are a good person.')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> you are a good person . <end>\n",
            "Predicted translation: tu es une bonne . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4X7WAvdOrci",
        "outputId": "42a3d601-c231-45ba-c3e1-fe2eadb73488"
      },
      "source": [
        "translate(u'Did you miss me?')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> did you miss me ? <end>\n",
            "Predicted translation: tu me manques loupé ? <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqzZXIUeOrW0",
        "outputId": "21b8f490-df47-4ed6-ce4d-4e810499ceff"
      },
      "source": [
        "translate(u'He came running.')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> he came running . <end>\n",
            "Predicted translation: il vint en courant . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHUNOW9DOrSD"
      },
      "source": [
        ""
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shmYnMzqOrQi"
      },
      "source": [
        ""
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akn3JDf__Sz1"
      },
      "source": [
        ""
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0EpzvgSOZ4r"
      },
      "source": [
        ""
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M3Sx24tOj2-"
      },
      "source": [
        ""
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbiynx69SYKg"
      },
      "source": [
        ""
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1qJrJgqSgdr"
      },
      "source": [
        ""
      ],
      "execution_count": 40,
      "outputs": []
    }
  ]
}